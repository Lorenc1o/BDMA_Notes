#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{footmisc}
\usepackage{listings}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1,0.99,0.94}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,  
    frame=single,
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\begin_modules
tcolorbox
customHeadersFooters
theorems-ams-bytype
theorems-sec-bytype
algorithm2e
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=blue, urlcolor=blue, citecolor=blue, pdfstartview={FitH}, unicode=true"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\boxbgcolor #62a0ea
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\headheight 2cm
\headsep 1cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
BDMA - Decision Modeling
\end_layout

\begin_layout Date
Fall 2023
\end_layout

\begin_layout Author
Jose Antonio Lorencio Abril
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../../../Decision-Modeling/LectureNotes/source/CS-logo.png
	scale 70

\end_inset


\end_layout

\begin_layout Standard
\align right
Professor: Petra Isenberg
\end_layout

\begin_layout Standard
\align right
Student e-mail: jose-antonio.lorencio-abril@student-cs.fr
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Address
This is a summary of the course 
\emph on
Visual Analytics
\emph default
 taught at the Université Paris Saclay - CentraleSupélec by Professor Petra
 Isenberg in the academic year 23/24.
 Most of the content of this document is adapted from the course notes by
 Isenberg, 
\begin_inset CommandInset citation
LatexCommand cite
key "Isenberg2023"
literal "false"

\end_inset

, so I won't be citing it all the time.
 Other references will be provided when used.
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
We all know about the increasing amount of data collected and handled by
 companies and organizations, but it is also important to understand that
 data is not the same as information: it is needed a process of analysis
 and understanding to derive information from data.
 When we have a question that we want to answer with our data, we 
\series bold
query
\series default
 the data seeking for the pieces of data that might be relevant for our
 questions.
 On the other hand, when we aren't sure what we're looking for, we 
\series bold
explore
\series default
 the data, looking for patterns that can give us insights and ideas we didn't
 thought about before.
\end_layout

\begin_layout Standard
Moreover, purely relying on automated analyses is not always effective due
 to potential unexpected results, usually because of edge cases and situations
 that we did not think about at the beginning or which did not even exist
 by then, and because data can be incomplete, inconsistent or deceptive.
 Therefore, human judgement and intervention is often needed, to provide
 background information, flexible analysis, modifiable to unintended directions
 and creativity.

\series bold
 Visual analytics
\series default
 is then a field that provides different tools to have a human in the loop
 in analysis tasks.
\end_layout

\begin_layout Standard
In this course, we want to build a strong critical thinking with data, relying
 on visualizations that can help us to better understand data.
 We will delve into the topics of Data Collection, Data Cleaning, Exploratory
 Analysis and Visualization.
\end_layout

\begin_layout Subsection
What is Visual Analytics?
\end_layout

\begin_layout Subsubsection
What is Data Analysis
\end_layout

\begin_layout Standard
Traditionally, there is the vision that data analysis consists in applying
 statistics to analyze data collected from the real world, but a more accurate
 vision would be to define data analysis as the task of thinking carefully
 about evidence, represented by data.
 Nowadays, this view is more spread, and data analysis is now covering a
 wide range of activities and skills:
\end_layout

\begin_layout Itemize
Problem definition
\end_layout

\begin_layout Itemize
Disassembling problems and data into analyzable pieces
\end_layout

\begin_layout Itemize
Data evaluation & Conclusion making
\end_layout

\begin_layout Itemize
Decision recommendation
\end_layout

\begin_layout Subsubsection
Visual Analytics
\end_layout

\begin_layout Standard
Visual Analytics is the science of analytical reasoning facilitated by interacti
ve visual interfaces.
 It combines automated analysis techniques with interactive visualizations
 for an effective understanding, reasoning and decision making on the basis
 of very large and complex data sets.
\end_layout

\begin_layout Standard
The greatest challenge of visual analytics is to enable deep insights, allowing
 analysts to examine massive, multi-dimensional, multi-source and time-varying
 information, to make the right decisions in a time-critical manner.
 With this in mind, the method is to combine automated analysis with human
 intervention, and representing data visually to allow for interaction,
 insight generation, conclusions making and enabling for better decision
 making.
\end_layout

\begin_layout Standard
The field can be understood as a whole, but it can also be divided into:
\end_layout

\begin_layout Itemize

\series bold
Information Visualization
\series default
: visualizations that enable to transmit information to the general public
 in a clear way.
\end_layout

\begin_layout Itemize

\series bold
Scientific Visualization
\series default
: visualizations that show scientific work and discoveries with precision.
\end_layout

\begin_layout Itemize

\series bold
Infographics
\series default
: this represents a visual summary of a topic that aims at providing an
 easy-to-understand overview on a topic.
\end_layout

\begin_layout Standard
As mentioned before, there are basically two approaches towards data analysis:
\end_layout

\begin_layout Itemize

\series bold
Confirmatory Analysis
\series default
: starts with a hypothesis about the data and tries to confirm its validity.
 This kind of analysis focuses more on fully automated analysis methods.
\end_layout

\begin_layout Itemize

\series bold
Exploratory Analysis
\series default
: when there is no or little a-priori information about the data and we
 are not sure about which patterns and information can be present in the
 data, we can explore it to create hypotheses that will need to be confirmed
 later.
 It is in this area where visual analytics is most widely used.
\end_layout

\begin_layout Standard
We can also understand visual analytics as a process, involving the following
 steps:
\end_layout

\begin_layout Enumerate
Information (data) gathering
\end_layout

\begin_layout Enumerate
Data preprocessing
\end_layout

\begin_layout Enumerate
Knowledge representation
\end_layout

\begin_layout Enumerate
Interaction
\end_layout

\begin_layout Enumerate
Decision making
\end_layout

\begin_layout Standard
Therefore, the requirements for an interesting and efficient visualization
 analytics approach are the development and understaing of data transformations
 and analysis algorithms, analytical reasoning techniques, visual representation
s and interactions, and techniques for production, presentation and disseminatio
n.
\end_layout

\begin_layout Subsubsection
History of Visual Analytics
\end_layout

\begin_layout Standard
In the early 2000s, there was an outgrowth of the Scientific & Information
 Visualization community, which started with US National Visualization and
 Analytics Center (NVAC) at PNNL in 2004.
 This center developed the first research and development agenda “Illuminating
 the Path” sponsored initially by DHS (US Department of Homeland Security).
 At first, the goals of this center and of the field were analyzing terrorist
 threats, safeguarding boarders and ports, and preparing for and responding
 to emergencies.
 
\end_layout

\begin_layout Standard
The field has evolved since then to serve for larger research goals, specially
 since the first edition of the VAST symposium, a conference in visual analytics
, science and technology, as part of the IEEE Visualizations Conference,
 in 2006; in addition to fundation of the VisMaster in 2008 by the EU.
 This represented a coordination action to join European academic and industrial
 R&D, with a focus in broader aplicability in different scientific fields
 (physics, astronomy, weather,...) rather than homeland security.
 From this point on, many centers in Europe have been created to research
 in this field.
\end_layout

\begin_layout Subsubsection
Challenges of Visual Analytics
\end_layout

\begin_layout Enumerate
Human reasoning & decision making
\end_layout

\begin_deeper
\begin_layout Enumerate
Understanding and supporting how humans reason about data.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ps-cs"
options "plain"

\end_inset


\end_layout

\begin_layout Enumerate
Support convergent and divergent thinking.
\end_layout

\begin_deeper
\begin_layout Enumerate
Create interfaces that are meaningful, clear, effective, and efficiente.
\end_layout

\end_deeper
\begin_layout Enumerate
Adoption
\end_layout

\begin_deeper
\begin_layout Enumerate
Communicate benefits of developed tools to drive frequent use.
\end_layout

\begin_layout Enumerate
Make tools accepted by users.
\end_layout

\end_deeper
\begin_layout Enumerate
Evaluation
\end_layout

\begin_deeper
\begin_layout Enumerate
Develop methods to compare novel tools to existing ones.
\end_layout

\begin_layout Enumerate
Asses how good a tool is, which is a very difficult task for measures other
 than time and error.
\end_layout

\end_deeper
\begin_layout Enumerate
Problem interdependence
\end_layout

\begin_deeper
\begin_layout Enumerate
Analysis in the real world often does not consist of isolated problems or
 questions.
 Problems are usually correlated and how one is solved influences how one
 should approach another.
\end_layout

\begin_layout Enumerate
Synthesis of analyses is needed.
\end_layout

\end_deeper
\begin_layout Enumerate
Integration of analysis methods
\end_layout

\begin_deeper
\begin_layout Enumerate
It is simple to do many isolated analyses, but it is hard to integrate them
 well into one tool or interface for human analysis.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Scalability
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Information scalability
\series default
: capability to extract relevant information from massive and possibly dynamical
ly changing data streams.
 There are different methods to achieve this kind of scalability, among
 which we can find abstract data sets, filter & reduce data, or multi-resolution
 representation of data.
\end_layout

\begin_layout Enumerate

\series bold
Display scalability
\series default
: this referes to the capability of visualizations and tools to adapt to
 different types of displays (computer monitor, smartphone, smartwatch,...).
\end_layout

\begin_layout Enumerate

\series bold
Visual scalability
\series default
: refers to the capability of visualizations to effectively display massive
 datasets in terms of number of data items or data dimensions.
 It depends on the quality of the layout, the interaction techniques and
 the perceptual capabilities.
\end_layout

\begin_layout Enumerate

\series bold
Human scalability
\series default
: human skills don't scale, but the amount of people involved in the analysis
 task can, so we must seek to design techniques to scale from a single to
 multiple users.
\end_layout

\begin_layout Enumerate

\series bold
Software scalability
\series default
: software systems and algorithms must scale to larger and different data.
\end_layout

\begin_layout Enumerate

\series bold
Others
\series default
: 
\end_layout

\begin_deeper
\begin_layout Enumerate
Privacy and security in multi-user settings.
\end_layout

\begin_layout Enumerate
Collaboration across languages and borders.
\end_layout

\end_deeper
\end_deeper
\begin_layout Section
Research Questions
\end_layout

\begin_layout Section
Data Collection
\end_layout

\begin_layout Standard
We tend to think of data as a thing stored in a database, or somewhere,...
 but in reality data has been collected using some methodology, and with
 many decisions taken before and during the process.
\end_layout

\begin_layout Standard
This is because the data was collected for some reason, and therefore was
 defined to give light on certain questions, and restricted to the measure
 devices that were available.
 However, having collected the data is not the same as already having the
 answers to our questions: we need to analyze it.
\end_layout

\begin_layout Standard
Analysis is a cycle, in which two big tasks are alternated:
\end_layout

\begin_layout Enumerate
Gathering data, applying statistical tools, and constructing graphics to
 address questions, to obtain answers.
\end_layout

\begin_layout Enumerate
Inspect the answers and assess new questions.
\end_layout

\begin_layout Standard
There are times when we already have the data, and we want to perform 
\series bold
exploratory data analysis
\series default
 to search for patterns and questions that could be answered.
 But oftentimes we have a question, and we need to collect the data somehow:
\end_layout

\begin_layout Itemize
Collect it ourselves:
\end_layout

\begin_deeper
\begin_layout Itemize
Surveys: which can be paper surveys, on-line or in-person interviews.
 It still represents one of the best ways to get detailed data or data about
 sensitive subjects.
\end_layout

\begin_deeper
\begin_layout Standard
Recently, it has become popular the concept of crowdsourcing data collection,
 which consists basically in publishing on-line surveys and people get paid
 for completing them.
\end_layout

\end_deeper
\begin_layout Itemize
Web logging: concists in tracking visits, click-throughs, and traffic patterns,
 along with other measures of user activity.
 There are tools such as Google Analytics or Open Web Analytics that allow
 this kind of analysis.
 A special kind of these analyses are the Edits & Accesses logs on wikipedia.
\end_layout

\begin_layout Itemize
Sensors: such as weather stations, personal activity trackers, cameras or
 even mobile phones.
\end_layout

\begin_layout Itemize

\color lime
Advantage
\color inherit
: you can define the variables of the data.
\end_layout

\begin_layout Itemize

\color red
Disadvantage
\color inherit
: it is expensive and time consuming.
\end_layout

\end_deeper
\begin_layout Itemize
Generating data:
\end_layout

\begin_deeper
\begin_layout Itemize
Simulations: consist on conveying the rules of our process using a model,
 and simulate the real scenario using this model.
\end_layout

\begin_layout Itemize

\color lime
Advantage
\color inherit
: you can define the simulations.
\end_layout

\begin_layout Itemize

\color red
Disadvantage
\color inherit
: it is hard to accurately represent reality.
\end_layout

\end_deeper
\begin_layout Itemize
Find it or extract it: there are many repositories of data, like DBPedia,
 FreeBase, WikiData, Project Gutenberg, Google N-Grams,...
 In addition, there are several published data initiatives led by governments
 and international institution, like 
\emph on
data.worldbank.org
\emph default
, 
\emph on
www.data.gov
\emph default
 (USA), 
\emph on
data.gov.uk
\emph default
 (UK), 
\emph on
data.gov.be 
\emph default
(Belgium),...
 There are even data initiatives meant to track other data initiatives,
 such as 
\emph on
re3data.org
\emph default
.
\end_layout

\begin_deeper
\begin_layout Standard
There are many more repositories of public data sets, like Google public
 data or Kaggle, among others.
\end_layout

\begin_layout Standard
In addition, there are what is called data retailers, which are basically
 companies that sells data that they have collected.
\end_layout

\begin_layout Standard
Moreover, there are many companies that provides an API to access their
 data, it can be free, or they may ask for a fee or a license.
\end_layout

\begin_layout Standard
Another way to extract data from the Internet, when there is not an available
 API, is by scraping the data.
 It consists on accessing the pages where the information is using a program
 that collects this information.
 This is usually a complex approach, and there are tools we can use to avoid
 scraping:
\end_layout

\begin_layout Itemize
Pulling data tables from the web using 
\emph on
importhtml
\emph default
.
\end_layout

\begin_layout Itemize
Parsing pdfs using 
\emph on
tabula
\emph default
.
\end_layout

\begin_layout Standard
Collecting data also has pros and cons:
\end_layout

\begin_layout Itemize

\color lime
Advantages
\color inherit
: cheap and fast.
\end_layout

\begin_layout Itemize

\color red
Disadvantages
\color inherit
: needs data cleaning and understanding of the sources.
 Also, it is hard to assess the reliability of the data.
\end_layout

\end_deeper
\begin_layout Subsection
Building a Web Scraper
\end_layout

\begin_layout Standard
If we need to build a Web Scraper, we should separate it into two different
 processes:
\end_layout

\begin_layout Itemize
Data fetching: it is advisable to download the complete pages and save them
 locally before processing them, specially if the data is spread across
 multiple pages, needing pagination.
\end_layout

\begin_layout Itemize
Parsing data: once we have our web pages stored locally, we can process
 them calmly.
 Another tip is to use the browsers' built-in tools for page inspection.
\end_layout

\begin_layout Standard
One need also to take into account that some sites are protected against
 data scraping, and we could get blocked.
 To get around this, we could introduce delays in the scraper, or use VPNs,...
\end_layout

\begin_layout Subsection
Data Formats
\end_layout

\begin_layout Itemize
Structured data: the kind of data that we can find in a spreadsheet or a
 database.
 It has a fixed schema and data types definition.
\end_layout

\begin_layout Itemize
Unstructured data: includes raw text, streaming data, images, videos,...
 Basically there is no control over the structure of the different data
 points.
\end_layout

\begin_layout Itemize
Semi-structured data: is more organized than the unstructured data, but
 does not follow a fixed schema.
 It could have a flexible schema, a multilayer schema, etc.
 For example JSON files.
\end_layout

\begin_layout Subsubsection
CSV
\end_layout

\begin_layout Standard
Comma-separated value files: we all know them!
\end_layout

\begin_layout Standard
Best practices:
\end_layout

\begin_layout Itemize
Remove unnecessary rows or cells (empty cells, comments)
\end_layout

\begin_layout Itemize
Write NA for missing values
\end_layout

\begin_layout Itemize
Split cells when possible
\end_layout

\begin_layout Itemize
Give meaningful unique column names
\end_layout

\begin_layout Subsubsection
XML, JSON, YAML
\end_layout

\begin_layout Standard
Different data formats to represent semi-structured data.
 They are all equivalent, but have different definitions and syntax.
\end_layout

\begin_layout Subsection
Handling Data
\end_layout

\begin_layout Standard
It is important to always keep backups of our data, and to password protect
 or encrypt any data with sensitive information.
\end_layout

\begin_layout Standard
In addition, it is important to take 
\series bold
provenance
\series default
 into account.
 We need to keep track of where and when data was collected, as well as
 to record any data processing steps we took, so they can be reproduced.
\end_layout

\begin_layout Standard
Regarding intellectual property, copyright and sharing data, it is crucial
 to be sure to know who owns the data, and to think early whether it will
 be possible to publish the data or not, as well as not to violate copyright
 (specially when scraping data).
\end_layout

\begin_layout Standard
Not only this, but any information that could be used to identify individuals
 is sensitive, and there might be legal repercussions for releasing it.
 It is important to be aware when to anonymize data before sharing.
 Also, regarding 
\series bold
anonymization
\series default
, it is important to note that just removing names is not enough, as there
 have been several studies showing how combining different publicly available
 anynomized datasets, individuals can be identified.
\end_layout

\begin_layout Standard
We need to comply with the 
\series bold
regulations
\series default
, and usually Institutional Review and Ethics Boards will need to approve
 the experiments or the data collection process before it happens, specially
 for studies involving people, which may even need informed consent.
 Moreover, in some cases there are limits on how long user data can be kept,
 or how the user should be notified when their data is tracked (through
 cookies for example).
\end_layout

\begin_layout Standard
In Europe, there is the 
\series bold
General Data Protection Regulation (GDPR)
\series default
, which is the world's strongest data protection law and defines how organizatio
ns can handle information about people.
 It defines what is personal data, as data from which people can be identified,
 and requires strict treatment for this kind of data.
 This processing should be lawful, fair and transparent, and get ethics
 approval.
 It is advisable to process the minimal amount of necessary personal data,
 and to anonymize it where possible.
\end_layout

\end_body
\end_document
