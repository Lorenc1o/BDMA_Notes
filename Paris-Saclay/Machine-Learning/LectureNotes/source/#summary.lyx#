#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{footmisc}
\usepackage{listings}
\usepackage{colortbl}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1,0.99,0.94}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,  
    frame=single,
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\begin_modules
tcolorbox
customHeadersFooters
theorems-ams-bytype
theorems-sec-bytype
algorithm2e
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=blue, urlcolor=blue, citecolor=blue, pdfstartview={FitH}, unicode=true"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\boxbgcolor #62a0ea
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\headheight 2cm
\headsep 1cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
BDMA - Machine Learning
\end_layout

\begin_layout Date
Fall 2023
\end_layout

\begin_layout Author
Jose Antonio Lorencio Abril
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../../../Decision-Modeling/LectureNotes/source/CS-logo.png
	scale 70

\end_inset


\end_layout

\begin_layout Standard
\align right
Professor: Tom Dupuis
\end_layout

\begin_layout Standard
\align right
Student e-mail: jose-antonio.lorencio-abril@student-cs.fr
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Address
This is a summary of the course 
\emph on
Machine Learning
\emph default
 taught at the Université Paris Saclay - CentraleSupélec by Professor Tom
 Dupuis in the academic year 23/24.
 Most of the content of this document is adapted from the course notes by
 Dupuis, 
\begin_inset CommandInset citation
LatexCommand cite
key "Dupuis2023"
literal "false"

\end_inset

, so I won't be citing it all the time.
 Other references will be provided when used.
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
Deep Learning
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard

\series bold
Artificial Intelligence
\series default
 is a wide concept, encompassing different aspects and fields.
 We can understand the term AI as the multidisciplinary field of study that
 aims at recreating human intelligence using artificial means.
 This is a bit abstract, and, in fact, there is no single definition for
 what this means.
 Intelligence is not fully understood, and thus it is hard to assess whether
 an artificial invention has achieved intelligence, further than intuitively
 thinking so.
\end_layout

\begin_layout Standard
For instance, AI involves a whole variety of fields:
\end_layout

\begin_layout Itemize
Perception
\end_layout

\begin_layout Itemize
Knowledge
\end_layout

\begin_layout Itemize
Cognitive System
\end_layout

\begin_layout Itemize
Planning
\end_layout

\begin_layout Itemize
Robotics
\end_layout

\begin_layout Itemize
Machine Learning (Neural Networks)
\end_layout

\begin_layout Itemize
Natural Language Processing
\end_layout

\begin_layout Standard
Leveraging all of these, people try to recreate or even surpass human performanc
e in different tasks.
 For example, a computer program that can play chess better than any human
 could ever possibly play, such as Stockfish, or a system that is able to
 understand our messages and reply, based on the knowledge that it has learnt
 in the past, such as ChatGPT and similar tools.
 Other examples are self-driving cars, auto-controlled robots, etc.
\end_layout

\begin_layout Standard
Therefore, AI is a very wide term, which merges many different scientific
 fields.
 
\series bold
Machine Learning
\series default
, on the other side, is a narrower term, which deals with the study of the
 techniques that we can use to make a computer learn to perform some task.
 It takes concepts from Statistics, Optimization Theory, Computer Science,
 Algorithms, etc.
 A relevant subclass of Machine Learning, which has come to be one of the
 most prominent fields of research in the recent years, is 
\series bold
Neural Networks 
\series default
or 
\series bold
Deep Learning
\series default
, which consists on an ML technique based on the human brain.
 Many amazing use cases that we see everywhere, like Siri (Apple assistant),
 Cortana (Windows assistant), Amazon recommender system, Dall-E (OpenAI
 image generation system), etc.
 Not only this, but the trend is growing, and the interest in DL is continuously
 increasing.
\end_layout

\begin_layout Standard
This is partly also due to the increase in computing resources, and the
 continuous optimization that different techniques are constantly experiencing.
 For instance, for a model trained on one trillion data points, in 2021
 the training process required around 16500x less compute than a model trained
 in 2012.
\end_layout

\begin_layout Standard
But not everything is sweet and roses when using DL.
 Since these systems are being involved in decision making processes, there
 are some questions that arise, like whose responsibility is it when a model
 fails? Moreover, data is needed to train the models, so it is relevant
 to address how datasets should be collected, and to respect the privacy
 of the people that produce data.
 In addition, the recent technologies that are able to generate new content
 and to modify real content, make it a new issue that AI can create false
 information, mistrust, and even violence or paranoia.
\end_layout

\begin_layout Standard
Nonetheless, let's not focus on the negative, there are lots of nice application
s of DL, and it is a key component to deal with data, achieving higher performan
ce than traditional ML techniques for huge amount of data.
\end_layout

\begin_layout Subsection
AI History
\end_layout

\begin_layout Standard
In 1950, Alan turing aimed to answer the question '
\emph on
Can machines think?
\emph default
' through a test, which came to be named the 
\series bold
Turing Test
\series default
, and consists in a 3 players game.
 First, a similar game is the following: 2 talkers, a man and a female,
 and 1 interrogator.
 The interrogator asks questions to the talkers, with the aim of determining
 who is the man and who is the female.
 The man tries to trick the interrogator, while the woman tries to help
 him to identify her.
\end_layout

\begin_layout Standard
Then, the Turing Test consists in replacing the man by an artificial machine.
 Turing thought that a machine that could trick a human interrogator, should
 be considered intelligent.
\end_layout

\begin_layout Standard
Later, in 1956, in the Dartmouth Workshop organized by IBM, the term 
\series bold
Artificial Intelligence
\series default
 was first used to describe 
\emph on
every aspect of learning or any other feature of intelligence can be so
 precisely described that a machine can be made to simulate it
\emph default
.
\end_layout

\begin_layout Standard
From this year on, there was a focus on researching about 
\series bold
Symbolic AI
\series default
, specially in three areas of research:
\end_layout

\begin_layout Itemize
Reasoning as search: a different set of actions leads to a certain goal,
 so we can try to find the best choice of action to obtain the best possible
 outcome.
\end_layout

\begin_layout Itemize
Natural Language: different tools were developed, following grammar and
 language rules.
\end_layout

\begin_layout Itemize
Micro world: small block based worlds, that the system can identify and
 move.
\end_layout

\begin_layout Standard
In 1958, the 
\series bold
Perceptron
\series default
 was conceived, giving birth to what is called the connectionism, an approach
 to AI based on the human brain, and a big hype that encouraged funding
 to support AI research.
 At this era, scientists experience a bit of lack of perspective, thinking
 that the power of AI was much higher than it was.
 For instance, H.
 A.
 Simon stated in 1965 that '
\emph on
machines will be capable, within twenty years, of doing any work a man can
 do.
\emph default
' We can relate to our time, with the huge hype that AI is experiencing,
 as well as the many apocaliptic theories that some people are making.
 Maybe we are again overestimating the power of AI.
\end_layout

\begin_layout Standard
The time from 1974 to 1980 is seen as the first winter of AI, in which research
 was slowed down and funding was reduced.
 This was due to several problems found at the time:
\end_layout

\begin_layout Itemize
There were few computational resources.
\end_layout

\begin_layout Itemize
The models at the time were not scalable.
\end_layout

\begin_layout Itemize
The Moravec's paradox: it is comparatively easy to make computers exhibit
 adult level performance on intelligence test or playing checkers, and difficult
 or impossible to give them the skills of a one-year-old when it comes to
 perception and mobility.
\end_layout

\begin_layout Itemize
Marvin Minsky made some devastating critics to connectionism, compared to
 symbolic, rule-based models:
\end_layout

\begin_deeper
\begin_layout Itemize
Limited capacity: Minsky showed that single-layer perceptrons (a simple
 kind of neural network) could not solve certain classes of problems, like
 the XOR problem.
 While it was later shown that multi-layer perceptrons could solve these
 problems, Minsky's work resulted in a shift away from neural networks for
 a time.
\end_layout

\begin_layout Itemize
Lack of clear symbols: Minsky believed that human cognition operates at
 a higher level with symbols and structures (like frames and scripts), rather
 than just distributed patterns of activation.
 He often argued that connectionist models lacked a clear way to represent
 these symbolic structures.
\end_layout

\begin_layout Itemize
Generalization and Abstraction: Minsky was concerned that connectionist
 models struggled with generalizing beyond specific training examples or
 abstracting high-level concepts from raw data.
\end_layout

\begin_layout Itemize
Inefficiency: Minsky pointed out that many problems which seemed simple
 for symbolic models could be extremely computationally intensive for connection
ist models.
\end_layout

\begin_layout Itemize
Lack of explanation: Connectionist models, especially when they become complex,
 can be seen as "black boxes", making it difficult to interpret how they
 arrive at specific conclusions.
\end_layout

\begin_layout Itemize
Over-reliance on learning: Minsky believed that not all knowledge comes
 from learning from scratch, and some of it might be innate or structured
 in advance.
 He felt connectionism put too much emphasis on learning from raw data.
\end_layout

\end_deeper
\begin_layout Standard
In 1980, there was a boom in expert knowledge systems that made AI recover
 interest.
 An 
\series bold
expert system
\series default
 solves specific tasks following an ensemble of rules based on knowledge
 facilitated by experts.
 A remarkable use case was the XCON sorting system, developed for the Digital
 Equipment Corporation, which helped them save 40M$ per year.
 In addition, connectionism also came again on scene, thanks to the development
 of 
\series bold
backpropagation
\series default
 applied to neurons, by Geoffrey Hinton.
 All these achievement made funding to come back to the field.
\end_layout

\begin_layout Standard
Nonetheless, there came a second winter of AI, from 1987 to 1994, mainly
 because several companies were disappointed and AI was seen as a technology
 that couldn't solve wide varieties of tasks.
 The funding was withdrawn from the field and a lot AI companies went bankrupt.
\end_layout

\begin_layout Standard
Luckily, from 1995 there started a new return of AI in the industry.
 The Moore's Law states that speed and memory of computer doubles every
 two years, and so computing power and memory was rapidly increasing, making
 the use of AI systems more feasible each year.
 During this time, many new concepts were introduced, such as 
\series bold
intelligent agents
\series default
 as systems that perceive their environment and take actions which maximize
 their chances of success; or different 
\series bold
probabilistic reasoning tools
\series default
 such as Bayesian networks, hidden Markov models, information theory, SVM,...
 In addition, AI researchers started to reframe their work in terms of mathemati
cs, computer science, physics, etc., making the field more attractive for
 funding.
 A remarkable milestone during this time was the victory of Deep Blue against
 Garry Kasparov.
\end_layout

\begin_layout Standard
The last era of AI comes from 2011 to today, with the advent and popularization
 of 
\series bold
Deep Learning
\series default
 (DL), which are deep graph processing layers mimicking human neurons interactio
ns.
 This happened thanks to the advances of hardware technologies, that have
 enabled the enormous computing requirements needed for DL.
 The huge hype comes from the spectacular results shown by this kind of
 systems in a huge variety of tasks, such as computer vision, natural language
 processing, anomaly detection,...
\end_layout

\begin_layout Standard
In summary, we can see how the history of AI has been a succession of hype
 and dissapointment cycles, with many actors involved and the industry as
 a very important part of the process.
\end_layout

\begin_layout Section
Machine Learning Basics
\end_layout

\begin_layout Standard
In this section, we review some notation, and basic knowledge of Linear
 Algebra, Probability and Machine Learning.
\end_layout

\begin_layout Subsection
Linear Algebra Basics
\end_layout

\begin_layout Standard
A 
\series bold
scalar
\series default
 is a number, either real and usually denoted 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

, or natural and denoted 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

.
 A 
\series bold
vector
\series default
 is an array of numbers, usually real, 
\begin_inset Formula $x\in\mathbb{R}^{n},$
\end_inset

 or
\begin_inset Formula 
\[
x=\left[\begin{array}{c}
x_{1}\\
x_{2}\\
\vdots\\
x_{n}
\end{array}\right].
\]

\end_inset

 A 
\series bold
matrix
\series default
 is a 2-dimensional array of numbers, 
\begin_inset Formula $A\in\mathbb{R}^{n\times m}$
\end_inset

, or
\begin_inset Formula 
\[
A=\left[\begin{array}{ccc}
A_{11} & \dots & A_{1n}\\
\vdots & \ddots & \vdots\\
A_{m1} & \dots & A_{mn}
\end{array}\right].
\]

\end_inset

 A 
\series bold
tensor
\series default
 is an 
\begin_inset Formula $n$
\end_inset

-dimensional array of numbers, for example 
\begin_inset Formula $A\in\mathbb{R}^{m\times k\times p}$
\end_inset

 is a 3-dimensional tensor.
\end_layout

\begin_layout Standard
Usually, we will be working with matrices, which can be operated in different
 ways:
\end_layout

\begin_layout Itemize
Transposition: 
\begin_inset Formula $A^{T}$
\end_inset

 is the transposed of 
\begin_inset Formula $A$
\end_inset

, defined as 
\begin_inset Formula $\left(A^{T}\right)_{ij}=A_{j,i}$
\end_inset

.
\end_layout

\begin_layout Itemize
Multiplication: Let 
\begin_inset Formula $A\in\mathbb{R}^{m\times k},B\in\mathbb{R}^{k\times n}$
\end_inset

, their multiplication, 
\begin_inset Formula $C\in\mathbb{R}^{m\times n}$
\end_inset

 is defined as 
\begin_inset Formula 
\[
C=A\cdot B=AB=\left(C_{ij}\right)_{i\leq m,j\leq n}=\left(\sum_{k}A_{ik}B_{kj}\right)_{i\leq m,j\leq n}.
\]

\end_inset

 Note that the following holds for every matrix 
\begin_inset Formula $A,B$
\end_inset

:
\begin_inset Formula 
\[
\left(AB\right)^{T}=B^{T}A^{T}.
\]

\end_inset


\end_layout

\begin_layout Itemize
Point-wise operations: if we have two matrices of the same size, 
\begin_inset Formula $A,B\in\mathbb{R}^{m\times n}$
\end_inset

, we can use apply scalar operator point-wise to each pair of elements in
 the same position in the two matrices.
 For example, the sum or the substraction of matrices.
\end_layout

\begin_layout Standard
There are also special matrices:
\end_layout

\begin_layout Itemize
Identity matrix: the identity matrix is a square matrix that preserves any
 vector it is multiplied with.
 For vectors of size 
\begin_inset Formula $n$
\end_inset

, the identity matrix 
\begin_inset Formula $I_{n}$
\end_inset

 verifies
\begin_inset Formula 
\[
I_{n}x=x,\forall x\in\mathbb{R}^{n}.
\]

\end_inset


\end_layout

\begin_layout Itemize
Inverse matrix: the inverse of a square matrix, 
\begin_inset Formula $A\in\mathbb{R}^{n\times n}$
\end_inset

, when it exists, is defined as the only matrix 
\begin_inset Formula $A^{-1}$
\end_inset

 such that
\begin_inset Formula 
\[
A^{-1}A=AA^{-1}=I_{n}.
\]

\end_inset


\end_layout

\begin_layout Standard
Another important concept is that of the norm, which is basically measuring
 how far a point is from the origin of the space and can be used to measure
 distances:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A 
\series bold
norm
\series default
 is a function 
\begin_inset Formula $f$
\end_inset

 that measures the size of vectors, and must have the following properties:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f\left(x\right)=0\iff x=0,$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $f\left(x+y\right)\leq f\left(x\right)+f\left(y\right),$
\end_inset

 and
\end_layout

\begin_layout Itemize
\begin_inset Formula $\forall\alpha\in\mathbb{R},f\left(\alpha x\right)=\left|\alpha\right|f\left(x\right).$
\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
A very important family of norms is the 
\begin_inset Formula $L^{p}$
\end_inset

 norm, defined as
\begin_inset Formula 
\[
\left\Vert x\right\Vert _{p}=\left(\sum_{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}.
\]

\end_inset

 The 
\series bold
Euclidean norm
\series default
 is the 
\begin_inset Formula $L^{2}$
\end_inset

 norm, noted 
\begin_inset Formula $\left\Vert x\right\Vert $
\end_inset

 and equivalent to computing 
\begin_inset Formula $\sqrt{x^{T}x}$
\end_inset

.
 In Machine Learning, it is not uncommon to find the use of the squared
 Euclidean norm, since it maintains the ordinals and is easier to operate
 with.
 The 
\series bold
Manhattan norm
\series default
 is the 
\begin_inset Formula $L^{1}$
\end_inset

 norm, and it is used when the difference between zero and nonzero elements
 is important.
 Finally, the 
\series bold
Max norm
\series default
 is the 
\begin_inset Formula $L^{\infty}$
\end_inset

, or 
\begin_inset Formula $\left\Vert x\right\Vert _{\infty}=\max_{i}\left|x_{i}\right|$
\end_inset

.
\end_layout

\begin_layout Subsection
Probability Basics
\end_layout

\begin_layout Standard
A 
\series bold
random variable
\series default
, 
\begin_inset Formula $X$
\end_inset

, is a variable that can take different values, 
\begin_inset Formula $x$
\end_inset

, randomly.
 They can be 
\series bold
discrete
\series default
, like the number drawn from a dice, or 
\series bold
continuous
\series default
, like the humidity in the air.
\end_layout

\begin_layout Standard
A probability distribution, 
\begin_inset Formula $p$
\end_inset

, is a 
\series bold
Probability Mass Function (PMF)
\series default
 for discrete variables, and a 
\series bold
Probability Density Function (PDF)
\series default
 for continuous random variables.
 It must satisfy:
\end_layout

\begin_layout Itemize
The domain of 
\begin_inset Formula $p$
\end_inset

 describe all possible states of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\forall x\in X,p\left(x\right)\geq0$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\int_{x\in X}p\left(x\right)dx=1$
\end_inset

.
\end_layout

\begin_layout Standard
It is usual to have two (or more) random variables, 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, and to be interested in the probability distribution of their combination,
 
\begin_inset Formula $p\left(x,y\right)$
\end_inset

.
 In this context, we define the 
\series bold
marginal probability
\series default
 of the variable 
\begin_inset Formula $X$
\end_inset

 as
\begin_inset Formula 
\[
p\left(X=x\right)=\int_{y\in Y}p\left(x,y\right)dy,\forall x\in X.
\]

\end_inset

 The 
\series bold
conditional probability
\series default
 of the variable 
\begin_inset Formula $Y$
\end_inset

 conditioned to 
\begin_inset Formula $X=x$
\end_inset

 is
\begin_inset Formula 
\[
p\left(Y=y|X=x\right)=\frac{p\left(Y=y,X=x\right)}{P\left(X=x\right)}.
\]

\end_inset

 Finally, there is the 
\series bold
chain rule of conditional probabilities
\series default
, in which we start with 
\begin_inset Formula $n$
\end_inset

 random variables, 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

, and it follows:
\begin_inset Formula 
\[
p\left(X_{1}=x_{1},...,X_{n}=x_{n}\right)=p\left(X_{1}=x_{1}\right)\prod_{i=2}^{n}p\left(X_{i}=x_{i}|X_{1}=x_{1},...,X_{i-1}=x_{i-1}\right).
\]

\end_inset


\end_layout

\begin_layout Example
For example, let's say 
\begin_inset Formula $X=\left\{ 1,2,3\right\} $
\end_inset

, 
\begin_inset Formula $Y=\left\{ 1,2\right\} $
\end_inset

 and 
\begin_inset Formula $Z=\left\{ 1,2\right\} $
\end_inset

 with the following probabilities:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Y$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Z$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $p\left(x,y,z\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{12}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{24}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{24}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{12}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Then, the marginal probabilities for the variable 
\begin_inset Formula $X$
\end_inset

 are
\begin_inset Formula 
\[
P\left(X=1\right)=\frac{1}{6}+\frac{1}{6}+\frac{1}{12}+\frac{1}{24}=\frac{11}{24},
\]

\end_inset


\begin_inset Formula 
\[
P\left(X=2\right)=\frac{1}{24}+\frac{1}{20}+\frac{1}{20}+\frac{1}{20}=\frac{23}{120},
\]

\end_inset


\begin_inset Formula 
\[
P\left(X=3\right)=\frac{1}{6}+\frac{1}{12}+\frac{1}{20}+\frac{1}{20}=\frac{21}{60}=\frac{7}{20}.
\]

\end_inset


\end_layout

\begin_layout Example
The conditional probability for the event 
\begin_inset Formula $\left\{ Y=1|X=3\right\} $
\end_inset

 is:
\begin_inset Formula 
\[
P\left(Y=1|X=3\right)=\frac{P\left(Y=1,X=3\right)}{P\left(X=3\right)}=\frac{\frac{1}{6}+\frac{1}{12}}{\frac{7}{20}}=\frac{\frac{1}{4}}{\frac{7}{20}}=\frac{5}{7}.
\]

\end_inset


\end_layout

\begin_layout Example
The conditional probability for the event 
\begin_inset Formula $\left\{ Z=1|X=3,Y=1\right\} $
\end_inset

 is:
\begin_inset Formula 
\[
P\left(Z=1|X=3,Y=1\right)=\frac{P\left(X=3,Y=1,Z=1\right)}{P\left(X=3,Y=1\right)}=\frac{\frac{1}{6}}{\frac{1}{4}}=\frac{2}{3}.
\]

\end_inset


\end_layout

\begin_layout Example
The probability of the event 
\begin_inset Formula $\left\{ X=3,Y=1,Z=1\right\} $
\end_inset

 could be computed from the conditional probabilities as follows, in case
 we only knew these:
\begin_inset Formula 
\begin{align*}
P\left(X=3,Y=1,Z=1\right)= & P\left(X=3\right)\cdot P\left(Y=1|X=3\right)\cdot P\left(Z=1|X=3,Y=1\right)\\
= & \frac{7}{20}\cdot\frac{5}{7}\cdot\frac{2}{3}=\frac{10}{60}=\frac{1}{6}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
When there are several variables, it is possible that the value of one of
 them is dependant, somehow, on the values that the other variables take;
 or that it is not:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Two random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
independant
\series default
, denoted 
\begin_inset Formula $X\perp Y$
\end_inset

, if 
\begin_inset Formula $\forall x\in X,y\in Y,p\left(X=x,Y=y\right)=p\left(X=x\right)\cdot p\left(Y=y\right).$
\end_inset

 
\end_layout

\begin_layout Definition
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
conditionally independent
\series default
 given the random variable 
\begin_inset Formula $Z$
\end_inset

, written 
\begin_inset Formula $X\perp_{Z}Y$
\end_inset

 if 
\begin_inset Formula $\forall x\in X,y\in Y,z\in Z$
\end_inset

,
\begin_inset Formula 
\[
p\left(X=x,Y=y|Z=z\right)=p\left(X=x|Z=z\right)\cdot p\left(Y=y|Z=z\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Statistics and Machine Learning, there are some measures that summarize
 information about random variables, and that hold great importance.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
The 
\series bold
expectation
\series default
 of a function 
\begin_inset Formula $f\left(x\right)$
\end_inset

 where 
\begin_inset Formula $x\sim p\left(x\right)$
\end_inset

 is the average value of 
\begin_inset Formula $f$
\end_inset

 over 
\begin_inset Formula $x$
\end_inset

:
\begin_inset Formula 
\[
\mathbb{E}_{x\sim p}\left[f\left(x\right)\right]=\int_{x\in X}p\left(x\right)f\left(x\right)dx.
\]

\end_inset

 The 
\series bold
variance
\series default
 of 
\begin_inset Formula $f\left(x\right)$
\end_inset

 measures how the values of 
\begin_inset Formula $f$
\end_inset

 varies from its average:
\begin_inset Formula 
\[
Var\left[f\left(x\right)\right]=\mathbb{E}\left[\left(f\left(x\right)-\mathbb{E}\left[f\left(x\right)\right]\right)^{2}\right],
\]

\end_inset

 and the 
\series bold
standard deviation 
\series default
is the square root of the variance.
\end_layout

\begin_layout Definition
The 
\series bold
covariance
\series default
 of two random variables provides informaiton about how much two values
 are linearly related.
 More generally, if we apply two functions 
\begin_inset Formula $f\left(x\right),$
\end_inset

 where 
\begin_inset Formula $x\sim p\left(x\right)$
\end_inset

, and 
\begin_inset Formula $g\left(y\right)$
\end_inset

, where 
\begin_inset Formula $y\sim p\left(y\right)$
\end_inset

, the covariance between them is:
\begin_inset Formula 
\[
Cov\left[f\left(x\right),g\left(y\right)\right]=\mathbb{E}\left[\left(f\left(x\right)-\mathbb{E}\left[f\left(x\right)\right]\right)\left(g\left(y\right)-\mathbb{E}\left[g\left(y\right)\right]\right)\right].
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Machine Learning Basics
\end_layout

\begin_layout Standard
To finalize with this review chapter, we are going to remember some basic
 concepts of Machine Learning.
\end_layout

\begin_layout Standard
First, let's give a definition of the concept:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A computer program is said to 
\series bold
learn
\series default
 from experience 
\begin_inset Formula $E$
\end_inset

 with respect to some class of tasks 
\begin_inset Formula $T$
\end_inset

 and performance measure 
\begin_inset Formula $P$
\end_inset

, if its performance at tasks in 
\begin_inset Formula $T$
\end_inset

, as measured by 
\begin_inset Formula $P$
\end_inset

, improves with experience 
\begin_inset Formula $E$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
The 
\series bold
task
\series default
 
\begin_inset Formula $T$
\end_inset

 can be classification, regression, translation, generation, anomaly detection,...
\end_layout

\begin_layout Itemize
The 
\series bold
performance measure 
\begin_inset Formula $P$
\end_inset

 
\series default
is specific to the tasks involved, and can be accuracy for classification,
 for example.
 It is measured on a 
\series bold
test set
\series default
.
\end_layout

\begin_layout Itemize
The 
\series bold
experience
\series default
 
\begin_inset Formula $E$
\end_inset

 is divided into two main categories:
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Supervised learning
\series default
: a dataset of points associated with a label or a target determines the
 expected outcome of each event.
\end_layout

\begin_layout Itemize

\series bold
Unsupervised learning
\series default
: a dataset of points without labels or targets, in which the desirable
 outcome needs to be define in some different way.
\end_layout

\end_deeper
\begin_layout Standard
Mathematically, we can formalize this as having a dataset of 
\begin_inset Formula $m$
\end_inset

 points and 
\begin_inset Formula $k$
\end_inset

 features, which can be represented as a matrix 
\begin_inset Formula $X\in\mathbb{R}^{m\times k}$
\end_inset

.
 In the case of supervised learning, 
\begin_inset Formula $X$
\end_inset

 is associated with a vector of labels, 
\begin_inset Formula $y$
\end_inset

, and we aim to learn a joint distribution, 
\begin_inset Formula $p\left(X,y\right)$
\end_inset

 to infer
\begin_inset Formula 
\[
p\left(Y=y|X=x\right)=\frac{p\left(x,y\right)}{\sum_{y'}p\left(x,y'\right)}.
\]

\end_inset

 The goal is then to find a function 
\begin_inset Formula $\hat{f}$
\end_inset

 that associates each 
\begin_inset Formula $x$
\end_inset

 to the best approximation of 
\begin_inset Formula $y$
\end_inset

, and that is capable of generalizing to unseen data.
 Usually, 
\begin_inset Formula $\hat{f}$
\end_inset

 is parameterized by a set of parameters, 
\begin_inset Formula $\theta$
\end_inset

, which are learnt during training.
\end_layout

\begin_layout Standard
The main challenge of an ML model is 
\series bold
generalization
\series default
 to unseen data estimated on test data after the training on training data.
 
\series bold
Overfitting
\series default
 occurs when the gap between training error and test error is too large,
 while 
\series bold
underfitting
\series default
 occurs when the training error is too large.
 The 
\series bold
capacity
\series default
 of a model is the range of functions that it is able to leanr and control
 how likely the model can overfit or underfit.
 This is visualized in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Appropriate-capacity,-overfittin"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename pegado1.png
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Appropriate-capacity,-overfittin"

\end_inset

Appropriate capacity, overfitting and underfitting visualization.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
When we want to train a model, we will define the parameters that characterize
 it, and then we need to obtain the best possible of the parameters, according
 to the data.
 For this, we use estimators:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Given an unknown parameter 
\begin_inset Formula $\theta$
\end_inset

, we estimate it through an 
\series bold
estimator
\series default
, 
\begin_inset Formula $\hat{\theta}$
\end_inset

.
 A 
\series bold
point estimator
\series default
 is a function of the data, 
\begin_inset Formula $X$
\end_inset

,
\begin_inset Formula 
\[
\hat{\theta}=g\left(X\right).
\]

\end_inset

 The 
\series bold
bias
\series default
 of an estimator is
\begin_inset Formula 
\[
bias\left(\hat{\theta}\right)=\mathbb{E}\left[\hat{\theta}\right]-\theta.
\]

\end_inset

 An estimator is 
\series bold
unbiased 
\series default
if 
\begin_inset Formula $bias\left(\hat{\theta}\right)=0$
\end_inset

.
\end_layout

\begin_layout Definition
The 
\series bold
variance
\series default
 of an estimator is 
\begin_inset Formula $Var\left(\hat{\theta}\right)$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are different ways to construct estimators, but one that is frequently
 used and that has solid mathematical foundations is the 
\series bold
maximum likelihood estimator
\series default
.
 Consider a dataset 
\begin_inset Formula $X=\left\{ x_{1},...,x_{n}\right\} $
\end_inset

 and 
\begin_inset Formula $p\left(x;\theta\right)$
\end_inset

 a parametric family of probability distribution that maps for each 
\begin_inset Formula $x$
\end_inset

 the probability 
\begin_inset Formula $p_{data}\left(x\right)$
\end_inset

.
 This is, for each 
\begin_inset Formula $\theta$
\end_inset

, 
\begin_inset Formula $p\left(x;\theta\right)$
\end_inset

 is a probability density function.
 The maximum likelihood estimator is then
\begin_inset Formula 
\begin{align*}
\theta_{ML}= & \arg\max_{\theta}p_{model}\left(X;\theta\right)\\
= & \arg\max_{\theta}\prod_{i=1}^{n}p_{model}\left(x_{i};\theta\right),
\end{align*}

\end_inset

 considering that all instances of data are independent and identically
 distributed (iid).
 It is also a common practice to use the maximum 
\series bold
log
\series default
-likelihood instead, removing the product and avoiding floating point issues,
 since when the dataset is large, the product will rapidly go to 0.
 In addition, the logarithm does not modify the ordinals of the function.
 Therefore, we can use:
\begin_inset Formula 
\[
\theta_{ML}=\arg\max_{\theta}\sum_{i=1}^{n}\log\left(p_{model}\left(x_{i};\theta\right)\right).
\]

\end_inset


\end_layout

\begin_layout Section
Deep Neural Networks
\end_layout

\begin_layout Subsection
Perceptron
\end_layout

\begin_layout Standard
A deeper explanation of the perceptron can be read in my notes from another
 course, 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://lorenc1o.github.io/BDMA_Notes/universities/UPC/Machine_Learning_summary.pdf
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
A perceptron is an algorithm for supervised learning of binary classifiers.
 That is, we have a dataset 
\begin_inset Formula $X\in\mathbb{R}^{n\times m}$
\end_inset

 associated with a vector of labels 
\begin_inset Formula $y\in\left\{ 0,1\right\} ^{n}$
\end_inset

.
 Then, the perceptron learns a function 
\begin_inset Formula $\hat{f}$
\end_inset

 parametrized by a vector of weights 
\begin_inset Formula $w\in\mathbb{R}^{m}$
\end_inset

 and a bias 
\begin_inset Formula $b$
\end_inset

, such that:
\begin_inset Formula 
\[
\hat{f}\left(x\right)=\begin{cases}
1 & if\ w\cdot x+b>0\\
0 & \sim
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore, it is a linear classifier, which divides the input space into
 two regions separated by a hyperplane.
 This means that a perceptron cannot separate non-linear data.
\end_layout

\begin_layout Subsection
Multi-layer perceptron
\end_layout

\begin_layout Standard
A deeper explanation of the MLP can be read in my notes from another course,
 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://lorenc1o.github.io/BDMA_Notes/universities/UPC/Machine_Learning_summary.pdf
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
When we say 'Deep' neural network, we refer to a series of stacked perceptrons.
 However, just like this, the model is still linear.
 This is why activation functions are introduced.
 An 
\series bold
activation function
\series default
 is a function that is applied to the output of a perceptron, to make it
 non linear.
\end_layout

\begin_layout Standard
For example, ReLU is a piecewise-linear function defined as
\begin_inset Formula 
\[
ReLU\left(z\right)=\begin{cases}
z & if\ z\geq0\\
0 & \sim
\end{cases}=\max\left\{ z,0\right\} .
\]

\end_inset

 This function preserves much of the good oprimization properties of a linear
 function, i.e., it is differentiable (apart from one point), and its derivative
 is constant.
\end_layout

\begin_layout Example
Learn the XOR function with a 2-layer MLP.
\end_layout

\begin_layout Example
The XOR function is represented with the table:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
We want to use a 2-layer MLP to learn this function:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename xor.drawio.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Example
In 
\begin_inset Formula $h_{1}$
\end_inset

, it will be
\begin_inset Formula 
\[
w_{11}x_{1}+w_{12}x_{2}+b_{1},
\]

\end_inset

 and in 
\begin_inset Formula $h_{2}$
\end_inset


\begin_inset Formula 
\[
w_{11}x_{1}+w_{12}x_{2}+b_{1}.
\]

\end_inset

 This can be represented as
\begin_inset Formula 
\[
h=W_{h}^{T}X+b_{h}.
\]

\end_inset

 Then, we apply ReLU
\begin_inset Formula 
\[
\max\left(0,W_{h}^{T}X+b_{h}\right),
\]

\end_inset

 and finally the output layer
\begin_inset Formula 
\[
y=W_{y}^{T}\max\left(0,W_{h}^{T}X+b_{h}\right)+b_{y}.
\]

\end_inset


\end_layout

\begin_layout Example
Let's see the different inputs:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $h$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
w_{11} & w_{12}\\
w_{21} & w_{22}
\end{array}\right)\left(\begin{array}{c}
0\\
0
\end{array}\right)+\left(\begin{array}{c}
b_{1}\\
b_{2}
\end{array}\right)=\left(\begin{array}{c}
b_{1}\\
b_{2}
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
w_{1}^{y} & w_{2}^{y}\end{array}\right)\left(\begin{array}{c}
\max\left(0,b_{1}\right)\\
\max\left(0,b_{2}\right)
\end{array}\right)+b_{y}\leq0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
w_{12}+b_{1}\\
w_{22}+b_{2}
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
w_{1}^{y} & w_{2}^{y}\end{array}\right)\left(\begin{array}{c}
\max\left(0,w_{12}+b_{1}\right)\\
\max\left(0,w_{22}+b_{2}\right)
\end{array}\right)+b_{y}>0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
w_{11}+b_{1}\\
w_{21}+b_{2}
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
w_{1}^{y} & w_{2}^{y}\end{array}\right)\left(\begin{array}{c}
\max\left(0,w_{11}+b_{1}\right)\\
\max\left(0,w_{21}+b_{2}\right)
\end{array}\right)+b_{y}>0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
w_{11}+w_{12}+b_{1}\\
w_{21}+w_{22}+b_{2}
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
w_{1}^{y} & w_{2}^{y}\end{array}\right)\left(\begin{array}{c}
\max\left(0,w_{11}+w_{12}+b_{1}\right)\\
\max\left(0,w_{21}+w_{22}+b_{2}\right)
\end{array}\right)+b_{y}\leq0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
A solution is:
\begin_inset Formula 
\[
W_{h}=\left(\begin{array}{cc}
1 & 1\\
1 & 1
\end{array}\right),b_{h}=\left(\begin{array}{c}
0\\
-1
\end{array}\right),W_{y}=\left(\begin{array}{c}
1\\
-2
\end{array}\right),b=0.
\]

\end_inset

 Let's check:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $h$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $y$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
0\\
-1
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
1 & -2\end{array}\right)\left(\begin{array}{c}
0\\
0
\end{array}\right)=0\leq0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
1\\
1-1
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
1 & -2\end{array}\right)\left(\begin{array}{c}
1\\
0
\end{array}\right)=1>0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
1\\
1-1
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
1 & -2\end{array}\right)\left(\begin{array}{c}
1\\
0
\end{array}\right)=1>0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{c}
1+1\\
1+1-1
\end{array}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\left(\begin{array}{cc}
1 & -2\end{array}\right)\left(\begin{array}{c}
2\\
1
\end{array}\right)=0\leq0$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
So, it works! Note that this solution is not unique!
\end_layout

\begin_layout Example
What happens is actually that the solution for the XOR problem is not linearly
 separable:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename xor_space.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Example
But, the hidden layer transforms this space, making the problem linearly
 separable, and therefore solvable in the last layer:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename xor_space_trans.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Subsection
Cost Functions
\end_layout

\begin_layout Standard
The cost function is important when working with neural networks, because
 our goal is to ultimately train the model to solve some problem, and the
 cost functions will be the function that our model will aim at minimizing,
 thus guiding the training process.
\end_layout

\begin_layout Standard
Usually, we will need to choose a cost function 
\begin_inset Formula $\mathcal{L}$
\end_inset

 that is suitable for our problem.
 Then, we will minimize 
\begin_inset Formula $\mathcal{L}$
\end_inset

 with stochastic gradient descent, by:
\end_layout

\begin_layout Itemize
Training on a training dataset.
\end_layout

\begin_layout Itemize
Estimating error on an evaluation dataset.
\end_layout

\begin_layout Itemize
Computing the gradients using backpropagation.
\end_layout

\begin_layout Standard
In this process, we will aim to find good local minima, instead of global
 minimum.
 This is related to overfitting (learning only the training data, losing
 generalization capabilities), and to the empirical fact that deep neural
 network have surprisingly good local and non-global optima.
\end_layout

\begin_layout Subsubsection
Choice of cost function
\end_layout

\begin_layout Standard
In the general case, we use the maximum likelihood principle, taking the
 output types of the network into account.
 This means that we assume our dataset 
\begin_inset Formula $\left\{ x_{1},...,x_{n}\right\} $
\end_inset

 to be independently and identically distributed (i.i.d.) from an unknown distribut
ion, 
\begin_inset Formula $p_{data}\left(x\right)$
\end_inset

.
 We choose a parametric model family 
\begin_inset Formula $p_{model}\left(x;\theta\right)$
\end_inset

 represented as a neural network, which we use to estimate an approximation
 of the true distribution.
 For this, we utilize the 
\series bold
maximum likelihood estimator
\series default
, defined as
\begin_inset Formula 
\[
\theta_{ML}=\arg\max_{\theta}\prod_{i=1}^{n}p_{model}\left(x_{i};\theta\right).
\]

\end_inset

 Usually, to avoid floating point errors, the log-likelihood is used instead:
\begin_inset Formula 
\[
\theta_{ML}=\arg\max_{\theta}\sum_{i=1}^{n}\log p_{model}\left(x_{i};\theta\right).
\]

\end_inset


\end_layout

\begin_layout Standard
In the maximum likelihood estimation framework, we might apply activation
 functions to the output layer to get a desired structure for our distribution.
 This choice will also influence the mathematical form of the cost function.
 For example, we can use linear units for regression or for Gaussian distributio
ns, sigmoid units for binary classification or softmax units for multi-class
 classification.
\end_layout

\begin_layout Paragraph
Linear units for regression
\end_layout

\begin_layout Standard
A 
\series bold
linear output layer
\series default
 is such that, given the features 
\begin_inset Formula $h$
\end_inset

, the output is
\begin_inset Formula 
\[
\hat{y}=W^{T}h+b,
\]

\end_inset

 where 
\begin_inset Formula $W$
\end_inset

 is the weights vector and 
\begin_inset Formula $b$
\end_inset

 the bias.
\end_layout

\begin_layout Standard
We can use this to predict real or vector valued variables, such as prices,
 biometrics,...
\end_layout

\begin_layout Paragraph
Linear unit for Gaussian distribution
\end_layout

\begin_layout Standard
A 
\series bold
Gaussian output unit
\series default
 is such that, given features 
\begin_inset Formula $h$
\end_inset

, a linear layer produces a vector 
\begin_inset Formula $\hat{y}$
\end_inset

 representing the mean and the covariance matrix of a conditional Gaussian
 distribution:
\begin_inset Formula 
\[
p\left(y|x\right)=\mathcal{N}\left(y;\hat{y},I\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Covariance is usually not modelled or simplified to be diagonal (in which
 case we need to ensure that the output is non-negative).
\end_layout

\begin_layout Paragraph
Binary classification
\end_layout

\begin_layout Standard
In this case, the objective is to predict a binary variable, 
\begin_inset Formula $y$
\end_inset

: the neural network must predict 
\begin_inset Formula $P\left(y=1|x\right)$
\end_inset

.
 Thus, we must ensure that the output is a probability, in the interval
 
\begin_inset Formula $\left[0,1\right]$
\end_inset

.
 For this, we can take
\begin_inset Formula 
\[
P\left(y=1|x\right)=\max\left\{ 0,\min\left\{ 1,W^{T}h+b\right\} \right\} .
\]

\end_inset

 The problem with this approach is that if 
\begin_inset Formula $W^{T}h+b\notin\left[0,1\right]$
\end_inset

 then the gradient is 0 and the training will stop.
 To solve this issue, we can use a 
\series bold
sigmoid unit
\series default
, which is 
\begin_inset Formula 
\[
\hat{y}=\sigma\left(W^{T}h+b\right)=\frac{1}{1+e^{-W^{T}h+b}}.
\]

\end_inset


\end_layout

\begin_layout Paragraph
Softmax unit for multi-class classification
\end_layout

\begin_layout Standard
Now our objective is to classify the input data into one among 
\begin_inset Formula $N>2$
\end_inset

 classes.
 We want to predict 
\begin_inset Formula $\hat{y}$
\end_inset

 with 
\begin_inset Formula $\hat{y_{i}}P\left(y=i|x\right)$
\end_inset

, subject to 
\begin_inset Formula $\hat{y_{i}}\in\left[0,1\right],\forall i$
\end_inset

 and 
\begin_inset Formula $\sum_{i}y_{i}=1$
\end_inset

.
\end_layout

\begin_layout Standard
In the output layer we can have 
\begin_inset Formula $N$
\end_inset

 perceptrons, each of them computing 
\begin_inset Formula $z_{i}=\log P\left(y=i|x\right)$
\end_inset

, i.e., the 
\series bold
logits
\series default
.
 With this, we can apply the 
\series bold
softmax output unit
\series default
 to all of them, obtaining our vector of probabilities, as
\begin_inset Formula 
\[
softmax\left(z\right)_{i}=\frac{e^{z_{i}}}{\sum_{j}e^{z_{j}}}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Cross-entropy
\end_layout

\begin_layout Standard
In classification problems we want to estimate the probability of different
 outcomes.
 Let the estimated probability of outcome 
\begin_inset Formula $i$
\end_inset

 be 
\begin_inset Formula $p_{model}\left(x=i\right)$
\end_inset

 with to-be-optimized parameters 
\begin_inset Formula $\theta$
\end_inset

 and let the frequency of outcome 
\begin_inset Formula $i$
\end_inset

 in the training set be 
\begin_inset Formula $p\left(x=i\right)$
\end_inset

.
 Given 
\begin_inset Formula $N$
\end_inset

 conditionally independent samples in the training set, then the likelihood
 of the parameters 
\begin_inset Formula $\theta$
\end_inset

 of the model 
\begin_inset Formula $p_{model}\left(x=i\right)$
\end_inset

 on the training set is:
\begin_inset Formula 
\[
\mathcal{L}\left(\theta\right)=\prod_{i\in X}p_{model}\left(x=i\right)^{N\cdot p\left(x=i\right)}.
\]

\end_inset

 Therefore, the log-likelihood, divided by 
\begin_inset Formula $N$
\end_inset

, is
\begin_inset Formula 
\[
\frac{1}{N}\log\left(\mathcal{L}\left(\theta\right)\right)=\frac{1}{N}N\cdot\sum_{i\in X}p\left(x=i\right)\log p_{model}\left(x=i\right)=\sum_{i\in X}p\left(x=i\right)\log p_{model}\left(x=i\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Cross-entropy minimization is frequently used in optimization and rare-event
 probability estimation.
 When comparing a distribution 
\begin_inset Formula $q$
\end_inset

 against a fixed reference distribution 
\begin_inset Formula $p$
\end_inset

, cross-entropy and KL divergence are identical up to an additive constant
 (since 
\begin_inset Formula $p$
\end_inset

 is fixed): According to the Gibbs' inequality, both take on their minimal
 values when 
\begin_inset Formula $p=q$
\end_inset

, which is 
\begin_inset Formula $0$
\end_inset

 for KL divergence, and 
\begin_inset Formula $H\left(p\right)$
\end_inset

 for cross-entropy.
 In the engineering literature, the principle of minimizing KL divergence
 (Kullback's "Principle of Minimum Discrimination Information") is often
 called the Principle of Minimum Cross-Entropy (MCE), or Minxent.
\end_layout

\begin_layout Subsection
Why deep NN?
\end_layout

\begin_layout Standard
Depth is the longest data path data can take from input to output.
 For a deep feed forward NN, depth is the number of hidden layers plus the
 output layer.
 State-of-the-art architectures used in practice have dozens to hundreds
 of layers.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
Universal Approximation Theorem
\end_layout

\begin_layout Theorem
Let 
\begin_inset Formula $\varphi\left(\right)$
\end_inset

 be a nonconstant, bounded, and monotonically increasing continuous function.
 Let 
\begin_inset Formula $I_{m_{0}}$
\end_inset

 denote the 
\begin_inset Formula $m_{0}-$
\end_inset

dimensional unit hypercube, 
\begin_inset Formula $\left[0,1\right]^{m_{0}}$
\end_inset

.
 The space of continuous functions on 
\begin_inset Formula $I_{m_{0}}$
\end_inset

 is denoted by 
\begin_inset Formula $C\left(I_{m_{0}}\right)$
\end_inset

.
\end_layout

\begin_layout Theorem
Then, given any function 
\begin_inset Formula $f\in C\left(I_{m_{0}}\right)$
\end_inset

 and 
\begin_inset Formula $\varepsilon>0$
\end_inset

, there exists an integer 
\begin_inset Formula $m_{1}$
\end_inset

 and sets of real constants 
\begin_inset Formula $\alpha_{i},b_{i}$
\end_inset

 and 
\begin_inset Formula $w_{ij}\in\mathbb{R}$
\end_inset

 where 
\begin_inset Formula $i=1,...,m_{1}$
\end_inset

 and 
\begin_inset Formula $j=1,...,m_{0}$
\end_inset

 such that we may define
\begin_inset Formula 
\[
F\left(x\right)=\sum_{i=1}^{m_{1}}\alpha_{i}\cdot\varphi\left(\sum_{j=1}^{m_{0}}w_{ij}\cdot x_{j}+b_{i}\right)
\]

\end_inset

 as an approximate realization of the function 
\begin_inset Formula $f$
\end_inset

, that is
\begin_inset Formula 
\[
\left|F\left(x\right)-f\left(x\right)\right|<\varepsilon,\forall x\in I_{m}.
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This theorem is very relevant, because it says that for any mapping function
 
\begin_inset Formula $f$
\end_inset

 in supervised learning, there exists a MLP with 
\begin_inset Formula $m_{1}$
\end_inset

 neurons in the hidden layer which is able to approximate it with a desired
 precision.
\end_layout

\begin_layout Standard
However, it only proves the existence of a shallow (just one hidden layer)
 MLP with 
\begin_inset Formula $m_{1}$
\end_inset

 neurons in the hidden layer that can approximate the function, but it does
 not tell how to find this number.
\end_layout

\begin_layout Standard
As a rule of thumb for the generalization error, it is
\begin_inset Formula 
\[
\varepsilon=\frac{VC_{dim}\left(MLP\right)}{N},
\]

\end_inset

 where 
\begin_inset Formula $VC_{dim}$
\end_inset

 is the Vapnik-Chervonenkis dimension, a measure of the capacity of a model.
 It refers to the largest set of points that the model can shatter.
 It is not easy to compute, but a rough upper bound for a FFNN is 
\begin_inset Formula $O\left(W\log W\right)$
\end_inset

, with 
\begin_inset Formula $W$
\end_inset

 being the total number of weight in the network.
\end_layout

\begin_layout Standard
Also, this theorem hints us that having more neurons in the hidden layers
 will give us better training error, but worse generalization error: overfitting.
\end_layout

\begin_layout Standard
However, for most functions 
\begin_inset Formula $m_{1}$
\end_inset

 is very high, and becomes quickly computationally intractable: so we need
 to go deeper.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
No Free Lunch Theorem
\end_layout

\begin_layout Theorem
Multiple informal formulations:
\end_layout

\begin_deeper
\begin_layout Itemize
For every learning algorithm A and B, there are as many problems where A
 has a better generalization error than problems where B has a better one.
\end_layout

\begin_layout Itemize
All learning algorithms ahve the same generalization error if we average
 over all learning problems.
\end_layout

\begin_layout Itemize
There is no universally better learning algorithm.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Plain Layout

\series bold
Depth Property
\end_layout

\begin_layout Plain Layout
The number of polygonal regions generated by a MLP with a ReLU function,
 
\begin_inset Formula $d$
\end_inset

 inputs, 
\begin_inset Formula $n$
\end_inset

 neurons per hidden layer and 
\begin_inset Formula $l$
\end_inset

 layers is
\begin_inset Formula 
\[
O\left(\binom{n}{d}^{d\left(l-1\right)}n^{d}\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This number grows exponentially with depth.
 This means that adding depth basically allows for more transformations
 of the input space.
\end_layout

\begin_layout Subsection
Gradient-based Learning
\end_layout

\begin_layout Standard
The 
\series bold
gradient
\series default
 of a function 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$
\end_inset

, is 
\begin_inset Formula $\nabla f:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$
\end_inset

, defined at the point 
\begin_inset Formula $p=\left(x_{1},...,x_{n}\right)$
\end_inset

 as
\begin_inset Formula 
\[
\nabla f\left(p\right)=\left(\begin{array}{c}
\frac{\partial f}{\partial x_{1}}\left(p\right)\\
\vdots\\
\frac{\partial f}{\partial x_{n}}\left(p\right)
\end{array}\right).
\]

\end_inset

 This is, it's the local derivative or slope of each dimension at a certain
 point.
\end_layout

\begin_layout Standard
Going in the opposite direction of the gradient is a naïve but practical
 guess of the direction of the local minimum.
 This is the base for the gradient descent method.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Plain Layout

\series bold
Gradient-descent method 
\series default
(Cauchy, 1847)
\end_layout

\begin_layout Plain Layout
A parametric function 
\begin_inset Formula $f\left(\theta\right)$
\end_inset

 can be iteratively minimized by following the opposite direction of the
 gradient:
\begin_inset Formula 
\[
\theta_{t+1}=\theta_{t}-\varepsilon\nabla_{\theta}f\left(\theta\right),
\]

\end_inset

 where 
\begin_inset Formula $\varepsilon>0$
\end_inset

 is the 
\series bold
learning rate
\series default
.
\end_layout

\begin_layout Plain Layout
We stop iterating when the gradient is near to 0.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Notice that this is useless if we have a close form for the gradient! In
 that case it is easier to just minimize it.
 This is useful when this is not the case, which always happens for neural
 networks.
\end_layout

\begin_layout Standard
In addition, there are variations to the method, for example, we can vary
 
\begin_inset Formula $\varepsilon$
\end_inset

 during training.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Plain Layout

\series bold
Stochastic gradient descent
\end_layout

\begin_layout Plain Layout
Given a cost function 
\begin_inset Formula $f\left(\theta\right)$
\end_inset

, parameters of the network are updated with
\begin_inset Formula 
\[
\theta\leftarrow\theta-\varepsilon\nabla_{\theta}f\left(\theta\right).
\]

\end_inset


\end_layout

\begin_layout Plain Layout
For the negative log-likelihood (MLE), the function is:
\begin_inset Formula 
\[
f\left(\theta\right)=\frac{1}{m}\sum_{i=1}^{m}L\left(x^{\left(i\right)},y^{\left(i\right)},\theta\right),
\]

\end_inset

 so the estimated gradient is
\begin_inset Formula 
\[
\nabla_{\theta}f\left(\theta\right)=\frac{1}{m}\sum_{i=1}^{m}\nabla_{\theta}L\left(x^{\left(i\right)},y^{\left(i\right)},\theta\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The 
\color red
problem
\color inherit
 with this approach is that to take a single step of gradient descent, we
 must compute the loss over the whole dataset everytime, making the method
 not scalable at all.
 This is called 
\series bold
batch gradient descent
\series default
.
\end_layout

\begin_layout Standard
One 
\color lime
solution
\color inherit
 is to compute the gradient with 1 sample only at each step, which is very
 noisy and inefficient, but works.
 This is the 
\series bold
stochastic gradient descent
\series default
.
\end_layout

\begin_layout Standard
In the middle ground, we find the 
\series bold
mini-batch gradient descent
\series default
, which divides the dataset into subsets, and updates the parameters after
 processing each of these subsets.
 A batch is a collection is a collection of samples used at each iteration
 for performing SDG in DL.
 A bigger batch provides a better gradient estimation, and therefore a faster
 learning, but also implies more device memory and slower descent.
\end_layout

\begin_layout Standard
Therefore, there is a tradeoff between money and performance at companies.
 In practice, a batch is set between 1 to 256 on one GPU.
\end_layout

\begin_layout Standard
But there is an even 
\series bold
\color red
greater problem
\series default
\color inherit
, the computation of the gradient is computationally very costly.
 To go around this problem, 
\series bold
back-propagation
\series default
 was invented, as an efficient technique for gradient computation.
 
\end_layout

\begin_layout Subsubsection
Back-propagation
\end_layout

\begin_layout Standard
The back-propagation algorithm is based on the chain rule for the derivative
 of composite functions: if we have 
\begin_inset Formula $y=g\left(x\right)$
\end_inset

 and 
\begin_inset Formula $z=f\left(y\right)=f\left(g\left(x\right)\right)=\left(f\circ g\right)\left(x\right)$
\end_inset

, then
\begin_inset Formula 
\[
\frac{df}{dx}\left(x\right)=f'\left(g\left(x\right)\right)g'\left(x\right),
\]

\end_inset

 or, abusing notation, 
\begin_inset Formula 
\[
\frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}.
\]

\end_inset

 This is generalized to multivariate funtions as follows: let 
\begin_inset Formula $x\in\mathbb{R}^{m},y\in\mathbb{R}^{n},g:\mathbb{R}^{m}\rightarrow\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $f:\mathbb{R}^{n}\rightarrow\mathbb{R}$
\end_inset

.
 If 
\begin_inset Formula $z=f\left(y\right)=f\left(g\left(x\right)\right)$
\end_inset

, then
\begin_inset Formula 
\[
\frac{\partial z}{\partial x_{i}}\left(x\right)=\sum_{j}\frac{\partial z}{\partial y_{j}}\frac{\partial y_{j}}{\partial x_{i}},
\]

\end_inset

 or, 
\begin_inset Formula 
\[
\nabla_{x}z=\left(\frac{\partial y}{\partial x}\right)^{T}\nabla_{y}z,
\]

\end_inset

 where 
\begin_inset Formula $\left(\frac{\partial y}{\partial x}\right)$
\end_inset

 is the Jacobian of 
\begin_inset Formula $g$
\end_inset

.
\end_layout

\begin_layout Standard
Now, back-propagation is a recursive application of the chain rule, starting
 from the cost function.
 The algorithm works as follows:
\end_layout

\begin_layout Enumerate

\series bold
Forward pass
\series default
: a feedforward network takes as input 
\begin_inset Formula $x$
\end_inset

 and produces the output 
\begin_inset Formula $\hat{y}$
\end_inset

.
 The information flows from layer to layer.
\end_layout

\begin_layout Enumerate

\series bold
Cost function
\series default
: compute the error between expected output and actual output.
\end_layout

\begin_layout Enumerate

\series bold
Back-propagate
\series default
: evaluate the individual gradient of each parameter and propagates them
 backwards to update them.
 For this, we use the concept of 
\series bold
local derivative
\series default
: the derivative of connected nodes are computed locally on the edges of
 the graph.
 For non-connected nodes, we multiply the edges connected between the nodes,
 and we sum over all incoming edges.
\end_layout

\begin_layout Standard
If we do this in a forward way, summing over all paths becomes intractable
 pretty quickly, while when doing it in a backwards way, it allows to obtain
 the derivative of the output with respect to every node directly in one
 pass.
 This leads to massive parallelization.
\end_layout

\begin_layout Standard
I did a more detailed explanation, with visualizations in my previous notes,
 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://lorenc1o.github.io/BDMA_Notes/universities/UPC/Machine_Learning_summary.pdf
\end_layout

\end_inset

.
\end_layout

\begin_layout Section
Deep Neural Networks: Optimization and Regularization
\end_layout

\begin_layout Subsection
Optimization
\end_layout

\begin_layout Standard
Recall that neural networks learn by optimizing a cost function, 
\begin_inset Formula $J\left(\theta\right)$
\end_inset

.
 This optimization is, in practice, performed by gradient descent, so we
 must be able to compute 
\begin_inset Formula $\nabla_{\theta}J\left(\theta\right)$
\end_inset

.
 The 
\color red
problem
\color inherit
 is that this is computationally very costly.
 However, we have seen how back-propagation is an efficient gradient computation
 technique.
\end_layout

\begin_layout Standard
Now, learning is related to what we want to optimize, since we are interested
 in the performance on the test set, which is not always possible to ensure.
 Therefore, what is done is minimizing a cost function, 
\begin_inset Formula $J$
\end_inset

, hoping that it will improve the performance in the test set.
 But this relationship is also what makes learning and optimizing two different
 things! In pure optimization, our objective is minimizing 
\begin_inset Formula $J$
\end_inset

, while in learning, the objective is the ability to 
\series bold
generalize
\series default
, or perform well on the test set.
 Optimizing 
\begin_inset Formula $J$
\end_inset

 on the training set does not ensure a good generalization, and sometimes
 worse results regarding the pure optimization problem in the training set,
 can yield better results in the learning problem (think about the overfitting
 problem).
\end_layout

\begin_layout Standard
Therefore, optimization is a crucial part of learning, and gradient-descent
 is a 
\begin_inset Quotes eld
\end_inset

cheap
\begin_inset Quotes erd
\end_inset

 optimization technique.
 However, it is not exempt of problems:
\end_layout

\begin_layout Itemize
Local minima and saddle points: small gradients can stop or greatly slow
 down the method.
\end_layout

\begin_layout Itemize
Partial estimation of gradients slows down descent, but can be beneficial
 for generalization.
 This refers to computing the gradient in batches, instead of in the full
 dataset (as we saw).
\end_layout

\begin_layout Standard
In addition, there are problems that are specific to the kind of functions
 that arise when working with neural networks:
\end_layout

\begin_layout Itemize
Bad convergence: due to the existence of many local optima.
\end_layout

\begin_layout Itemize
Long training time: the speed of stochastic gradient descent depends on
 initialization.
\end_layout

\begin_layout Itemize
Overfitting: deep neural networks have a lot of free parameters.
 They can sometimes learn by heart the whole training set, losing the ability
 to generalize.
\end_layout

\begin_layout Itemize
Vanishing gradients: in the backpropagation scheme, the first layers of
 the network may not receive sufficiently large gradients early in training.
\end_layout

\begin_layout Standard
There are different techniques to address these problems.
 Let's see some of them.
\end_layout

\begin_layout Subsubsection
Solving Bad Convergence
\end_layout

\begin_layout Standard
It's important to stabilize and improve the convergence of gradient descent
 on DNNs, and for this we need good optimization techniques.
\end_layout

\begin_layout Paragraph
Gradient Clipping
\end_layout

\begin_layout Standard
Gradient Clipping proposes to clip the gradient norm to a threshold 
\begin_inset Formula $v$
\end_inset

, so:
\end_layout

\begin_layout Enumerate
Compute the gradient, say 
\begin_inset Formula $g$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $\left\Vert g\right\Vert >th$
\end_inset

, then 
\begin_inset Formula 
\[
g\leftarrow\frac{g\cdot th}{\left\Vert g\right\Vert },
\]

\end_inset

 where 
\begin_inset Formula $th$
\end_inset

 is a threshold to the maximum admissible gradient norm.
\end_layout

\begin_layout Standard
This way, we keep the direction of the gradient, while preventing 
\emph on
overshooting
\emph default
, i.e., taking too large steps.
 Although this introduces a bias in the optimization process, it works well
 in practice.
\end_layout

\begin_layout Standard
A visualization is the following:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado11.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Here, we can observe how if we don't clip, the gradient is too large and
 we miss the minimum at the right, while clipping enables us to get ther
 easily.
\end_layout

\begin_layout Paragraph
Gradient with Momentum
\end_layout

\begin_layout Standard
Momentum represents an acceleration method for stochastic gradient descent.
 The idea is to smooth gradient steps with some momentum or inertia, using
 previous gradient steps as a 
\begin_inset Quotes eld
\end_inset


\emph on
memory
\emph default

\begin_inset Quotes erd
\end_inset

 of the direction.
\end_layout

\begin_layout Standard
Let's call the gradient at step 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $G^{t}\left(\theta\right)$
\end_inset

, then we define the velocity, 
\begin_inset Formula $v^{t}\left(\theta\right)$
\end_inset

, as
\begin_inset Formula 
\[
v^{t}\left(\theta\right)=\alpha v^{t-1}\left(\theta\right)-\left(1-\alpha\right)G^{t}\left(\theta\right),
\]

\end_inset

 where 
\begin_inset Formula $0\leq\alpha<1$
\end_inset

 is a parameter controlling how much of the gradient we use for the parameter
 update, usually set as 0.9.
 If it is set to 0, we obtain the vanilla SGD.
\end_layout

\begin_layout Standard
The updates are done as
\begin_inset Formula 
\[
\theta^{t+1}=\theta^{t}-\eta v^{t}\left(\theta\right),
\]

\end_inset

 where 
\begin_inset Formula $\eta$
\end_inset

 is the learning rate.
\end_layout

\begin_layout Standard
The momentum approach is shown below, observing a slight speedup.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado15.png
	scale 60

\end_inset


\end_layout

\begin_layout Paragraph
Nesterov Momentum
\end_layout

\begin_layout Standard
This represents a variant of gradient descent with momentum.
 It tries to address the problem of the momentum approach, which is that
 is tends to oscillate around the minimum.
 Nesterov corrects these oscillations by estimating the gradient after the
 momentum update as:
\begin_inset Formula 
\[
v^{t}\left(\theta\right)=\alpha v^{t-1}\left(\theta\right)-\left(1-\alpha\right)G\left(\theta-\alpha v^{t-1}\left(\theta\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename pegado16.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
We can observe how the oscillations are less prominent.
 If the function was different and momentum oscillates around the minimum,
 Nesterov would help with this.
\end_layout

\begin_layout Paragraph
Dynamic Learning Rate
\end_layout

\begin_layout Standard
Stochastic gradient descent estimates the gradient with only one sample,
 and iterates over the whole dataset, as
\begin_inset Formula 
\[
\theta\leftarrow\theta-\eta G\left(\theta;x^{i},y^{i}\right).
\]

\end_inset

 It is common to use minibatches instead:
\begin_inset Formula 
\[
\theta\leftarrow\theta-\eta G\left(\theta;x^{i_{0}:i_{0}+B},y^{i_{0}:i_{0}+B}\right)=\theta-\eta\nabla_{\theta}\sum_{i=i_{0}}^{i_{0}+B}L\left(\theta;x^{i},y^{i}\right).
\]

\end_inset

 The learning rate is very important, and in fact it should decrease during
 training, as we get closer to the optimum.
 Some reasons to make this decrease are:
\end_layout

\begin_layout Itemize
True gradients becomes small when 
\begin_inset Formula $\theta$
\end_inset

 is close to the minimum.
\end_layout

\begin_layout Itemize
With SGD, estimating the gradient with samples introduces noise, and these
 gradients don't necessarily decrease.
\end_layout

\begin_layout Itemize
A sufficient condition for convergence of SGD is:
\begin_inset Formula 
\[
\sum_{k=1}^{\infty}\eta_{k}=\infty,\ and\ \sum_{k=1}^{\infty}\eta_{k}^{2}<\infty.
\]

\end_inset


\end_layout

\begin_layout Standard
In practice, what we do is apply a linear decay until some point 
\begin_inset Formula $\tau$
\end_inset

, and keep it constant after this point:
\begin_inset Formula 
\[
\eta_{k}=\left(1-\frac{k}{\tau}\right)\eta_{0}+\frac{k}{\tau}\eta_{\tau},
\]

\end_inset

 and 
\begin_inset Formula $\eta_{\tau}$
\end_inset

 after 
\begin_inset Formula $\tau$
\end_inset

 iterations.
\end_layout

\begin_layout Standard
Now, the question is, how to choose 
\begin_inset Formula $\eta_{0},\eta_{\tau}$
\end_inset

 and 
\begin_inset Formula $\tau$
\end_inset

? There are several options:
\end_layout

\begin_layout Itemize
With trail and error (using train/validation sets).
\end_layout

\begin_layout Itemize
It's better to monitor the loss function during training.
\end_layout

\begin_layout Itemize
A practical choice:
\end_layout

\begin_deeper
\begin_layout Itemize
Choose 
\begin_inset Formula $\tau$
\end_inset

 so that the whole training dataset is seen around 100 times.
\end_layout

\begin_layout Itemize
Choose 
\begin_inset Formula $\eta_{\tau}$
\end_inset

 around 1% of 
\begin_inset Formula $\eta_{0}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\eta_{0}$
\end_inset

 comes with experience:
\end_layout

\begin_deeper
\begin_layout Itemize
Too big: big variations in loss
\end_layout

\begin_layout Itemize
Too small: learning is slow, we can get stuck in a plateau
\end_layout

\end_deeper
\begin_layout Itemize
Recipe:
\end_layout

\begin_deeper
\begin_layout Itemize
Try multiple 
\begin_inset Formula $\eta_{0}$
\end_inset

 over 100 iterations
\end_layout

\begin_layout Itemize
Pick 
\begin_inset Formula $\eta_{0}$
\end_inset

 slightly higher than the best
\end_layout

\end_deeper
\end_deeper
\begin_layout Paragraph
Cyclical Learning Rate
\end_layout

\begin_layout Standard
Optimization difficulties comes more from plateaus than from bad local optima,
 and increasing 
\begin_inset Formula $\eta$
\end_inset

 allows to go across these plateaus.
 For this, what is done is varying the learning rate in a cyclical manner,
 from a minimum bound, 
\begin_inset Formula $\eta_{min}$
\end_inset

 to a maximum bound, 
\begin_inset Formula $\eta_{max}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Super Convergence with One-Cycle Policy
\end_layout

\begin_layout Standard
Only once cycle works as:
\end_layout

\begin_layout Itemize
Start with a small learning rate to begin convergence.
\end_layout

\begin_layout Itemize
Increases and then stabilizes to high value, to cross big plateaus.
\end_layout

\begin_layout Itemize
Decreases to a small value, to optimize local minima.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado17.png

\end_inset


\end_layout

\begin_layout Paragraph
SGD with Adaptive Learning Rates
\end_layout

\begin_layout Standard
Preconditioning:
\begin_inset Formula 
\[
\theta^{t+1}\leftarrow\theta^{t}-\eta_{t}P_{t}^{-1}G\left(\theta^{t}\right),
\]

\end_inset

 where 
\begin_inset Formula $P_{t}$
\end_inset

 can be defined in different ways.
 Let's see AdaGrad and RMSProp.
\end_layout

\begin_layout Standard

\series bold
AdaGrad
\series default
: parameters with largest partial derivatives should have a rapid decrease.
\begin_inset Formula 
\[
P_{t}=\left[diag\left(\sum_{j=0}^{t}G\left(\theta^{t}\right)G\left(\theta^{t}\right)^{T}\right)\right]^{\frac{1}{2}}.
\]

\end_inset

 More precisely:
\begin_inset Formula 
\[
\begin{cases}
g^{t}\leftarrow G\left(\theta^{t}\right)\\
r^{t}\leftarrow r^{t-1}+g^{t}\odot g^{t}\\
\theta^{t+1}\leftarrow\theta^{t}-\frac{\lambda}{\delta+\sqrt{r^{t}}}\odot g^{t}
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
AdaGrad converges quickly on convex problems.
 However, keeping all the history with momentum can be detrimentary, and
 smoothing the gradient destroys information.
 
\end_layout

\begin_layout Standard
RMSProp: introduces momentum when computing the precondicioner.
 The idea is to adapt the learning rate to the curvature of the loss function,
 putting the brakes on when the function is steep and accelerating when
 the loss function is flat.
\begin_inset Formula 
\[
P_{t}=\left[diag\left(\alpha P_{t-1}+\sum_{j=0}^{t}G\left(\theta^{t}\right)G\left(\theta^{t}\right)^{T}\right)\right]^{\frac{1}{2}}.
\]

\end_inset


\end_layout

\begin_layout Paragraph
More precisely:
\begin_inset Formula 
\begin{align*}
v^{t}\left(\theta\right) & =\alpha v^{t-1}\left(\theta\right)+\left(1-\alpha\right)G\left(\theta\right)^{2}\\
\theta^{t+1} & =\theta^{t}-\frac{\eta}{\epsilon+\sqrt{v^{t}\left(\theta\right)}}G\left(\theta\right).
\end{align*}

\end_inset

 Adam
\end_layout

\begin_layout Standard
Adam (Adaptative Moment Estimation) builds on RMSProp, but also uses a moving
 average of the gradients.
 It works as:
\begin_inset Formula 
\begin{align*}
m^{t}\left(\theta\right) & =\beta_{1}m^{t-1}\left(\theta\right)+\left(1-\beta_{1}\right)G\left(\theta\right)\\
v^{t}\left(\theta\right) & =\beta_{2}v^{t-1}\left(\theta\right)+\left(1-\beta_{2}\right)G\left(\theta\right)^{2}\\
\theta^{t+1} & =\theta^{t}-\eta\frac{m\left(\theta\right)}{\epsilon+\sqrt{v\left(\theta\right)}}.
\end{align*}

\end_inset

 In practice, Adam is the most used optimizer.
 However, there are more efficient algorithm, like LARS (Layerwise Adaptive
 Rate Scaling) or LAMB (LARS+Adam).
\end_layout

\begin_layout Paragraph
Comparison
\end_layout

\begin_layout Itemize
SGD momentum should allow for better solution, but hyperparameters are harder
 to find.
\end_layout

\begin_layout Itemize
Adam is easier to tune.
\end_layout

\begin_layout Subsection
Initialization and Normalization
\end_layout

\begin_layout Standard
The parameters of a deep learning model need initial values.
 The assignation of initial values is called 
\series bold
initialization
\series default
, and can impact the optimization process in several ways:
\end_layout

\begin_layout Itemize
A bad initialization can make the training process not to converge.
\end_layout

\begin_layout Itemize
It can impact the convergence quality, in terms of speed and the value reached.
\end_layout

\begin_layout Itemize
Also, it can impact the generalization error.
\end_layout

\begin_layout Standard
Therefore, a difficult question arises: initial parameters can help optimization
, but can detriment the generalization error.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Plain Layout

\series bold
Principle: Break Symmetries
\end_layout

\begin_layout Plain Layout
Two identical parameters, connected to the same input, should be initialized
 differently, to incentivize different learning.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
One option could be to initialize everything to 0, but this is not a good
 choice, because it disentivizes learning.
 Instead, there are different initialization schemes, like random initialization.
\end_layout

\begin_layout Subsubsection
Random Initialization
\end_layout

\begin_layout Standard
Random initialization uses a probability distribution to initialize the
 weights.
 For example, 
\series bold
Xavier initialization
\series default
 uses an uniform distribution as
\begin_inset Formula 
\[
W_{i,j}\sim U\left(-\frac{\sqrt{6}}{\sqrt{n_{i}+n_{i+1}}},\frac{\sqrt{6}}{\sqrt{n_{i}+n_{i+1}}}\right),
\]

\end_inset

 where 
\begin_inset Formula $n_{j}$
\end_inset

 is the number of neurons in layer 
\begin_inset Formula $j=1,...,N$
\end_inset

.
 The input layer is initialized as
\begin_inset Formula 
\[
W_{0,j}\sim\mathcal{N}\left(0,\sqrt{\frac{2}{n_{1}}}\right).
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Input normalization
\end_layout

\begin_layout Standard
Gradient descent is sensitive to strong variations in the input, and, ideally,
 the surface of the loss function should ahve a uniform curvature in all
 directions, similar to a sphere.
 This can be incentivized by input normalization, i.e., normalizing all input
 parameters so that they all lie in a similar value range.
\end_layout

\begin_layout Standard
Moreover, there is the concept of 
\series bold
batch normalization
\series default
, or adaptive reparametrization.
 This consists in normalizing the input of each layer of a neural network.
 It is motivated by the following:
\end_layout

\begin_layout Itemize
Deep neural networks are compositions of functions, whose parameters are
 iteratively updated during training.
\end_layout

\begin_layout Itemize
The updates are done simultaneously to all layers, and unexpected effects
 can come into play, since each layer is updated assuming all other layers
 remain constant.
\end_layout

\begin_layout Itemize
Therefore, the updates to other layers can add high order effects that can
 lead to the problem of 
\series bold
gradient explosion
\series default
, a situation in which the gradient keeps growing indefinitely.
\end_layout

\begin_layout Standard
In this case, the idea is to normalize the distribution of each input feature
 in each layer, across each minibatch, to a normal, 
\begin_inset Formula $\mathcal{N}\left(0,1\right)$
\end_inset

:
\begin_inset Formula 
\begin{align*}
\mu & \leftarrow\frac{1}{m}\sum_{i=1}^{m}\overline{x}^{i},\\
\sigma^{2} & \leftarrow\frac{1}{m}\sum_{i=1}^{m}\left(\overline{x}^{i}-\mu\right)^{2},\\
\overline{x}^{i} & \leftarrow\frac{\overline{x}^{i}-\mu}{\sqrt{\sigma^{2}-\varepsilon}}.
\end{align*}

\end_inset

 Remember that 
\begin_inset Formula $\varepsilon$
\end_inset

 is the approximation of the generalization error, 
\begin_inset Formula $\varepsilon=\frac{VC_{dim}}{N}$
\end_inset

.
\end_layout

\begin_layout Subsection
Regularization
\end_layout

\begin_layout Standard
The loss function can be small on the training data, but large on the dataset.
 This is the overfitting problem, that we have seen before.
 Deep NN can tend to overfit, since more depth implies more free parameters,
 and therefore a higher VC dimension, which can increase 
\begin_inset Formula $\varepsilon$
\end_inset

 according the rule of thumb for its approximation.
 
\end_layout

\begin_layout Standard
A way to go around this is to put constraints on the weights, to reduce
 the VC dimension.
 This can be done through regularization.
\end_layout

\begin_layout Subsubsection
\begin_inset Formula $\mathcal{L}_{2}$
\end_inset

 Regularization (or Ridge)
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathcal{L}_{2}$
\end_inset

 regularization keeps the 
\begin_inset Formula $\mathcal{L}_{2}$
\end_inset

 norm of the free patameters, 
\begin_inset Formula $\left\Vert \theta\right\Vert $
\end_inset

, as small as possible, during learning.
\end_layout

\begin_layout Standard
The intuition is that each neuron will use all its inputs with small weights,
 instead of specializing on a small part with high weights.
\end_layout

\begin_layout Standard
To accomplish this, we have to minimize two things at the same time: the
 training loss and a penanlty term representing the norm of the weights:
\begin_inset Formula 
\[
\mathcal{J}\left(\theta\right)=\mathbb{E}_{D}\left[\left\Vert t-y\right\Vert ^{2}\right]+\lambda\left\Vert \theta\right\Vert ^{2},
\]

\end_inset

 where 
\begin_inset Formula $\lambda$
\end_inset

 is the 
\series bold
regularization parameter
\series default
, controlling the strength of the regularization:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $\lambda$
\end_inset

 is small, there is only a small regularization, allowing higher weights.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $\lambda$
\end_inset

 is high, the weights will be kept very small, but they may not minimize
 the training loss.
\end_layout

\begin_layout Standard
The gradient of this new loss function is
\begin_inset Formula 
\[
\nabla_{\theta}\mathcal{J}\left(\theta\right)=-2\left(t-y\right)\nabla_{\theta}y+2\lambda\theta,
\]

\end_inset

 and so the parameter updates become
\begin_inset Formula 
\[
\Delta\theta=\eta\left(t-y\right)\nabla_{\theta}y-\eta\lambda\theta.
\]

\end_inset

 The 
\begin_inset Formula $\mathcal{L}_{2}$
\end_inset

 regularization leads to weights decay: even if there is no output error,
 the weight will converge to 0, forcing the weights to constatly learn,
 and disincentivizing the specialization on particular examples (overfitting),
 enhancing generalization.
\end_layout

\begin_layout Subsubsection
\begin_inset Formula $\mathcal{L}_{1}$
\end_inset

 regularization (or Lasso)
\end_layout

\begin_layout Standard
In this case, we penalize the absolute value of the weights, instead of
 their euclidean norm:
\begin_inset Formula 
\[
\mathcal{J}\left(\theta\right)=\mathbb{E}_{D}\left[\left\Vert t-y\right\Vert ^{2}\right]+\lambda\left\Vert \theta\right\Vert _{1}.
\]

\end_inset

 This method leads to very sparse representations, where a lot of neurons
 may be inactive, and only a few represent the input.
\end_layout

\begin_layout Subsubsection
Early Stopping
\end_layout

\begin_layout Standard
During training, a common behavior is the following:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado18.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
It's usual that the training error decreases constantly, while the validation
 error decreases, and the increases again.
 If we manage to find the optimal point in this process, we can stop earlier
 the training process, before the validation error gets larger.
\end_layout

\begin_layout Standard
This method is equivalent to 
\begin_inset Formula $\mathcal{L}_{2}$
\end_inset

 normalization, both limiting the capacity of the model:
\end_layout

\begin_layout Itemize
With Ridge regularization, small slope regions contract the dimension of
 
\begin_inset Formula $\theta$
\end_inset

, which decays to 0, and high slope regions are not regularized because
 they help descent.
\end_layout

\begin_layout Itemize
With early stopping, parameters with high slope are learned before parameters
 with low slope.
\end_layout

\begin_layout Subsubsection
Dropout
\end_layout

\begin_layout Standard
Dropout considers all the networks can be formed by removing some units
 from a network.
 With this in mind, the method consists of:
\end_layout

\begin_layout Itemize
At each optimization iteration: we apply random binary masks on the units
 to consider.
\end_layout

\begin_layout Standard
The probability of dropout, 
\begin_inset Formula $p$
\end_inset

, is a hyperparameter.
 Therefore, what we do at training time is, at each step, deactivate some
 neurons, randomly.
 This incentivizes generalization, since relying on some neurons specializing
 a lot for some features of the training data is harder if these neurons
 are not always available.
 
\end_layout

\begin_layout Standard
Note that, at inference time, all neurons are always available.
\end_layout

\begin_layout Subsubsection
Data Augmentation
\end_layout

\begin_layout Standard
The best way to avoid overfitting is collecting more data, but this can
 be hard, costly, or simply impossible.
 A simple trick is 
\series bold
data augmentation
\series default
, which consists in creating new varied data from the current data by perturbing
 it, while not chaning the labels associated to it.
\end_layout

\begin_layout Standard
For example:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado19.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Mixup
\series default
 is a particular case of data augmentation, consisting on creating new training
 new samples with labels by interpolation:
\begin_inset Formula 
\begin{align*}
\hat{x} & =\lambda x_{i}+\left(1-\lambda\right)x_{j},\\
\hat{y} & =\lambda y_{i}+\left(1-\lambda\right)y_{j},
\end{align*}

\end_inset

 where 
\begin_inset Formula $\lambda\sim Beta\left(\alpha,\alpha\right)$
\end_inset

, with 
\begin_inset Formula $\alpha\in\left[0.1,0.4\right]$
\end_inset

 for classification tasks.
 This method works for structured data, and can be used to stabilizing GANs
 (we will see this later).
\end_layout

\begin_layout Subsection
Vanishing Gradients
\end_layout

\begin_layout Standard
Contrary to what we could think, adding more layers to a DNN does not necessaril
y lead to better performance, both on the training and test set.
 For instance, see the following graph, where we observe the performance
 of a 20 layers NN (left) and a 56 layers NN (right):
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado20.png

\end_inset


\end_layout

\begin_layout Standard
We observe how its performance is worse in all senses.
 The main reason for this is the 
\series bold
vanishing gradient problem
\series default
.
 The gradient of the loss function is repeatedly multiplied by a weight
 matrix 
\begin_inset Formula $W$
\end_inset

 as it travels backwards in a deep NN, as
\begin_inset Formula 
\[
\frac{\partial h_{k}}{\partial h_{k-1}}=f'\left(W^{k}h_{k-1}+b^{k}\right)W^{k}.
\]

\end_inset

 When the gradient arrives to the first layer, the contribution of the weight
 matrices is comprised between 
\begin_inset Formula $W_{min}^{d},$
\end_inset

 and 
\begin_inset Formula $W_{max}^{d}$
\end_inset

, which are the weight matrix with the highest and lowest norm, and 
\begin_inset Formula $d$
\end_inset

 is the depth of the network.
 We find:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $\left|W_{max}\right|<1$
\end_inset

, then 
\begin_inset Formula $W_{max}^{d}$
\end_inset

 is very small for high values of 
\begin_inset Formula $d$
\end_inset

, and the gradient vanishes.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $\left|W_{min}\right|>1$
\end_inset

, then 
\begin_inset Formula $W_{min}^{d}$
\end_inset

 is very high for high values of 
\begin_inset Formula $d$
\end_inset

, and the gradient explodes.
\end_layout

\begin_layout Standard
We saw that exploding gradients can be solved by gradient clipping.
 But vanishing gradients are still the current limitation of deep NN.
 The solutions include the utilization of ReLU activaiton functions, unsupervise
d pre-training, batch normalization, residual networks, etc.
\end_layout

\begin_layout Subsubsection
Residual network
\end_layout

\begin_layout Standard
A Residual Neural Network, or 
\series bold
ResNet
\series default
, is an advanced type of neural network that is specifically designed to
 help improve the performance of deep learning models.
\end_layout

\begin_layout Standard
ResNet introduces the concept of residual learning.
 Instead of expecting each stack of layers to directly fit a desired underlying
 mapping, ResNet layers are designed to fit a residual mapping.
 The key component of ResNet is the introduction of "skip connections" or
 "shortcuts" that bypass one or more layers.
 A skip connection in a ResNet allows the gradient to be directly backpropagated
 to earlier layers.
\end_layout

\begin_layout Standard
These skip connections perform identity mapping, and their outputs are added
 to the outputs of the stacked layers.
 This design helps in training deeper networks by mitigating the vanishing
 gradient problem.
 With residual blocks, the network learns the additive residual function
 with respect to the layer inputs, making it easier to optimize and gain
 accuracy from considerably deeper networks.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado21.png

\end_inset


\end_layout

\begin_layout Subsubsection
Stochastic Depth
\end_layout

\begin_layout Standard
Stochastic depth is a training technique for deep neural networks, particularly
 effective for very deep networks like ResNets.
 It was introduced as a solution to the problem of vanishing gradients and
 long training times in deep networks.
\end_layout

\begin_layout Standard
During training, stochastic depth randomly drops layers in the network.
 The idea is similar to dropout, where random neurons are turned off during
 training to prevent overfitting.
 In stochastic depth, however, it's entire layers that are dropped.
\end_layout

\begin_layout Standard
Each training iteration uses a shallower version of the network.
 The depth of the network varies each time, as different subsets of layers
 are randomly deactivated.
\end_layout

\begin_layout Standard
Notice how stochastic depth is particularly useful for ResNets, where skip
 connections (or residual connections) are a key feature.
 When a residual block is dropped, the skip connection effectively takes
 its place, allowing the signal to still propagate forward.
\end_layout

\begin_layout Standard
At test time, all layers are used, but their outputs are scaled appropriately
 to compensate for the dropout during training.
 This ensures that the network can benefit from its full depth during inference.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado22.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsection
Double Descent
\end_layout

\begin_layout Standard
Double descent is a phenomenon observed in the training of machine learning
 models, particularly in relation to the model's complexity and its performance
 on a given task.
 This concept challenges the traditional understanding of the bias-variance
 tradeoff and has gained attention in the field of machine learning and
 statistics.
\end_layout

\begin_layout Standard
The double descent curve shows that after the point where the model starts
 to overfit (as per the traditional U-shaped bias-variance tradeoff curve),
 increasing the model complexity even further can lead to a decrease in
 the total error again.
\end_layout

\begin_layout Standard
It shows the following phases:
\end_layout

\begin_layout Itemize

\series bold
Underparameterized Regime
\series default
: Where the model has too few parameters and underfits the data.
 Here, increasing complexity reduces bias and total error.
 
\end_layout

\begin_layout Itemize

\series bold
Interpolation Threshold
\series default
: At this point, the model just starts to fit all the training data perfectly
 (including noise), leading to high variance and total error.
 
\end_layout

\begin_layout Itemize

\series bold
Overparameterized Regime
\series default
: Beyond this threshold, as complexity continues to increase, the model
 enters the second descent where surprisingly, the total error begins to
 decrease again despite the model being overparameterized.
\end_layout

\begin_layout Standard
The double descent phenomenon is especially noticeable in scenarios with
 limited training data.
 With more data, the peak of the curve (at the interpolation threshold)
 becomes less pronounced.
\end_layout

\begin_layout Standard
Double descent suggests that in some cases, choosing an even more complex
 model after hitting the overfitting point can improve performance.
\end_layout

\begin_layout Standard
For example, observe this phenomenon in the following graphs:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado23.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
A similar phenomenon is 
\series bold
grokking
\series default
, which occur when we increase training time.
 It is remarkable that shallow models don't show it, which is a reason to
 use deep networks! 
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado24.png
	scale 60

\end_inset


\end_layout

\begin_layout Section
Convolutional Neural Networks
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
When working with MLP, we find several limitations:
\end_layout

\begin_layout Enumerate
Dealing with data with a high number of features.
 For example, let imagine we are working with a dataset of images at full
 HD resolution.
 The feature size is 
\begin_inset Formula $1920\times1080\times3=6\ 220\ 800$
\end_inset

.
 Learning a single layer to reduce the dimension to 1000 requires around
 
\begin_inset Formula $6000K\times1K\sim10^{9}$
\end_inset

 parameters, making the training really difficult.
\end_layout

\begin_layout Enumerate
Use the knowledge of the input data modality to shape the network.
 E.g., for images, the network should be equivariant to translation.
 This means that a pattern should be detected independently of where it
 is located in the image.
\end_layout

\begin_layout Standard

\series bold
Convolutional Neural Networks (CNNs)
\series default
 appear to mitigate these limitations.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A CNN is an NN that uses convolutions in place of general matrix multiplication
 in, at least, one of their layers.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
CNNs deal with data arranged according to a grid, which can be temporal
 date, images, videos, etc.
\end_layout

\begin_layout Subsubsection
History of CNNs
\end_layout

\begin_layout Itemize
The first work on CNNs was done in 1998, by LeCun et al.
 
\end_layout

\begin_layout Itemize
Theoretical advances to make DNN converge by Hinton et al.
 in 2006.
\end_layout

\begin_layout Itemize
Access to large datasets such as ImageNet thanks to Deng et al.
 in 2009.
\end_layout

\begin_layout Itemize
Advances in hardware technology to scale learning, with better CPUs and
 the development of GPUs.
\end_layout

\begin_layout Itemize
Win of the 2012 ImageNet challenge with AlexNet, using CNNs, by Krizhevsky
 et al.
 in 2012, made them famous.
\end_layout

\begin_layout Subsection
Convolutions
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Given two functions, 
\begin_inset Formula $f,g:\mathbb{R}\rightarrow\mathbb{R}$
\end_inset

, their 
\series bold
convolution
\series default
 is defined as
\begin_inset Formula 
\[
\left(f*g\right)\left(x\right)=\int_{-\infty}^{\infty}f\left(z\right)g\left(x-z\right)dz.
\]

\end_inset

 For discrete function, it becomes
\begin_inset Formula 
\[
\left(f*g\right)\left(m,n\right)=\sum_{i,j=-\infty}^{i,j=\infty}f\left(i,j\right)g\left(m-i,n-j\right),
\]

\end_inset

 where in this case 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $g$
\end_inset

 are bidimensional.
\end_layout

\begin_layout Definition
\begin_inset Formula $f$
\end_inset

 is called the 
\series bold
input
\series default
 
\series bold
signal
\series default
.
\end_layout

\begin_layout Definition
\begin_inset Formula $g$
\end_inset

 is called the 
\series bold
kernel
\series default
, or filter.
\end_layout

\begin_layout Definition
\begin_inset Formula $f*g$
\end_inset

, the convolution output, is the 
\series bold
feature map
\series default
.
\end_layout

\end_inset


\end_layout

\begin_layout Remark
Properties of convolutions:
\end_layout

\begin_deeper
\begin_layout Itemize
Commutativity:
\begin_inset Formula 
\[
\left(f*g\right)\left(x\right)=\left(g*f\right)\left(x\right).
\]

\end_inset


\end_layout

\begin_layout Itemize
Distributivity:
\begin_inset Formula 
\[
\left(f*\left(g+h\right)\right)\left(x\right)=\left(f*g\right)\left(x\right)+\left(f*h\right)\left(x\right).
\]

\end_inset


\end_layout

\begin_layout Itemize
Associativity:
\begin_inset Formula 
\[
\left(\left(f*g\right)*h\right)\left(x\right)=\left(f*\left(g*h\right)\right)\left(x\right).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Remark
Observe that convolutions can be understood as taking a moving average of
 
\begin_inset Formula $f$
\end_inset

 around each point 
\begin_inset Formula $x$
\end_inset

, with weights provided by 
\begin_inset Formula $g$
\end_inset

.
 If 
\begin_inset Formula $\int gdx=1$
\end_inset

, then it would represent a proper moving average.
\end_layout

\begin_layout Standard
In practice, however, CNNs do not really use convolutions, but 
\series bold
cross-correlations
\series default
, which consist in sliding one signal (or function) over another and measuring
 the similarity at each position.
 It's a way to track how much one signal resembles another as you shift
 one of them over time or space.
 Their definition is very similar to convolutions, but convolutions invert
 the kernel function, while cross-correlations do not:
\begin_inset Formula 
\[
\left(f\logof g\right)\left(m,n\right)=\sum_{i,j=-\infty}^{i,j=\infty}f\left(m,n\right)g\left(m+i,n+i\right).
\]

\end_inset


\end_layout

\begin_layout Standard
While MLPs make an interaction between each input neurons and each output
 neurons, CNNs have 
\series bold
sparse interactions
\series default
, thanks to the kernels, which have a small number of parameters, significantly
 reducing the number of parameters of the network.
\end_layout

\begin_layout Standard
Moreover, in MLP there is one weight per connection between the input and
 the output, while CNNs apply the same kernel to different parts of the
 input, also reducing the number of parameters of the network.
 This is called the 
\series bold
parameter sharing
\series default
 property.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A function 
\begin_inset Formula $f$
\end_inset

 is said to be 
\series bold
equivariant
\series default
 to a transform 
\begin_inset Formula $g$
\end_inset

, if for any input 
\begin_inset Formula $x$
\end_inset

, it holds
\begin_inset Formula 
\[
f\left(g\left(x\right)\right)=g\left(f\left(x\right)\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Because of paratemer sharing, the CNNs are equivariant to translations.
 This makes them particulary useful for some modalities, such as image,
 for which we aim to detect several objects in the same manner.
\end_layout

\begin_layout Standard
Images, and some other modalities, like videos, are composed of 
\series bold
channels
\series default
.
 For example, RGB is a 3-channel way to compose images.
\end_layout

\begin_layout Standard
Kernels are convoluted with all channels of the input, as visualized in
 the following figure.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename pegado28.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Convolution of a 3-channel input with a 3-channel kernel.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Convolutions are not equivariant to rotation, zoom, etc.
 And these might be interesting for our model to be invariant.
 To make the network invariant to such transformation, we can transform
 the data with data augmentations including zooming and rotating, and feeding
 the network with this transformed data.
\end_layout

\begin_layout Standard
Notice how convolutions can reduce the input size, whenever the kernel is
 larger than 
\begin_inset Formula $1\times1$
\end_inset

.
 This is due to the necessity to fit the whole image.
 
\end_layout

\begin_layout Standard
The output size of the convolution of an input of size 
\begin_inset Formula $n_{h}\times n_{w}$
\end_inset

 with a kernel of size 
\begin_inset Formula $k_{h}\times k_{w}$
\end_inset

 is
\begin_inset Formula 
\[
\left(n-k_{h}+1\right)\times\left(n_{w}-k_{w}+1\right).
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Fixed Kernels Weights
\end_layout

\begin_layout Standard
If we are interested in certain features, and we know how to define a kernel
 that is good for identifying these features, we can just do this and applying
 this kernel.
\end_layout

\begin_layout Standard
For example, in the following illustration we observe a kernel that is good
 at finding vertical edges:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado29.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsubsection
Learned Kernel Weights
\end_layout

\begin_layout Standard
Learning a CNN backbone using DL is learning the weights of the kernels
 via backpropagation.
 The filters seek to learn the best representation to fit its training objective
, via the training loss.
\end_layout

\begin_layout Standard
Using different kernels allows to detect various patterns, so usually CNNs
 contain thousands of kernels and are grouped in hierarchical layers, to
 learn from low-level features to high-level features.
\end_layout

\begin_layout Standard
To compute various features, such as different detections (horizontal, vertical,
 diagonal, etc.) we need several filters.
 For an input of size 
\begin_inset Formula $C\times n_{1}\times n_{2}$
\end_inset

, where 
\begin_inset Formula $C$
\end_inset

 is the amount of channels, and 
\begin_inset Formula $F$
\end_inset

 filters of size 
\begin_inset Formula $C\times m_{1}\times m_{2}$
\end_inset

, the feature map produced has 
\begin_inset Formula $F$
\end_inset

 channels and is of size
\begin_inset Formula 
\[
F\times\left(n_{1}-m_{1}+1\right)\times\left(n_{2}-m_{2}+1\right).
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Receptive fields
\end_layout

\begin_layout Standard
The 
\series bold
receptive field
\series default
 is the region of the input space that a particular CNN's feature is looking
 at.
\end_layout

\begin_layout Subsubsection
\begin_inset Formula $1\times1$
\end_inset

 Convolution
\end_layout

\begin_layout Standard
The 
\begin_inset Formula $1\times1$
\end_inset

 convolution is a linear combination of all channels for each pixel, allowing
 to learn to reduce or increase the number of filters.
\end_layout

\begin_layout Standard
In general, if the input is of size 
\begin_inset Formula $F_{in}\times H\times W$
\end_inset

 and the filter is of size 
\begin_inset Formula $F_{out}\times1\times1$
\end_inset

, then
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $F_{out}<F_{in}$
\end_inset

: the dimension is reduced.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $F_{out}>F_{in}$
\end_inset

: the dimension is increased.
\end_layout

\begin_layout Standard
\begin_inset Formula $1\times1$
\end_inset

 convolutions can replace fully connected layers.
 For example, in classification, we could do 
\begin_inset Formula $F_{out}=N_{classes}$
\end_inset

.
\end_layout

\begin_layout Subsection
Padding, Stride, Pooling
\end_layout

\begin_layout Subsubsection
The Sides Problem
\end_layout

\begin_layout Standard
Convolutions are applied on fixed size patches of the input data, and they
 can only be shifted until there are no pixels.
 This introduces two potential problems:
\end_layout

\begin_layout Itemize
The output size is reduced.
\end_layout

\begin_layout Itemize
The information in the sides of the image can be lost, because the convolution
 cannot be applied there.
\end_layout

\begin_layout Subsubsection
Padding
\end_layout

\begin_layout Standard
Padding is a solution to the edge problem, consisting on adding data at
 the sides of the image.
 There are several strategies, but in general, we just add zeros:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado30.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
There are several modes of zero padding.
 For a padding of 
\begin_inset Formula $k$
\end_inset

 pixels:
\end_layout

\begin_layout Itemize
Valid: no padding.
\end_layout

\begin_layout Itemize
Same: add 
\begin_inset Formula $\frac{k-1}{2}$
\end_inset

 zeros on each side.
\end_layout

\begin_layout Itemize
Full: add 
\begin_inset Formula $k$
\end_inset

 zeros on each side.
\end_layout

\begin_layout Standard
The output size of a convolution of a 
\begin_inset Formula $n_{h}\times n_{w}$
\end_inset

 sized input, to which we add 
\begin_inset Formula $p_{h}$
\end_inset

 rows and 
\begin_inset Formula $p_{w}$
\end_inset

 columns of padding, and a kernel of size 
\begin_inset Formula $k_{h}\times k_{w}$
\end_inset

 becomes
\begin_inset Formula 
\[
\left(n_{h}-k_{h}+p_{h}+1\right)\times\left(n_{w}-k_{w}+p_{w}+1\right).
\]

\end_inset

 Generally, we want to have 
\begin_inset Formula $p_{h}=k_{h}-1$
\end_inset

 and 
\begin_inset Formula $p_{w}=k_{w}-1$
\end_inset

, which is achieve by applying same zero padding.
\end_layout

\begin_layout Subsubsection
Stride
\end_layout

\begin_layout Standard
As far as we have seen, we slide the kernel across all locations right and
 down.
 However, we could skip some of this locations, effectively reducing the
 feature map output and the computational cost, but at the expense of the
 accuracy of the representations.
\end_layout

\begin_layout Standard
If we add 
\begin_inset Formula $s_{h},s_{w}$
\end_inset

 for the height and width strides, the feature map size is
\begin_inset Formula 
\[
\frac{\left(n_{h}-k_{h}+p_{h}+1+s_{h}\right)}{s_{h}}\times\frac{\left(n_{w}-k_{w}+p_{w}+1+s_{w}\right)}{s_{w}}.
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Pooling
\end_layout

\begin_layout Standard
Pooling consists in statistically summarizing a neighbourhood.
 A pooling layer takes a window of values and output one value.
 There are several pooling types:
\end_layout

\begin_layout Itemize
Max Pooling: take the maximum value of a window.
\end_layout

\begin_layout Itemize
Average pooling: take the eman value of a window.
\end_layout

\begin_layout Itemize
\begin_inset Formula $L_{2}$
\end_inset

 norm, weighted average pooling, etc.
\end_layout

\begin_layout Standard
For example, the following illustrates the use of a 2x2 max pooling layer:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado31.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Pooling is useful to make our representations invariant to minor translations.
 For deep layers, minor modifications can mean great changes in the input
 image.
\end_layout

\begin_layout Standard
Also, it reduces the amount of parameters and computation, and help reducing
 overfiting.
\end_layout

\begin_layout Standard
It sets up a strong prior: invariance to local translation of learned kernels.
\end_layout

\begin_layout Standard
It can be degrading for some tasks, where precise locations are required.
\end_layout

\begin_layout Subsection
CNNs
\end_layout

\begin_layout Standard

\series bold
LeNet
\series default
 by LeCun et al.
 in 1998 was designed after 10 uears of working with handwritten bank checks.
 It paved the basics of DL:
\end_layout

\begin_layout Itemize
Feature extraction by convolution layers.
\end_layout

\begin_layout Itemize
Classification by MLP layers.
\end_layout

\begin_layout Itemize
Layer of convolution followed by average pooling, and non-linearity, with
 sigmoid or tanh.
\end_layout

\begin_layout Itemize
SGD optimizer to perform backpropagation.
\end_layout

\begin_layout Standard
The architecture is the following:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado32.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
AlexNet
\series default
 by Krizhevsky et al.
 in 2012 was on of the first DNN, and won the 2012 ImageNet challenge, causing
 a new DL area.
 They extended LeNet to larger images, with wider convolutions, and used
 ReLUs and max pooling, combined with dropout.
\end_layout

\begin_layout Standard
A very interesting fact they observed was that as the layers were deeper,
 the receptive field was higher: The first layers learn basic patterns,
 while deeper layers learn more complicated shapes.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado33.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Visual Geometry Group (VGG)
\series default
 by Simonyan et al.
 in 2015 was the first network with blocks.
 the blocks consisted in:
\end_layout

\begin_layout Itemize
Convolution layer with padding to keep the same resolution.
\end_layout

\begin_layout Itemize
Non-linearity.
\end_layout

\begin_layout Itemize
Pooling layer to reduce resolution.
\end_layout

\begin_layout Standard
The architecture was the following:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado34.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
The problem was how to maintain enough resolution to have a lot of blocks.
 The solution was to introduce more convolutions at low resolution, instead
 of few convolutions at high resolution.
\end_layout

\begin_layout Standard
This increases the number of non-linearities and reduces the number of parameter
 to achieve an equal receptive field.
\end_layout

\begin_layout Standard

\series bold
Network in Network (NiN)
\series default
, by Lin et al.
 in 2013: previous architectures improved by enhacing the number of convolutions
 (width) and deepening the network (depth).
 This presents two problems:
\end_layout

\begin_layout Itemize
The last fully connected layers consume large number of parameters.
\end_layout

\begin_layout Itemize
It is difficult to add non-linearity without using fully connected layers,
 that destroy the spatial structure.
\end_layout

\begin_layout Standard
NiN made improvements:
\end_layout

\begin_layout Itemize
It used 
\begin_inset Formula $1\times1$
\end_inset

 convolutiones to increase the number of non-linearities.
\end_layout

\begin_layout Itemize
Also, a global average pool at the end to remove large fully connected layers.
\end_layout

\begin_layout Standard

\series bold
Inception Blocks
\series default
: Google was facing a problem.
 They needed fast deployment and inference, but large convolutions with
 lots of channels increase inference time.
 Their solution was to reduce the number of channels by applying several
 convolutions in parallel.
 Instead of choosing a single filter size for a given layer, Inception blocks
 apply multiple different-sized filters (e.g., 1x1, 3x3, 5x5 convolutions)
 in parallel to the same input feature map.
 This allows the network to capture information at various scales.
\end_layout

\begin_layout Standard
An inception block looks as follows:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado35.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
GoogleNet
\series default
, by Szegedy et al.
 in 2015 was based on inception blocks.
 It used several classifiers throughout training to enhance discriminative
 features at first layers, and reduce vanishing gradients.
\end_layout

\begin_layout Standard

\series bold
Residual Blocks
\series default
: these blocks make use of 
\series bold
residual connections
\series default
, or shortcut connections, which forward the input to the following layer.
 That is, if a layer is represented as 
\begin_inset Formula $f\left(x\right)$
\end_inset

, the same layer, when used inside a residual block, would be 
\begin_inset Formula $f\left(x\right)+x$
\end_inset

.
 This is illustrated below.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado36.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Residual blocks make the identity function easier to learn, and reduce vanishing
 or exploding gradient problems.
\end_layout

\begin_layout Standard

\series bold
ResNet Blocks
\series default
: these blocks are a combination of VGG blocks and residual blocks.
 They use 
\begin_inset Formula $3\times3$
\end_inset

 convolutions, with batch normalization to stabilize training and residual
 connection concatenated to the result of applying two of these convolutions.
 The residual connection can be either direct, or by means of a 
\begin_inset Formula $1\times1$
\end_inset

 convolution.
 This is illustrated below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado37.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Residual Neural Networks (ResNet)
\series default
, by He et al.
 in 2016, is a network architecture consisting of blocks of residual blocks.
 There are different ResNets depending on how many blocks or layer are used.
 For example, the following is a ResNet-18, as it has 18 trainable layers
 (the first 7x7 conv, two 3x3 convs for each internal block, and there are
 eight of them, and the last fully connected layer):
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado38.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
ResNet is a widely used backbone until today.
\end_layout

\begin_layout Standard

\series bold
ResNexts: Group convolution
\series default
, by Xie et al.
 in 2017.
 To add more non-linearities in ResNets we can add more layers, increase
 the width of convolutions or the number of channels.
 However, increasing the number of channels add quadratic complexity 
\begin_inset Formula $\left(F_{in}\times F_{out}\right)$
\end_inset

.
 Group convolutions is a technique to reduce the computational complexity
 while still increasing the network's width.
 In group convolution, the input channels are divided into groups, and a
 convolution is performed independently on each group.
 This means that if you have 
\begin_inset Formula $g$
\end_inset

 groups, each group will have 
\begin_inset Formula $\frac{c}{g}$
\end_inset

 input channels and 
\begin_inset Formula $\frac{b}{g}$
\end_inset

 filters applied to it, where 
\begin_inset Formula $c$
\end_inset

 is the total number of input channels, and 
\begin_inset Formula $b$
\end_inset

 is the total number of intermediate channels.
 Each filter in a group only interacts with the input channels within that
 group.
\end_layout

\begin_layout Standard
The following diagram shows a block of the ResNeXt architecture.
 The input channels are first split into 
\begin_inset Formula $g$
\end_inset

 groups.
 Each group is processed by its own set of 1x1 convolutions (to reduce dimension
ality), followed by 3x3 convolutions (to capture spatial hierarchies).
 The outputs of these groups are then concatenated, and a final 1x1 convolution
 is applied to the concatenated result to produce the final output channels.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado39.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
DenseNet
\series default
, by Huang et al.
 in 2017.
 This architecture is based on ResNet blocks, but instead of adding the
 input and the result of the convolution, it concatenates both of them plus
 the results of each dense blocks on the channel dimension.
 It makes use of 
\series bold
transition layers
\series default
, which are 
\begin_inset Formula $1\times1$
\end_inset

 convolutions after concatenation, to reduce feature dimension.
\end_layout

\begin_layout Standard
Some other architectures address different problems.
 MobileNets, by Howard et al.
 in 2017 was thought to be deployed on mobiles, it separates convolution
 in two operations; EfficientNet, by Tan et al.
 in 2019, uses grid search without computational budget to modify the architectu
re at best width, depth or input resolution...
 
\end_layout

\begin_layout Standard
CNNs are being slowly replaced in some cases by 
\series bold
Visual Transformers
\series default
.
\end_layout

\begin_layout Subsubsection
Object Detection Problem
\end_layout

\begin_layout Standard
The goal of the object detection problem is to find a bounding box that
 contain an object of interest.
 It implies two objectives:
\end_layout

\begin_layout Itemize
Regression to shape the box.
\end_layout

\begin_layout Itemize
Classification to identify the object.
\end_layout

\begin_layout Standard
If we consider this problem as a classification problem, one approach is
 to test various positions and scales to propose various anchor boxes.
 This is scalable only if the classifier is fast enough.
 However, CNNs are computationally expensive.
 A solution is to select only a subset of the boxes, by finding blobs likely
 to contain objects without class consideration.
\end_layout

\begin_layout Standard

\series bold
Region proposal: selective search
\series default
, by Uijlings et al.
 in 2013
\end_layout

\begin_layout Standard
Selective search is a widely used tool to provide regions of interest in
 images.
 The regions are computed following the pipeline:
\end_layout

\begin_layout Enumerate
Ascendant segmentation: The algorithm starts with a fine-grained segmentation
 of the image, where many small regions are created based on pixel similarity
 (color, texture, etc.).
 This is often done using a graph-based segmentation method.
\end_layout

\begin_layout Enumerate
Fuse regions at different scales: The segmented regions are then hierarchically
 merged based on various similarity measures.
 This process is iterative, with smaller regions combining to form larger
 ones.
 This step is crucial as it operates over multiple scales, allowing the
 algorithm to be more robust in detecting objects of different sizes and
 aspects.
\end_layout

\begin_layout Enumerate
Convert regions to potential boxes of interest: The resulting regions from
 the previous step are then used to generate bounding boxes, which are the
 "region proposals." These are the candidate regions that could contain objects
 and are subsequently used by an object detection model for classification.
\end_layout

\begin_layout Standard
This process is depicted below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado40.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Intersection over Union (IoU)
\end_layout

\begin_layout Standard
For two sets, 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, the Jaccard index, or Intersection over Union, is the reatio of the intersecti
on area to their union are
\begin_inset Formula 
\[
J\left(A,B\right)=\frac{\left|A\cap B\right|}{\left|A\cup B\right|}.
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
Label region proposal
\end_layout

\begin_layout Standard
Region proposal anchor boxes are associated to ground-truth bounding boxes
 given their IoU (above a threshold).
 The class of an anchor is the same as its associated bounding box.
 If the anchor box is not associated to a bounding box, it is labeled as
 background.
\end_layout

\begin_layout Standard
The offsets, relative to the position of central coordinates between anchor
 box and boundingbox, label the region.
\end_layout

\begin_layout Standard
That is, proposal anchor boxes are labeled with the same label of a ground-truth
 bounding box if their IoU is above a given threshold.
\end_layout

\begin_layout Standard

\series bold
R-CNN
\series default
, by Girshick et al.
 in 2014
\end_layout

\begin_layout Standard
R-CNN takes region proposal as input.
 It computes features for each of the regions, and the classification is
 done using several SVMs.
 The regression of offsets is done by using a linear regression model.
\end_layout

\begin_layout Standard
To train R-CNNs, there is a supervised pretraining of a CNN backbone, generally
 on ImageNet, followed by an optional fine-tuning of the backbone, to learn
 specialised features based on a classification obkective.
 The backbone is then fixed.
\end_layout

\begin_layout Standard
For each input: crop and wrap proposal regions computed by selective search
 and compute the features.
 Train a binary SVM for each class, and apply linear regression to crrect
 small offsets between the prediction and the actual bounding box.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado41.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Evaluating detection models
\end_layout

\begin_layout Standard
The meaning of true positive, false positive and false negative for the
 detection problem is not the same as for regular classification problems.
 The threshold for True and Falso positive/negatives is based on the IoU
 and a given threshold.
 For example:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado42.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Remember, 
\begin_inset Formula $precision=\frac{TP}{TP+FP}$
\end_inset

 and 
\begin_inset Formula $recall=\frac{TP}{TP+FN}$
\end_inset

.
\end_layout

\begin_layout Standard
The 
\series bold
average precision
\series default
 is the area ander the prevision-recall curve.
\end_layout

\begin_layout Standard
The 
\series bold
mean-average precision
\series default
 is the mean of average precision for various IoU threholds.
\end_layout

\begin_layout Standard
R-CNNs is slow in testing phase, because there are as many passes in the
 CNN as the number of region proposals, which is around 2000.
 Also, SVM and regression are a bit old school, so this architecture is
 not usable for real world applications.
\end_layout

\begin_layout Standard

\series bold
Fast R-CNN
\series default
, by Girshick in 2015
\end_layout

\begin_layout Standard
This modification of R-CNN was proposed to increase its efficiency.
 It passes thewhole image only once in the CNN backbone.
 The CNN is trainable, and not fixed, and the proposed regions are associated
 with computed features from the output feature map.
\end_layout

\begin_layout Standard
Each region of interest can have a different size, so selective search proposed
 regions are concatenated with features from the CNN to form the 
\series bold
Region of Interest (RoI) Pooling Layer
\series default
, which reshape the features to feed them to fully connected layers.
 From these features the classes and the offsets are predicted.
\end_layout

\begin_layout Standard
The following table compares R-CNN and Fast R-CNN:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
R-CNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fast R-CNN
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Test time per image
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
47 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.32 s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Speedup
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
146x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Test time per image with selective search
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
2 s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Speedup
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
25x
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\series bold
Faster R-CNN
\series default
, by Ren et al.
 in 2017
\end_layout

\begin_layout Standard
This new modification replaces selective search by a learned region proposal
 network.
 The rest is similar to Fast R-CNN.
\end_layout

\begin_layout Standard
The 
\series bold
region proposal network (RPN)
\series default
 is a network learned to propose regions of interest.
 It slides a window on the feature size, and, at each location of the window,
 it makes a prediction for 
\begin_inset Formula $k$
\end_inset

 anchors (propositions), which are sampled by varying scale and aspect ratio.
 A small network predicts if there is an object there, and a small network
 predicts offsets with the bounding box.
\end_layout

\begin_layout Standard
The following table compares the three approaches:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
R-CNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Fast R-CNN
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Faster R-CNN
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Test time per image (with proposals)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2 s
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
0.2 s
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Speedup
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
25x
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
250x
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
mAP (VOC 2007)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
66.0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
66.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
66.9
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard

\series bold
You Only Look Once (YOLO)
\series default
, by Redmon et al.
 in 2016
\end_layout

\begin_layout Standard
This model is a single stage detector: one network is used to predict the
 bounding boxes and the class probabilities.
 It is the first real time detector close to Faster R-CNN performance.
\end_layout

\begin_layout Standard
Its architecture consists of 24 convolutional layers and input dimension
 of 
\begin_inset Formula $448\times448$
\end_inset

.
 For each input, it cuts it in 
\begin_inset Formula $7\times7$
\end_inset

 grids of cells.
 Each cell computes the objectness and anchor boxes, considering the object
 at the center of the cell, and enabling the boxes to reach out the cell.
\end_layout

\begin_layout Standard
This model has been enhanced multiple times, with YoLo v2, v3, v4, v5,...
\end_layout

\begin_layout Subsubsection
Semantic Segmentation
\end_layout

\begin_layout Standard
The goal in this case is to find an object class for each pixel.
 There are several associated problems:
\end_layout

\begin_layout Itemize

\series bold
Semantic segmentation
\series default
: associate each pixel to a specific class.
\end_layout

\begin_layout Itemize

\series bold
Instance segmentation
\series default
: associate each pixel to a specific class and identify various instances
 from the same class.
\end_layout

\begin_layout Itemize

\series bold
Panoptic segmentation
\series default
: associate each pixel to once class, and prevent overlapping segments.
\end_layout

\begin_layout Standard
These are illustrated below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado43.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Mask R-CNN
\series default
 by He et al.
 in 2017
\end_layout

\begin_layout Standard
Basically, it is Faster R-CNN with a third branch, which outputs the object
 mask.
 
\end_layout

\begin_layout Standard
It can use various backbones such as ResNet, DenseNet,...
\end_layout

\begin_layout Subsection
Data and Transfer
\end_layout

\begin_layout Standard
Modern CNNs are made of millions of parameters, requiring a huge amount
 of data to train them.
 For example, ImageNet has 1.2M images for 1k classes, and is being replaced
 by ImageNet21k, that has 1B images.
\end_layout

\begin_layout Standard
Manually annotating such amount of images is costly in terms of money and
 time, and therefore there is the need for techniques to deal with lacking
 of data: data augmentation and transfer learning.
\end_layout

\begin_layout Subsubsection
Data Augmentation
\end_layout

\begin_layout Standard
We already saw it! It increases the diversity of data by transforming the
 source data with invariants
\end_layout

\begin_layout Subsubsection
Transfer Learning
\end_layout

\begin_layout Standard
Sometimes there is possibility to learn from scratch, by random initialisation,
 because of lack of data.
 In this case, we can make use of an already 
\series bold
pre-trained
\series default
 backbone from a source task for the target task.
\end_layout

\begin_layout Itemize
If the target task is similar to the source task, and the size is comparable,
 transfer learning works directly; while if the size is inferior, there
 is a risk of overfitting to the target task after few epochs.
\end_layout

\begin_deeper
\begin_layout Standard
For small problems, the transfer learning is accomplished by learning a
 linear classifier with last layers of a pre-trained backbone.
\end_layout

\end_deeper
\begin_layout Itemize
If the target task is very different from the the source task, and the problem
 is small, a linear classifier from lower level layers can be used; if the
 problem is large, we can fine-tune the backbone to the new task.
\end_layout

\begin_layout Standard
In all cases, starting from initialized weights is better than nothing.
\end_layout

\begin_layout Standard

\series bold
Fine tuning
\end_layout

\begin_layout Standard
Fine tuning consists in training several layers of a pre-trained backbone:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado44.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
Domain Adaptation
\end_layout

\begin_layout Standard
Sometimes, the target task and the source task share the same classes, but
 the target data has a different distribution than the source.
 This is an entire field in ML: how to adapt our features to the new domain,
 and have the best possible results.
\end_layout

\begin_layout Subsection
Self-Supervised Learning (SSL)
\end_layout

\begin_layout Standard
We already know supervised learning.
 It consists on predicting a target associated to an input.
 
\end_layout

\begin_layout Standard
Self-Supervised Learning (SSL) is different.
 It consists on predicting a part of en input, from the input.
 This means the model learns to understand and generate data by teaching
 itself.
\end_layout

\begin_layout Standard
A 
\series bold
pretext task
\series default
 is a task designed to teach the model something about the structure of
 the input data without using labels.
 For example, the pretext task might involve predicting the next word in
 a sentence, or the color version of a grayscale image.
 The idea is to construct targets from the data itself and learn from these
 artificially created labels.
\end_layout

\begin_layout Standard
SSL presents several advantages:
\end_layout

\begin_layout Itemize
Reduces the Need for Labeled Data: Labeling is often expensive and time-consumin
g, and SSL offers a way to learn useful representations without the need
 for extensive labeled datasets.
 
\end_layout

\begin_layout Itemize
Better Pre-training: SSL can serve as pre-training for neural networks,
 allowing them to learn general features from the data that can then be
 refined with a smaller amount of labeled data for a specific task (using
 transfer learning).
\end_layout

\begin_layout Standard
All this is illustrated below:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado45.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
For images, several pretext tasks have been firstly proposed, like rotation,
 patch localization, colorization, counting,...
\end_layout

\begin_layout Standard
For videos, which add the time dimension, we find the same pretext tasks
 as in images, plus some others specific to videos, which can be masking
 frames, shuffling frames,...
\end_layout

\begin_layout Standard

\series bold
Contrastive Learning
\end_layout

\begin_layout Standard
Constrastive Learning is a pretext task for SSL.
 It aligns positively pairs of images, and push away other images.
 We find the problem of defining what is a positive pair, which can be solved
 by using data augmentation.
\end_layout

\begin_layout Standard
The following figure illustrates this concept:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado46.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
SimCLR
\series default
, by Chen et al.
 in 2020
\end_layout

\begin_layout Standard
This model defines a siamese pipeline for contrastive learning.
 Positive pairs are formed from strong data augmentation, like color jittering,
 gaussian blur, grayscale, etc.
 Both paris go through an encoder and a projector, which consists on several
 stacked MLP layers.
 Then, contrastive loss is applied.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado47.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard

\series bold
SCE
\series default
, by Denize et al.
 in 2021
\end_layout

\begin_layout Standard
This model tries to address the problem of how to deal with negatives that
 share semantic information with the positive pairs.
 For example, two different cats share more information than two different
 dogs.
 Pushing negatives with high semantic similarities makes training unstable,
 and so SCE predicts positive pairs and estimated relations among instances.
\end_layout

\begin_layout Standard

\series bold
Deep Cluster
\series default
, by Caron et al.
 in 2018
\end_layout

\begin_layout Standard
Clustering associates several input data to a same pseudo-label, without
 supervision.
\end_layout

\begin_layout Standard
Deep Cluster applies clustering to traing a backbone using several stages:
\end_layout

\begin_layout Itemize
Estimate pseudo-labels for each instance with a fixed backbone.
\end_layout

\begin_layout Itemize
Train the backbone on this label.
\end_layout

\begin_layout Itemize
Repeat the operations until convergence.
\end_layout

\begin_layout Section
Recurrent Neural Networks
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
Recurrent Neural Networks are a family of Neural Network architectures specially
 designed to deal with sequential data, such as text in NLP, speech signals
 in speech2text tasks, temporal data in videos, or other temporal signals,
 like ECGs, time series, etc.
\end_layout

\begin_layout Standard

\series bold
Sequential data
\series default
 is data with a temporal component, that usually implies correlation in
 the temporal dimension.
 More precisely, a 
\series bold
sequence
\series default
 consists in a set of vectors 
\begin_inset Formula $x_{t}$
\end_inset

, where 
\begin_inset Formula $t\in\left[1,\tau\right]$
\end_inset

 is a temporal index.
\end_layout

\begin_layout Standard
Note that the temporal index is not necessarily related to time, but to
 order.
 For example, text is not temporal, but words are ordered.
\end_layout

\begin_layout Standard

\series bold
Memory
\series default
 is essential for us to understand and interpret what we perceive.
 Memory can be understood as a persistent format of information.
 MLP don't have this persistence, each data point is processed independently
 of the rest.
 Therefore, RNNs introduce a way to store information, by adding inner loops
 that enables them to preserve information at each time-step.
\end_layout

\begin_layout Subsection
Recurrent Neural Networks
\end_layout

\begin_layout Standard
A Recurrent Neural Network (RNN) is defined with a state, 
\begin_inset Formula $h^{\left(t\right)}$
\end_inset

, by recurrence.
 This state depends on the current input, 
\begin_inset Formula $x^{\left(t\right)}$
\end_inset

, and the previous state, 
\begin_inset Formula $h^{\left(t-1\right)}$
\end_inset

:
\begin_inset Formula 
\[
h^{\left(t\right)}=f\left(h^{\left(t-1\right)},x^{\left(t\right)};\theta\right).
\]

\end_inset

 The computational graph can be represented with a loop, or unfolded, making
 it direct and acyclic, as:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado50.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
A RNN is trained to predict the future, given past information, in such
 a way that 
\begin_inset Formula $h^{\left(t\right)}$
\end_inset

 is a summary of the sequence until the timestep 
\begin_inset Formula $t$
\end_inset

.
 This summarization implies information compression, or loss of information,
 and the training must keep relevant information for the task.
\end_layout

\begin_layout Standard
Going back to the definition of the state, we can then write it alternative
 as
\begin_inset Formula 
\[
h^{\left(t\right)}=f\left(h^{\left(t-1\right)},x^{\left(t\right)};\theta\right)=g^{\left(t\right)}\left(x^{\left(t\right)},x^{\left(t-1\right)},...,x^{\left(1\right)}\right),
\]

\end_inset

 where 
\begin_inset Formula $g^{\left(t\right)}$
\end_inset

 takes the whole sequence as input, of variable length.
\end_layout

\begin_layout Standard
On the other hand, using the factorized form, with 
\series bold
transition function 
\begin_inset Formula $f$
\end_inset


\series default
, the function is the same at each timestep, allowing for parameter sharing
 and generalization.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
RNNs are universal approximators.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We measure the performance of a RNN through the cost function 
\begin_inset Formula $L$
\end_inset

, between the output 
\begin_inset Formula $o$
\end_inset

 and the ground truth 
\begin_inset Formula $y$
\end_inset

.
 Internatlly, we use softmax:
\begin_inset Formula 
\[
\hat{y}_{i}=\frac{e^{o_{i}}}{\sum_{j}e^{o_{j}}}.
\]

\end_inset

 The parameters of a RNN are:
\end_layout

\begin_layout Itemize
\begin_inset Formula $U$
\end_inset

: input to hidden layers.
\end_layout

\begin_layout Itemize
\begin_inset Formula $W$
\end_inset

: recurrent connections between hidden layers.
\end_layout

\begin_layout Itemize
\begin_inset Formula $V$
\end_inset

: hidden layers to output.
\end_layout

\begin_layout Standard
That is:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado51.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsubsection
Direct Propagation
\end_layout

\begin_layout Standard
In the case of discrete variable prediction (like words), 
\begin_inset Formula $o$
\end_inset

 represents log-likelihoods of possible output values, and the normalize
 probability is 
\begin_inset Formula $\hat{y}=softmax\left(o\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Direct propagation works by:
\begin_inset Formula 
\begin{align*}
a^{\left(t\right)} & =b+Wh^{\left(t-1\right)}+Ux^{\left(t\right)},\\
h^{\left(t\right)} & =\phi\left(a^{\left(t\right)}\right),\\
o^{\left(t\right)} & =c+Vh^{\left(t\right)},\\
\hat{y}^{\left(t\right)} & =softmax\left(o^{\left(t\right)}\right),
\end{align*}

\end_inset

 where 
\begin_inset Formula $\phi$
\end_inset

 is the activation function.
\end_layout

\begin_layout Subsubsection
Recurrent Neural Networks with output recurrence
\end_layout

\begin_layout Standard
We don't link directly hidden layers recurrently, but rather we link the
 output to a hidden layer.
 This has the cons of using less information than 
\begin_inset Formula $h^{\left(t-1\right)}$
\end_inset

, being therefore a less expressive model, but the pros of being easier
 to train, enabling parallelization and efficient backpropagation.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado52.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsubsection
Recurrent Neural Networks with unique output
\end_layout

\begin_layout Standard
In this case, it needs the complete input sequence, and the output is a
 summary of the input.
 This kind of setting is usually used a simpler module of a more complex
 architecture.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado53.png
	scale 60

\end_inset


\end_layout

\begin_layout Subsubsection
More architectures
\end_layout

\begin_layout Standard
In this figure we observe different possible setups, which apply to different
 use cases.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado54.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
For instance:
\end_layout

\begin_layout Itemize
Automatic captioning, converting images to text sequences, could be done
 with a one to many architecture.
\end_layout

\begin_layout Itemize
Sentiment analysis, converting a text sequence to a predicted label, could
 be done with a many to one architecture.
\end_layout

\begin_layout Itemize
Machine translation, converting text sequence to text sequence, could be
 done with a many to many architecture.
\end_layout

\begin_layout Itemize
Frame-label video classification, converting a video sequence into a sequence
 of labels, could also be done with a many to many architecture.
\end_layout

\begin_layout Subsubsection
Bi-Directional Recurrent Neural Network
\end_layout

\begin_layout Standard
Sometimes, the future of the sequence can also be helpful, for example in
 NLP, in Character recognition and even in Speech recognition.
 For this, there exist the Bi-Directional RNN (BRNN), which combine a RNN
 processing from past to future, with state 
\begin_inset Formula $h$
\end_inset

, and a RNN processing from future to past, with state 
\begin_inset Formula $g$
\end_inset

, and the output combines the two of them.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado55.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Moreover, BRNN can be applied to images with 4 direction, applying them
 up,down and left,right.
 This is a bit outdated approach for visual recognition, with architectures
 as ReNet for classification and ReSeg for segmentation.
\end_layout

\begin_layout Subsubsection
Deep Recurrent Neural Network
\end_layout

\begin_layout Standard
A classical RNN has an input layer, 
\begin_inset Formula $U$
\end_inset

, a hidden layer, 
\begin_inset Formula $W$
\end_inset

, and an output layer 
\begin_inset Formula $V$
\end_inset

.
 However, we can add hidden layers, allowing to go higher in abstraction.
\end_layout

\begin_layout Standard
The representation improves hierarchically:
\end_layout

\begin_layout Itemize
\begin_inset Formula $h$
\end_inset

, the first state, represents temporal dependencies on inputs 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $z$
\end_inset

, the second state, represents temporal dependencies on the representations
 
\begin_inset Formula $h$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado56.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
Also, we can add an MLP before every recurrent layer, increasing the representat
ion capacity of the network, at the expense of a harder training.
 A possibility to improve these is to use skip connections.
\end_layout

\begin_layout Subsection
Recurrent Neural Networks Training
\end_layout

\begin_layout Standard
The principle is the same as with MLP and CNNs: we choose a cost function
 a minimize it during training using gradient descent with backpropagation.
\end_layout

\begin_layout Standard
However, we need to take into account the recurrency of the network, and
 so we use what is called 
\series bold
Backpropagation through time 
\series default
(BPTT), which consists in applying backpropagation to an unrolled graph
 of the RNN.
\end_layout

\begin_layout Standard
The idea is to forward through the entire sequence to compute the loss,
 and then go backwards through the entire sequence to compute gradient.
\end_layout

\begin_layout Standard
However, this can be very inefficient, so we also find the 
\series bold
truncated BPTT
\series default
, which does BPTT to chunks of the sequence, instead of the complete sequence.
 The hidden states are carried forward in time until the end of the sequence,
 but we only backpropagation for some smaller number of steps.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado57.png
	scale 50

\end_inset


\end_layout

\begin_layout Subsection
Long-Short Term Memory (LSTM) and Gated Recurrent Units (GRU)
\end_layout

\begin_layout Standard
Classical RNN present two main limitations:
\end_layout

\begin_layout Enumerate
A computation limitation: they are hard to train, and prone to gradient
 vanishing and explosion.
\end_layout

\begin_layout Enumerate
Long term interactions are hard to model.
\end_layout

\begin_layout Standard
Some upgraded variants of RNNs are Long Short Term Memory (LSTM) and Gated
 Recurrent Units (GRU).
\end_layout

\begin_layout Standard

\series bold
Gradient vanishing and exploding
\series default
: the reason RNNs are prone to gradient vanishing/exploding is that the
 gradient needs to go through the unfolded computational graph.
 If the largest singular value of the hidden matrix is greater than 1, a
 recurrent multiplication by it would tend to increase the gradient vector,
 leading to gradient explosion.
 The opposite happens when the largest singular value is smaller than 1,
 leading to gradient vanishing.
\end_layout

\begin_layout Standard
The solution to gradient explosion can be using gradient clipping.
\end_layout

\begin_layout Standard
The solution to gradient vanishing is to change the RNN architecture.
\end_layout

\begin_layout Standard

\series bold
Long-term dependency problem
\series default
: RNNs can connect past information to present data, and, in theory, time
 distance of information is irrelevant.
 However, in practice, classical RNNs cannot model long sequences (more
 than 20 points).
\end_layout

\begin_layout Subsubsection
LSTM
\end_layout

\begin_layout Standard
LSTM is based on a standard RNN whose neuron activates with 
\begin_inset Formula $tanh$
\end_inset

.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado58.png
	scale 50

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $C_{t}$
\end_inset

 is the cell state, which flows through the entire chain and is updated
 with a sum instead of a product.
 This avoids memory vanishing and the gradient explosion and vanish.
 
\end_layout

\begin_layout Standard
Then, there are three gates foverned by sigmoid units, which define the
 control of in and out information.
\end_layout

\begin_layout Standard
A key component is the forget gate,
\begin_inset Formula 
\[
f_{t}=\sigma\left(W_{f}\cdot\left[h_{t-1},x_{t}\right]+b_{f}\right),
\]

\end_inset

 which can affect the affect the previous state, letting it through or not
 (forgetting).
\end_layout

\begin_layout Standard
Then, the input gate layer,
\begin_inset Formula 
\[
i_{t}=\sigma\left(W_{i}\cdot\left[h_{t-1},x_{t}\right]+b_{i}\right),
\]

\end_inset

 which processes the input, contributing to the cell state.
\end_layout

\begin_layout Standard
Then, there is the classical neuron, activated with 
\begin_inset Formula $tanh$
\end_inset

, which also contributes to the cell state, by
\begin_inset Formula 
\[
\hat{C}_{t}=tanh\left(W_{C}\cdot\left[h_{t-1},x_{t}\right]+b_{C}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Finally, to update the cell state it is
\begin_inset Formula 
\[
C_{t}=f_{t}\cdot C_{t-1}+i_{t}\cdot\hat{C}_{t}.
\]

\end_inset

 Notice that the output is computed as
\begin_inset Formula 
\[
h_{t}=tanh\left(C_{t}\right)+\sigma\left(W_{o}\cdot\left[h_{t-1},x_{t}\right]+b_{o}\right).
\]

\end_inset


\end_layout

\begin_layout Subsubsection
GRU
\end_layout

\begin_layout Standard
GRU is a variant of LSTM, simpler and faster, and with similar performance.
 It works by applying:
\begin_inset Formula 
\begin{align*}
u_{i} & =\sigma\left(W_{u}\cdot x_{i}+U_{u}\cdot h_{i-1}+b_{u}\right),\\
r_{i} & =\sigma\left(W_{r}\cdot x_{i}+U_{r}\cdot h_{i-1}+b_{r}\right),\\
\hat{h}_{i} & =tanh\left(W_{h}\cdot x_{i}+r_{i}\circ U_{h}\cdot h_{i-1}+b_{h}\right),\\
h_{i} & =u_{i}\circ\hat{h}_{i}+\left(1-u_{i}\right)\circ h_{i-1}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
Reinforcement Learning
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
People and animals learn by interacting with the environment that sorround
 them, differing from certain other types of learning.
 This process is active, rather than passive: the subject needs to perform
 interactions with the environment, to obtain knowledge.
 Also, the interactions are usually sequential, with future interactions
 possibly depending on earlier ones.
\end_layout

\begin_layout Standard
Not only this, but we are goal oriented: we act towards an objective.
 And, more importantly, we can learn without examples of optimal behavior!
 Instead, we optimise some reward signal obtained from the outcome of our
 actions.
\end_layout

\begin_layout Standard
It is in these observation that 
\series bold
Reinforcement Learning (RL)
\series default
 arises as a learning paradigm, based on the 
\series bold
interaction loop
\series default
: there is an agent in an environment; the agent can make actions in the
 environment, and get observations from it.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename interaction_loop.png
	scale 60

\end_inset


\end_layout

\begin_layout Standard
RL relies on the reward hypothesis:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Conjecture
Reward Hypothesis
\end_layout

\begin_layout Conjecture
Any goal can be formalized as the outcome of maximizing a cumulative reward.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This hypothesis basically says that every objective that an agent can have,
 can be stated in terms of maximizing a reward associated to the actions
 of the agent with respect to this objective.
\end_layout

\begin_layout Standard
For example, if the objective of the agent is to fly a helicopter from point
 A to point B, then the reward could be negatively affected by the distance
 to point B, by the time taken to reach B,...
\end_layout

\begin_layout Standard
Now, it is important to realize that there exist different reasons to learn:
\end_layout

\begin_layout Itemize
Find solutions to problems.
\end_layout

\begin_layout Itemize
Adapt online to unforseen circumstances.
\end_layout

\begin_layout Standard
Well, RL can provide algorithm for both cases! Note that the second point
 is not just about generalization, but also to cope with the so-called data
 shift, efficiently, during operation.
\end_layout

\begin_layout Standard
With all this, now we can define RL:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Reinforcement Learning is the science and framework of learning to make
 decisions from interaction.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This requires us to think about time, consequences of actions, experience
 gathering, future prediction, uncertainty,...
\end_layout

\begin_layout Standard
It has a huge potential scope and is a formalisation of the AI problem.
\end_layout

\begin_layout Section
Definition and components
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
The 
\series bold
environment
\series default
 is the world of the problem at hand, with 
\series bold
agents
\series default
 in it that can perform actions, over time.
\end_layout

\begin_layout Definition
At each time step 
\begin_inset Formula $t$
\end_inset

, the agent:
\end_layout

\begin_deeper
\begin_layout Itemize
Receives observation 
\begin_inset Formula $O_{t}$
\end_inset

 and reward 
\begin_inset Formula $R_{t}$
\end_inset

 from the environment.
\end_layout

\begin_layout Itemize
Executes action 
\begin_inset Formula $A_{t}$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Definition
And the environment:
\end_layout

\begin_deeper
\begin_layout Itemize
Receives action 
\begin_inset Formula $A_{t}$
\end_inset

.
\end_layout

\begin_layout Itemize
Emits observation 
\begin_inset Formula $O_{t+1}$
\end_inset

 and reward 
\begin_inset Formula $R_{t+1}$
\end_inset

.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
But, what is a reward?
\end_layout

\begin_layout Standard
A 
\series bold
reward
\series default
, 
\begin_inset Formula $R_{t}$
\end_inset

, is a scalar feedback signal which indicates how well the agent is doing
 at step 
\begin_inset Formula $t$
\end_inset

: it defines how well the goal is being accomplished!
\end_layout

\begin_layout Standard
Therefore, the agent's job is to maximize the cummulative reward of the
 future steps, i.e., 
\begin_inset Formula 
\[
G_{t}=R_{t+1}+R_{t+2}+R_{t+3}+...
\]

\end_inset

 This is called the 
\series bold
return
\series default
.
 But, when one thinks about it carefully, one realizes that it is hard to
 know the future rewards with such precision.
 Therefore, it is also usual to use the 
\series bold
value
\series default
, which is the expected return, taking into account the current state, 
\begin_inset Formula $s$
\end_inset

:
\begin_inset Formula 
\[
v\left(s\right)=\mathbb{E}\left[G_{t}|S_{t}=s\right].
\]

\end_inset

 This depends on the actions the agents takes, and the goal is to 
\color blue
maximize it
\color inherit
! To achieve this, the agent must pick suitable actions.
\end_layout

\begin_layout Standard
Therefore, rewards and values define the utility of states and actions,
 and in this setup there is no supervised feedback.
\end_layout

\begin_layout Standard
Note, also, that this values can be defined recursively as
\begin_inset Formula 
\[
G_{t}=R_{t+1}+G_{t+1},
\]

\end_inset

 
\begin_inset Formula 
\[
v\left(s\right)=\mathbb{E}\left[R_{t+1}+v\left(S_{t+1}\right)|S_{t}=s\right].
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\series bold
environment state
\series default
 is the environment's internal state, which is usually invisible or partially
 visible to the agent.
 It is very important, but it can also contain lots of irrelevant information.
\end_layout

\begin_layout Standard
An environment is 
\series bold
fully observable
\series default
 when the agent can see the full environment state, so every observation
 reveals the whole environment state.
 That is, the agent state could just be the observation:
\begin_inset Formula 
\[
S_{t}=O_{t}.
\]

\end_inset


\end_layout

\begin_layout Standard
Note that 
\begin_inset Formula $S_{t}$
\end_inset

 is the agent state, not the environment state!
\end_layout

\begin_layout Subsection
Maximising the value by taking actions
\end_layout

\begin_layout Standard
As we have outlined, the goal is to select the actions that maximise the
 value.
 For this, we may need to take into account that actions may have long term
 consequences, delaying rewards.
 Thus, it may be better to sacrifice immediate reward to gain long-term
 reward.
\end_layout

\begin_layout Standard
The decision making process that for a given state chooses which action
 to take is called a 
\series bold
policy
\series default
.
 
\end_layout

\begin_layout Standard
To decide which action to take, we can also condition the value on actions:
\begin_inset Formula 
\[
q\left(s,a\right)=\mathbb{E}\left[G_{t}|S_{t}=s,A_{t}=a\right],
\]

\end_inset

 so, for a given state 
\begin_inset Formula $s$
\end_inset

, a possible set of actions 
\begin_inset Formula $A_{t}^{s}$
\end_inset

, we could decide which action to take as
\begin_inset Formula 
\[
a_{t}=\max_{a\in A_{t}^{s}}q\left(s,a\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Then, the 
\series bold
history
\series default
 is the full sequence of observation, actions and rewards:
\begin_inset Formula 
\[
\mathcal{H}_{t}=O_{0},A_{0},R_{1},O_{1},...,O_{t-1},A_{t-1},R_{t},O_{t}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Markov Decision Processes
\end_layout

\begin_layout Standard
Markov Decision Processes (MDPs) are a useful mathematical framework, defined
 as:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A decision process is Markov if
\begin_inset Formula 
\[
p\left(r,s|S_{t},A_{t}\right)=p\left(r,s|\mathcal{H}_{t},A_{t}\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This means that the current state is the only information needed to make
 a decision, we don't need the full story.
 For example, think in a chess game: there are many ways to arrive to a
 certain position, but it really does not matter how to got to the position,
 the past does not affect your choice now.
\end_layout

\begin_layout Standard
In order for a process to be Markov, full observability is required.
 When the situation is of 
\series bold
partial observability
\series default
, the observations are not Markovian, so using the observation as state
 is not enough to make the decision.
 This is called a 
\series bold
partially observable Markov decision process (POMDP)
\series default
.
 Note that the environment state can still be Markov, but the agent does
 not know it.
 In this case, we might be able to construct a Markov agent state.
\end_layout

\begin_layout Standard
In the general case, the agent state is a function of the history:
\begin_inset Formula 
\[
S_{t+1}=u\left(S_{t},A_{t},R_{t+1},O_{t+1}\right),
\]

\end_inset

 where 
\begin_inset Formula $u$
\end_inset

 is a 
\series bold
state update function
\series default
.
\end_layout

\begin_layout Standard
Usually, the agent state is much smaller than the environment state.
\end_layout

\begin_layout Example
A not Markov process:
\end_layout

\begin_layout Example
Consider the following maze to be the full environment:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado2.png

\end_inset


\end_layout

\end_deeper
\begin_layout Example
And consider the following observations:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado3.png

\end_inset


\begin_inset Graphics
	filename pegado4.png

\end_inset


\end_layout

\end_deeper
\begin_layout Example
They are indistinguishable! This process is not Markov, because only taking
 into account the current state, we cannot identify where we are.
\end_layout

\begin_layout Standard
To deal with partial observability, agent can construct suitable state represent
ations.
 Some examples of agent states are:
\end_layout

\begin_layout Itemize
Last observation: 
\begin_inset Formula $S_{t}=O_{t}$
\end_inset

 (might not be enough).
\end_layout

\begin_layout Itemize
Complete history: 
\begin_inset Formula $S_{t}=\mathcal{H}_{t}$
\end_inset

 (might be too large).
\end_layout

\begin_layout Itemize
A generic update: 
\begin_inset Formula $S_{t}=u\left(S_{t-1},A_{t-1},R_{t},O_{t}\right)$
\end_inset

 (but how to design 
\begin_inset Formula $u$
\end_inset

?)
\end_layout

\begin_layout Standard
Constructing a fully Markovian agent state is often not feasible and, more
 importantly, the state should allow for good policies and value predictions.
\end_layout

\begin_layout Subsection
Policies
\end_layout

\begin_layout Standard
As we saw, a 
\series bold
policy
\series default
 defines the agent's behavior: it is a map from the agent state to an action.
 Policies can be deterministic,
\begin_inset Formula 
\[
A=\pi\left(S\right),
\]

\end_inset

 or stochastic,
\begin_inset Formula 
\[
\pi\left(A|S\right)=p\left(A|S\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Value Functions
\end_layout

\begin_layout Standard
We saw the value before, which is the expected return.
 However, it is usual to introduce a 
\series bold
discount factor
\series default
, 
\begin_inset Formula $\gamma\in\left[0,1\right]$
\end_inset

, which trades off importance of immediate and long-term rewards.
 This way, the value becomes
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[G_{t}|S_{t}=s,\pi\right]=\mathbb{E}\left[R_{t+1}+\gamma R_{t+2}+\gamma^{2}R_{t+3}+...|S_{t}=s,\pi\right].
\]

\end_inset

 The value depends on the policy, 
\begin_inset Formula $\pi$
\end_inset

, and can be used to evaluate the desirability of states, as well as to
 select between actions.
\end_layout

\begin_layout Standard
Note the role of the discount factor: the higher it is, the higher the focus
 on long term outcomes.
\end_layout

\begin_layout Standard
Now, using the recursive expression of the return, 
\begin_inset Formula $G_{t}=R_{t+1}+\gamma G_{t+1}$
\end_inset

, we can rewrite the value as
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right)|S_{t}=a,A_{t}\sim\pi\left(s\right)\right],
\]

\end_inset

 where 
\begin_inset Formula $A\sim\pi\left(s\right)$
\end_inset

 means 
\begin_inset Formula $A$
\end_inset

 is chosen by policy 
\begin_inset Formula $\pi$
\end_inset

 in state 
\begin_inset Formula $s$
\end_inset

.
 This is known as a 
\series bold
Bellman equation
\series default
.
 A similar equation holds for the optimal value, i.e., the highest possible
 value:
\begin_inset Formula 
\[
v_{*}\left(s\right)=\max_{a}\mathbb{E}\left[R_{t+1}+\gamma v_{*}\left(S_{t+1}\right)|S_{t}=s,A_{t}=a\right].
\]

\end_inset

 Note how this does not depend on a policy, it is just the maximum achievable
 value from the current state.
\end_layout

\begin_layout Subsubsection
Value Function Approximations
\end_layout

\begin_layout Standard
Agents often approximate value functions, and with an accurate value function
 approximation, the agent can behave optimally, or very well, even in intractabl
y big domains.
\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
A 
\series bold
model
\series default
 predicts what the environment will do next.
 For example, 
\begin_inset Formula $\mathcal{P}$
\end_inset

 predicts the next state, given the current state and an action:
\begin_inset Formula 
\[
\mathcal{P}\left(s,a,s'\right)\approx p\left(S_{t+1}=s'|S_{t}=s,A_{t}=a\right).
\]

\end_inset

 Or 
\begin_inset Formula $\mathcal{R}$
\end_inset

 predicts the next immediate reward:
\begin_inset Formula 
\[
\mathcal{R}\left(s,a\right)\approx\mathbb{E}\left[R_{t+1}|S_{t}=s,A_{t}=a\right].
\]

\end_inset

 Note that a model does not immediately give us a good policy! We still
 need to plan and see how actions and states are related.
 
\end_layout

\begin_layout Example
Consider the following maze, where the rewards are -1 per time-step, the
 actions are to go N, E, S and W, and the states are the agent's location:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="10">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

Start
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

End
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
The following arrows represent the policy, 
\begin_inset Formula $\pi\left(s\right)$
\end_inset

, for each state 
\begin_inset Formula $s$
\end_inset

:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="10">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

Start
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado8.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado8.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado8.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado9.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado6.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado8.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\begin_inset Graphics
	filename pegado5.png
	scale 30

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

End
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
In the following one, the numbers represent the value 
\begin_inset Formula $v_{\pi}\left(s\right)$
\end_inset

 of each state 
\begin_inset Formula $s$
\end_inset

:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="10">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-13
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-12
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-11
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

Start
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-15
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-12
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-16
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-17
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-6
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-18
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-19
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-24
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-23
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-21
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset

End
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
rowcolor{black}
\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{white}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
The grid layout represents the partial transition model 
\begin_inset Formula $\mathcal{P}_{ss'}^{a}$
\end_inset

, and numbers represent the immediate reward, 
\begin_inset Formula $\mathcal{R}_{ss'}^{a}$
\end_inset

 from each state 
\begin_inset Formula $s$
\end_inset

, which is -1 for all 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $s'$
\end_inset

 in this case.
\end_layout

\begin_layout Subsection
Agent categories
\end_layout

\begin_layout Standard
An agent is 
\series bold
model free
\series default
 when the behavior of the environment is not known.
 The agent needs a policy or a value function to operate and there is no
 model.
 On the other hand, it is 
\series bold
model based
\series default
 when the environment is known by means of a model.
 In this case, a policy and a value function might be optional, since it
 is possible that the agent can operate just knowing the model.
\end_layout

\begin_layout Standard
Model free agents are simpler, while model based agents are more sample
 efficient.
\end_layout

\begin_layout Standard
Another categorization is the following:
\end_layout

\begin_layout Itemize
Value based: there is no policy, it is implicit in the value function.
\end_layout

\begin_layout Itemize
Policy based: there is no value function, the model operates only by means
 of the policy.
\end_layout

\begin_layout Itemize
Actor critic: they have both a policy and a value function.
\end_layout

\begin_layout Subsection
Subproblems of RL
\end_layout

\begin_layout Standard

\series bold
Prediction 
\series default
consists in evaluating the future, for a given policy, i.e., what are the
 values in each state?
\end_layout

\begin_layout Standard

\series bold
Control
\series default
 refers to the problem of optimising the future to find the best policy,
 i.e., which actions to take?
\end_layout

\begin_layout Standard
These two problems are strongly related, because the best actions to take
 will be decided using our predictions about the future:
\begin_inset Formula 
\[
\pi_{*}\left(s\right)=\arg\max_{\pi}v_{\pi}\left(s\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Two fundamental problems in RL are:
\end_layout

\begin_layout Itemize
Learning: the environment is initially unknown and the agent interacts with
 it to learn.
\end_layout

\begin_layout Itemize
Planning/search: a model of the environment is given or learnt, and the
 agent plans in this model.
\end_layout

\begin_layout Standard
In order to learn, we need to define all components of the problem as functions:
\end_layout

\begin_layout Itemize
Policy: 
\begin_inset Formula $\pi:S\rightarrow A$
\end_inset

 (or probabilities over 
\begin_inset Formula $A$
\end_inset

).
\end_layout

\begin_layout Itemize
Value functions: 
\begin_inset Formula $v:S\rightarrow\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Itemize
Models: 
\begin_inset Formula $p:S\rightarrow S$
\end_inset

 or 
\begin_inset Formula $r:S\rightarrow\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Itemize
State update: 
\begin_inset Formula $u:S\times O\rightarrow S$
\end_inset

.
\end_layout

\begin_layout Standard
Then, we can use, for example, neural networks and deep learning techniques
 to learn.
 But we do need to be careful, because in RL it is usual to violate assumptios
 made in supervised learning, such as having i.i.d.
 samples, or stationarity.
\end_layout

\begin_layout Section
Markov Decision Processes
\end_layout

\begin_layout Standard
We saw the notion of MDP, and now we formalize it:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A 
\series bold
Markov Decision Process (MDP)
\series default
 is a tuple 
\begin_inset Formula $\left(S,A,p,\gamma\right)$
\end_inset

 where:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $S$
\end_inset

 is the set of all possible states with the Markov Property.
\end_layout

\begin_layout Itemize
\begin_inset Formula $A$
\end_inset

 is the set of all possible actions.
\end_layout

\begin_layout Itemize
\begin_inset Formula $p\left(r,s'|s,a\right)$
\end_inset

 is the joint probability of a reward, 
\begin_inset Formula $r$
\end_inset

, and next state, 
\begin_inset Formula $s'$
\end_inset

, given a state 
\begin_inset Formula $s$
\end_inset

 and an action 
\begin_inset Formula $a$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\gamma\in\left[0,1\right]$
\end_inset

 is a discount factor that trades off later rewards to earlier ones.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Remark
\begin_inset Formula $p$
\end_inset

 defines the dynamics of the problem.
\end_layout

\begin_layout Remark
Sometimes, it is useful to marginalise out the state transitions or expected
 rewards:
\begin_inset Formula 
\[
p\left(s'|s,a\right)=\sum_{r}p\left(s',r|s,a\right),
\]

\end_inset

 to obtain the probability of arriving to a certain state.
\end_layout

\begin_layout Remark
Also, the expected reward:
\begin_inset Formula 
\[
\mathbb{E}\left[R|s,a\right]=\sum_{r}r\sum_{s'}p\left(r,s'|s,a\right).
\]

\end_inset


\end_layout

\begin_layout Standard
There is an alternative equivalent definition, which introduces the notion
 of the expected reward into the concept, and takes it out of the probabity
 function:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A MDP is a tuple 
\begin_inset Formula $\left(S,A,p,r,\gamma\right)$
\end_inset

 where:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $S$
\end_inset

 is the set of all possible states with the Markov Property.
\end_layout

\begin_layout Itemize
\begin_inset Formula $A$
\end_inset

 is the set of all possible actions.
\end_layout

\begin_layout Itemize
\begin_inset Formula $p\left(s'|s,a\right)$
\end_inset

 is the probability of transitioning to 
\begin_inset Formula $s'$
\end_inset

, fiven a state 
\begin_inset Formula $s$
\end_inset

 and an action 
\begin_inset Formula $a$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $r:S\times A\rightarrow\mathbb{R}$
\end_inset

 is the expected reward, achieved on a transition starting in 
\begin_inset Formula $\left(s,a\right)$
\end_inset

,
\begin_inset Formula 
\[
r=\mathbb{E}\left[R|s,a\right].
\]

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\gamma\in\left[0,1\right]$
\end_inset

 is a discount factor that trades off later rewards to earlier ones.
\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
Now, we have to clarify what is the Markov Property:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Consider a sequence of random variables, 
\begin_inset Formula $\left\{ S_{t}\right\} _{t\in\mathbb{N}}$
\end_inset

, indexed by time and taken from a set of states 
\begin_inset Formula $S$
\end_inset

.
 Consider also the set of actions 
\begin_inset Formula $A$
\end_inset

 and rewards in 
\begin_inset Formula $\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Definition
A state 
\begin_inset Formula $s$
\end_inset

 has the 
\series bold
Markov Property
\series default
 when, for all 
\begin_inset Formula $s'\in S$
\end_inset

,
\begin_inset Formula 
\[
p\left(S_{t+1}=s'|S_{t}=s\right)=p\left(S_{t+1}=s'|h_{t-1},S_{t}=s\right),
\]

\end_inset

 for all possible histories 
\begin_inset Formula $h_{t-1}=\left\{ S_{1},...,S_{t-1},A_{1},...,A_{t-1},R_{1},...,R_{t-1}\right\} $
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Therefore, in an MDP, the current state captures all relevant information
 from the history, it is a sufficient statistic of the past.
 So, once the state is known, the history may be thrown away.
\end_layout

\begin_layout Exercise
In an MDP, which of the following statemest are true?
\end_layout

\begin_deeper
\begin_layout Enumerate
\begin_inset Formula $p\left(S_{t+1}=s'|S_{t}=s,A_{t}=a\right)=p\left(S_{t+1}=s'|S_{1},...,S_{t-1},A_{1},...,A_{t},S_{t}=s\right)$
\end_inset

: false, the RHS does not condition on 
\begin_inset Formula $A_{t}=a$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $p\left(S_{t+1}=s'|S_{t}=s,A_{t}=a\right)=p\left(S_{t+1}=s'|S_{1},...,S_{t-1},S_{t}=s,A_{t}=a\right)$
\end_inset

: true.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $p\left(S_{t+1}=s'|S_{t}=s,A_{t}=a\right)=p\left(S_{t+1}=s'|S_{1},...,S_{t-1},S_{t}=s\right)$
\end_inset

: false, the RHS does not condition on 
\begin_inset Formula $A_{t}=a$
\end_inset

.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $p\left(R_{t+1}=r,S_{t+1}=s'|S_{t}=s\right)=p\left(R_{t+1}=r,S_{t+1}=s'|S_{1},...,S_{t-1},S_{t}=s\right)$
\end_inset

: true.
\end_layout

\end_deeper
\begin_layout Standard
It is also worth noting that most MDPs are discounted, and there are several
 reasons for these:
\end_layout

\begin_layout Itemize
Problem specification: immediate rewards may actually be more valuable.
 For instance, animal/human behavior shows preference for immediate reward.
\end_layout

\begin_layout Itemize
Solution side: it is mathematically convenient to discount rewards, because
 it allows for easier proofs of convergence, and avoids infinite returns
 in cyclic Markov processes.
\end_layout

\begin_layout Standard
As we outlined previously, the 
\series bold
goal of an RL agent
\series default
 is to find a behavior policy that maximises the expected return 
\begin_inset Formula $G_{t}$
\end_inset

.
 Recall our definition for value funtion
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[G_{t}|S_{t}=s,\pi\right].
\]

\end_inset

 Similarly, we can define the 
\series bold
state-action values
\series default
, as
\begin_inset Formula 
\[
q_{\pi}\left(s,a\right)=\mathbb{E}\left[G_{t}|S_{t}=s,A_{t}=a,\pi\right],
\]

\end_inset

 and there is the following connection between them:
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\sum_{a}\pi\left(a|s\right)q_{\pi}\left(s,a\right)=\mathbb{E}\left[q_{\pi}\left(S_{t},A_{t}\right)|S_{t}=s,\pi\right],\forall s\in S.
\]

\end_inset


\end_layout

\begin_layout Standard
Also, we can define the maximum possible value functions:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
The 
\series bold
optimal state value function
\series default
, 
\begin_inset Formula $v^{*}\left(s\right)$
\end_inset

, is the maximum value function over all policies,
\begin_inset Formula 
\[
v^{*}\left(s\right)=\max_{\pi}v_{\pi}\left(s\right).
\]

\end_inset

 The 
\series bold
optimal state-action value function
\series default
, 
\begin_inset Formula $q^{*}\left(s,a\right)$
\end_inset

, is the amximum state-action value function over all policies,
\begin_inset Formula 
\[
q^{*}\left(s,a\right)=\max_{\pi}q_{\pi}\left(s,a\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The optimal value function specifies the best possible performance in the
 MDP.
 We can consider the MDP to be solved when we know the optimal value function.
\end_layout

\begin_layout Standard
In addition, value functions allow us to define a partial ordering over
 policies, having
\begin_inset Formula 
\[
\pi\geq\pi'\iff v_{\pi}\left(s\right)\geq v_{\pi'}\left(s\right),\forall s\in S.
\]

\end_inset


\end_layout

\begin_layout Standard
With this partial ordering, the following theorem state that optimal policies
 exist for every MDP:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem

\series bold
Optimal Policies Theorem
\end_layout

\begin_layout Theorem
For any MDP:
\end_layout

\begin_deeper
\begin_layout Itemize
There exists an optimal policy 
\begin_inset Formula $\pi^{*}$
\end_inset

 that is better than or equal to all other policies,
\begin_inset Formula 
\[
\pi^{*}\geq\pi,\forall\pi.
\]

\end_inset


\end_layout

\begin_layout Itemize
All optimal policies achieve the optimal value function,
\begin_inset Formula 
\[
v^{\pi^{*}}\left(s\right)=v^{*}\left(s\right).
\]

\end_inset


\end_layout

\begin_layout Itemize
All optimal policies achieve the optimal state-action value function, 
\begin_inset Formula 
\[
q^{\pi^{*}}\left(s,a\right)=q^{*}\left(s,a\right).
\]

\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
To find an optimal policy, we can maximise over 
\begin_inset Formula $q^{*}\left(s,a\right)$
\end_inset

:
\begin_inset Formula 
\[
\pi^{*}\left(s,a\right)=\begin{cases}
1 & if\ a=\arg\max_{a\in A}q^{*}\left(s,a\right)\\
0 & otherwise
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
That is, the optimal policy is to take action 
\begin_inset Formula $a$
\end_inset

 in state 
\begin_inset Formula $s$
\end_inset

 if 
\begin_inset Formula $a$
\end_inset

 is the action that gives the highes state-action value given state 
\begin_inset Formula $s$
\end_inset

.
\end_layout

\begin_layout Remark
There is always a deterministic optimal policy for any MDP, and we know
 
\begin_inset Formula $q^{*}\left(s,a\right)$
\end_inset

, we know the optimal policy immediately.
\end_layout

\begin_layout Remark
Also, there can be multiple optimal policies, and if multiple actions maximize
 
\begin_inset Formula $q_{*}\left(s,\cdot\right)$
\end_inset

, we can pick any of them.
\end_layout

\begin_layout Standard
Now, recall the Bellman Equations we saw previously.
 The following theorem explains how to express the value functions by means
 of these equations:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem

\series bold
Bellman Expectation Equations
\end_layout

\begin_layout Theorem
Given an MDP, 
\begin_inset Formula $M=\left(S,A,p,r,\gamma\right)$
\end_inset

, for any policy 
\begin_inset Formula $\pi$
\end_inset

, the value functions obey the followin expectation equations:
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\sum_{a}\pi\left(s,a\right)\left[r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)v_{\pi}\left(s'\right)\right],
\]

\end_inset

 and
\begin_inset Formula 
\[
q_{\pi}\left(s,a\right)=r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)\sum_{a'\in A}\pi\left(a'|s'\right)q_{\pi}\left(s',a'\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem

\series bold
Bellman Optimality Equations
\end_layout

\begin_layout Theorem
Given an MDP, 
\begin_inset Formula $M=\left(S,A,p,r,\gamma\right)$
\end_inset

, the optimal value functions obey the following expectation equations:
\begin_inset Formula 
\[
v^{*}\left(s\right)=\max_{a\in A}\left[r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)v^{*}\left(s'\right)\right],
\]

\end_inset


\begin_inset Formula 
\[
q^{*}\left(s,a\right)=r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)\max_{a'\in A}q^{*}\left(s',a'\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Remark
There can not be a policy with a higher value than 
\begin_inset Formula $v^{*}\left(s\right)=\max_{\pi}v_{\pi}\left(s\right),\forall s$
\end_inset

.
\end_layout

\begin_layout Standard

\emph on
Intuition on the proof for the Bellman Optimality 
\emph default
Equations
\emph on
:
\end_layout

\begin_layout Standard
An optimal policy can be found by maximising over 
\begin_inset Formula $q^{*}\left(s,a\right)$
\end_inset

,
\begin_inset Formula 
\[
\pi^{*}\left(s,a\right)=\begin{cases}
1 & if\ a=\arg\max_{a\in A}q^{*}\left(s,a\right),\\
0 & otherwise.
\end{cases}
\]

\end_inset

 Applyin the Bellman Expectation Equation:
\begin_inset Formula 
\begin{align*}
q_{\pi^{*}}\left(s,a\right)= & r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)\sum_{a'\in A}\pi^{*}\left(a'|s'\right)q_{\pi^{*}}\left(s',a'\right)\\
= & r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)\max_{a'\in A}q^{*}\left(s',a'\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can also express the Bellman equations in matrix form, as
\begin_inset Formula 
\[
V=R^{\pi}+\gamma P^{\pi}V,
\]

\end_inset

 where 
\begin_inset Formula $v_{i}=v\left(s_{i}\right),$
\end_inset

 
\begin_inset Formula $R_{i}^{\pi}=\mathbb{E}\left[R_{t+1}|S_{t}=s_{i},A_{t}\sim\pi\left(S_{t}\right)\right]$
\end_inset

 and 
\begin_inset Formula $P_{ij}^{\pi}=p\left(s_{j}|s_{i}\right)=\sum_{a}\pi\left(a|s_{i}\right)p\left(s_{j}|s_{i},a\right)$
\end_inset

.
\end_layout

\begin_layout Standard
This is a linear equations, that can be solved directly:
\begin_inset Formula 
\begin{align*}
\left(I-\gamma P^{\pi}\right)V= & R^{\pi}\\
V= & \left(I-\gamma P^{\pi}\right)^{-1}R^{\pi}.
\end{align*}

\end_inset

 The computational complexity is 
\begin_inset Formula $O\left(\left|S\right|^{3}\right)$
\end_inset

, making this only feasible for small problems.
 This makes it helpful to design other methods for larger problems.
 For example, there are iterative methods such as dynamic programming, monte-cal
ro evaluation and temporal-difference learning.
\end_layout

\begin_layout Subsection
Solving Reinforcement Learning Problems with Bellman Equations
\end_layout

\begin_layout Enumerate
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
Pb1.
\end_layout

\end_inset

 Estimating 
\begin_inset Formula $v_{\pi}$
\end_inset

 or 
\begin_inset Formula $q_{\pi}$
\end_inset

 is called 
\series bold
policy evaluation
\series default
, or 
\series bold
prediction
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
Given a policy, what is my expected return under that behavior?
\end_layout

\begin_layout Enumerate
Given this treatment protocol/trading strategy, what is my expected return?
\end_layout

\end_deeper
\begin_layout Enumerate
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
Pb2.
\end_layout

\end_inset

 Estimating 
\begin_inset Formula $v_{*}$
\end_inset

 or 
\begin_inset Formula $q_{*}$
\end_inset

 is sometimes called 
\series bold
control
\series default
, because these can be used for 
\series bold
policy optimisation
\series default
:
\end_layout

\begin_deeper
\begin_layout Enumerate
What is the optimal way of behaving? What is the optimal value function?
\end_layout

\begin_layout Enumerate
What is the optimal treatment? What is the optimal control policy to minimise
 time, fuel consumption, etc?
\end_layout

\end_deeper
\begin_layout Exercise
Consider the following MDP:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename mdp_exercise.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Exercise
The actions have a 0.9 probability of success and with 0.1 probability we
 remain in the same state.
\end_layout

\begin_layout Exercise
\begin_inset Formula $R_{t}=0$
\end_inset

 for all transitions that end up in 
\begin_inset Formula $S_{0}$
\end_inset

 and 
\begin_inset Formula $R_{t}=-1$
\end_inset

 for all other transitions.
\end_layout

\begin_layout Exercise
Discount factor: 
\begin_inset Formula $\gamma=0.9$
\end_inset

.
\end_layout

\begin_layout Exercise
Questions:
\end_layout

\begin_deeper
\begin_layout Itemize
What is 
\begin_inset Formula $v_{\pi}$
\end_inset

 for 
\begin_inset Formula $\pi\left(s\right)=a_{1}\left(\rightarrow\right),\forall s$
\end_inset

?
\end_layout

\begin_deeper
\begin_layout Standard
According to the Bellman Equations:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s\right)= & \sum_{a}\pi\left(s,a\right)\left[r\left(s,a\right)+\gamma\sum_{s'}p\left(s'|a,s\right)v_{\pi}\left(s'\right)\right],
\end{align*}

\end_inset

 
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{0}\right)= & \pi\left(s_{0},a_{1}\checkmark\right)\left[r\left(s_{0},a_{1}\checkmark\right)+0.9\cdot\left[p\left(s_{1}|a_{1},s_{0}\right)v_{\pi}\left(s_{1}\right)+p\left(s_{2}|a_{1},s_{0}\right)v_{\pi}\left(s_{2}\right)\right]\right]+\pi\left(s_{0},a_{1}\times\right)\cdot\left[r\left(s_{0},a_{1}\times\right)+0.9\cdot p\left(s_{0}|s_{0},a_{1}\times\right)v_{\pi}\left(s_{0}\right)\right]\\
= & 0.9\cdot\left[-1+0.9\cdot\left[0+v_{\pi}\left(s_{2}\right)\right]\right]+0.09\cdot v_{\pi}\left(s_{0}\right)\\
= & -0.9+0.81\cdot v_{\pi}\left(s_{2}\right)+0.09\cdot v_{\pi}\left(s_{0}\right).
\end{align*}

\end_inset

Isolating, 
\begin_inset Formula $v_{\pi}\left(s_{0}\right)$
\end_inset

, we get
\begin_inset Formula 
\[
0.91v_{\pi}\left(s_{0}\right)=-0.9+0.81\cdot v_{\pi}\left(s_{2}\right)\implies v_{\pi}\left(s_{0}\right)=-0.99+0.89\cdot v_{\pi}\left(s_{2}\right).
\]

\end_inset

 Now, let's go for 
\begin_inset Formula $v_{\pi}\left(s_{2}\right)$
\end_inset

: 
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{2}\right)= & \pi\left(s_{2},a_{1}\checkmark\right)\left[r\left(s_{2},a_{1}\checkmark\right)+0.9\cdot\left[p\left(s_{0}|a_{1},s_{2}\right)v_{\pi}\left(s_{0}\right)+p\left(s_{1}|a_{1},s_{2}\right)v_{\pi}\left(s_{1}\right)\right]\right]+\pi\left(s_{2},a_{1}\times\right)\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{2}\right)\right]\\
= & 0.9\cdot\left[0+0.9\cdot\left[v_{\pi}\left(s_{0}\right)+0\right]\right]+0.1\left[-1+0.9\cdot v_{\pi}\left(s_{2}\right)\right]\\
= & 0.81\cdot v_{\pi}\left(s_{0}\right)-0.1+0.09\cdot v_{\pi}\left(s_{2}\right)\\
= & 0.81\cdot\left(-1+0.9\cdot v_{\pi}\left(s_{2}\right)\right)-0.1+0.09\cdot v_{\pi}\left(s_{2}\right)\\
= & -0.91+0.82\cdot v_{\pi}\left(s_{2}\right).
\end{align*}

\end_inset

Therefore,
\begin_inset Formula 
\[
v_{\pi}\left(s_{2}\right)=\frac{-0.91}{0.18}=-5.06.
\]

\end_inset

 This means that
\begin_inset Formula 
\[
v_{\pi}\left(s_{0}\right)=-5.49.
\]

\end_inset

 Finally, 
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{1}\right)= & \pi\left(s_{1},a_{1}\right)\left[r\left(s_{1},a_{1}\right)+0.9\cdot\left[p\left(s_{0}|a_{1},s_{1}\right)v_{\pi}\left(s_{0}\right)+p\left(s_{2}|a_{1},s_{1}\right)v_{\pi}\left(s_{2}\right)\right]\right]+\pi\left(s_{1},a_{1}\times\right)\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{1}\right)\right]\\
= & 0.9\cdot\left[0+0.9\cdot\left[-5.49+0\right]\right]+0.1\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{1}\right)\right]\\
= & -4.45-0.1+0.09\cdot v_{\pi}\left(s_{1}\right).\\
= & -4.55+0.09\cdot v_{\pi}\left(s_{1}\right).
\end{align*}

\end_inset

 So
\begin_inset Formula 
\[
v_{\pi}\left(s_{1}\right)=\frac{-4.55}{0.91}=-5.
\]

\end_inset

 That is, 
\begin_inset Formula $v_{\pi}\left(s_{0}\right)=-5.49,v_{\pi}\left(s_{1}\right)=-5$
\end_inset

 and 
\begin_inset Formula $v_{\pi}\left(s_{2}\right)=-5.06$
\end_inset

.
\end_layout

\end_deeper
\begin_layout Itemize
What is 
\begin_inset Formula $v_{\pi}$
\end_inset

 for the uniformly random policy?
\end_layout

\begin_deeper
\begin_layout Standard
This is: with probability 0.1, stay in the same state, with probability 0.45
 choose 
\begin_inset Formula $a_{1}$
\end_inset

 and with probability 0.45 choose 
\begin_inset Formula $a_{2}$
\end_inset

.
 For 
\begin_inset Formula $s_{0}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{0}\right)= & 0.1\cdot0.9\cdot v_{\pi}\left(s_{0}\right)+0.45\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{2}\right)\right]+0.45\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{1}\right)\right]\\
= & 0.09\cdot v_{\pi}\left(s_{0}\right)-0.9+0.405\cdot v_{\pi}\left(s_{2}\right)+0.405\cdot v_{\pi}\left(s_{1}\right),
\end{align*}

\end_inset

 so
\begin_inset Formula 
\[
v_{\pi}\left(s_{0}\right)=-0.99+0.445\cdot v_{\pi}\left(s_{2}\right)+0.445\cdot v_{\pi}\left(s_{1}\right).
\]

\end_inset

 For 
\begin_inset Formula $s_{1}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{1}\right)= & 0.1\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{1}\right)\right]+0.45\cdot\left[0+0.9\cdot v_{\pi}\left(s_{0}\right)\right]+0.45\cdot\left[0+0.9\cdot v_{\pi}\left(s_{0}\right)\right]\\
= & -0.1+0.09\cdot v_{\pi}\left(s_{1}\right)+0.81\cdot v_{\pi}\left(s_{0}\right),
\end{align*}

\end_inset

so
\begin_inset Formula 
\[
v_{\pi}\left(s_{1}\right)=-0.1+0.9\cdot v_{\pi}\left(s_{0}\right).
\]

\end_inset

 For 
\begin_inset Formula $s_{2}$
\end_inset

:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{2}\right)= & 0.1\cdot\left[-1+0.9\cdot v_{\pi}\left(s_{2}\right)\right]+0.45\cdot\left[0+0.9\cdot v_{\pi}\left(s_{0}\right)\right]+0.45\cdot\left[0+0.9\cdot v_{\pi}\left(s_{0}\right)\right]\\
= & -0.1+0.09\cdot v_{\pi}\left(s_{2}\right)+0.81\cdot v_{\pi}\left(s_{0}\right),
\end{align*}

\end_inset

 so
\begin_inset Formula 
\[
v_{\pi}\left(s_{2}\right)=-0.1+0.9\cdot v_{\pi}\left(s_{0}\right).
\]

\end_inset

 Therefore_
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{0}\right)= & -0.99+0.89\cdot\left(-0.1+0.9\cdot v_{\pi}\left(s_{0}\right)\right)\\
= & -0.99-0.089+0.8\cdot v_{\pi}\left(s_{0}\right)\\
= & -1.08+0.8\cdot v_{\pi}\left(s_{0}\right).
\end{align*}

\end_inset

 That is,
\begin_inset Formula 
\[
v_{\pi}\left(s_{0}\right)=-5.4.
\]

\end_inset

 And,
\begin_inset Formula 
\[
v_{\pi}\left(s_{1}\right)=v_{\pi}\left(s_{2}\right)=-4.96.
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Itemize
Same policy evaluation problems for 
\begin_inset Formula $\gamma=0$
\end_inset

? What do you notice?
\end_layout

\begin_deeper
\begin_layout Standard
First, 
\begin_inset Formula $\pi\left(s\right)=a_{1}\left(\rightarrow\right),\forall s$
\end_inset

:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{0}\right)= & 0.1\cdot0+0.9\cdot\left(-1\right)\\
= & -0.9.
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{1}\right)= & 0.1\cdot\left(-1\right)+0.9\cdot\left(0\right)\\
= & -0.1.
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{2}\right)= & -0.1.
\end{align*}

\end_inset

 Second, 
\begin_inset Formula $\pi\left(s\right)$
\end_inset

 the random policy:
\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{0}\right)= & 0.1\cdot0+0.45\cdot\left(-1\right)+0.45\cdot\left(-1\right)\\
= & -0.9.
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{1}\right)= & 0.1\cdot\left(-1\right)+0.9\cdot\left(0\right)\\
= & -0.1.
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
v_{\pi}\left(s_{2}\right)= & -0.1.
\end{align*}

\end_inset

 We can observe that if we don't take the discount factor into account,
 two very different policies can give us the same (short term) values.
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection
Dynamic Programming
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Plain Layout
\begin_inset Argument 1
status open

\begin_layout Plain Layout
colback=green!5!white,colframe=cyan!75!black
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
Dynamic programming refers to a collection of algorithms that can be used
 to compute optimal policies given a perfect model of the environment as
 a Markov Decision Process (MDP).
\end_layout

\begin_layout Plain Layout
\noindent
\align right
-Sutton & Barto, 2018
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We will discuss several dynamic programming methods to solve MDPs, all of
 which consist of two important parts:
\end_layout

\begin_layout Itemize
Policy evaluation.
\end_layout

\begin_layout Itemize
Policy improvement.
\end_layout

\begin_layout Subsubsection
Policy Evaluation
\end_layout

\begin_layout Standard
We start by discussing how to estimate
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right)|s,\pi\right].
\]

\end_inset

 The idea is to turn the equality into an update rule.
 The process is described in the following algorithm:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

def policy_eval(S, R, pi, gamma):
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	v = [0 for s in S]
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	repeat until converge:
\end_layout

\begin_layout Plain Layout

		for s in S:
\end_layout

\begin_layout Plain Layout

			v_new(s) = E[R + gamma * v(S_t+1) | S_t = s, pi]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		v = v_new
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	return v
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that this algorithm always converge under appropriate conditions, like
 
\begin_inset Formula $\gamma<1$
\end_inset

.
 We will delve into this later.
\end_layout

\begin_layout Example
Policy Evaluation example.
\end_layout

\begin_layout Example
Take the following MDP:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{red}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
6
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
11
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
13
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cellcolor{red}
\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
The possible actions are to go up, down, left, right and when you reach
 the red cells, you finish.
 Each transitions costs -1 point.
\end_layout

\begin_layout Example
Let's evaluate the random policy with 
\begin_inset Formula $\gamma=1$
\end_inset

.
\end_layout

\begin_layout Example
Initialization:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 1: we do
\begin_inset Formula 
\[
v\left(s\right)=\mathbb{E}\left[R+\gamma v\left(S\right)|S,\pi\right],
\]

\end_inset

 so for example, for cell 
\begin_inset Formula $\left(1\right)$
\end_inset

, it is:
\begin_inset Formula 
\[
v\left(1\right)=\frac{1}{3}\left(-1+1\cdot0\right)\cdot3=-1.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 2:
\begin_inset Formula 
\[
v\left(1\right)=\frac{1}{3}\left(-1+1\cdot0\right)+\frac{2}{3}\left(-1-1\right)=-1.7.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 3:
\begin_inset Formula 
\[
v\left(1\right)=\frac{1}{3}\left(-1+0\right)+\frac{2}{3}\left(-1-2\right)=-2.3.
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
–3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
And so on...
 It would converge at
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-18
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-18
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection
Policy Improvement
\end_layout

\begin_layout Standard
We can use the values computed with policy evaluation to improve the policy.
 The simplest way to achieve this is with a 
\series bold
greedy policy improvement
\series default
 approach, which is as follows:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

def policy_improvement(S, R, pi, gamma)
\end_layout

\begin_layout Plain Layout

	pi_new = {}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	v = [0 for s in S]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	for s in S:
\end_layout

\begin_layout Plain Layout

		v(s) = policy_eval(S, R, pi, gamma)
\end_layout

\begin_layout Plain Layout

		pi_new[v] = argmax_a E[R + gamma*v(S_t+1) | S_t = s, A_t = a]
\end_layout

\begin_layout Plain Layout

		pi = pi_new
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	return pi_new
\end_layout

\end_inset


\end_layout

\begin_layout Claim
It is possible to show that
\begin_inset Formula 
\[
v_{\pi_{new}}\left(s\right)\geq v_{\pi}\left(s\right),\forall s.
\]

\end_inset


\end_layout

\begin_layout Example
We can use this greedy approach combined with the previous example:
\end_layout

\begin_layout Example
Initialization, with random policy:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 1:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 2:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step 3:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
–3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Step converged:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-22
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-18
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-18
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-20
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-14
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\leftarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\downarrow,\leftarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\downarrow$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\uparrow,\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rightarrow$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Observe how in the second iteration we already found the optimal policy!
\end_layout

\begin_layout Example
In this example, we showed how we can use evaluation to improve our policy,
 and in fact we obtained the optimal policy.
 However, the greedy approach does not always ensure reaching the optimal
 policy.
\end_layout

\begin_layout Standard
This approach is called 
\series bold
policy iteration
\series default
:
\end_layout

\begin_layout Itemize
Policy evaluation: estimate 
\begin_inset Formula $v^{\pi}$
\end_inset

.
\end_layout

\begin_layout Itemize
Policy improvement: generate 
\begin_inset Formula $\pi'\geq\pi$
\end_inset

.
\end_layout

\begin_layout Standard
It is natural to ask if policy evaluation need to converge to 
\begin_inset Formula $v^{\pi}$
\end_inset

 or if we should stop the evaluation at some point.
 Ways to stop it are to put a threshold of minimum change between iterations,
 or simply after 
\begin_inset Formula $k$
\end_inset

 iterations.
 One extreme, which is in fact quite usual in practice, is to stop after
 
\begin_inset Formula $k=1$
\end_inset

, which is equivalent to 
\series bold
value iteration
\series default
:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

def value_iter(S, R, pi, gamma):
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	v = [0 for s in S]
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	repeat until converge
\end_layout

\begin_layout Plain Layout

		for s in S:
\end_layout

\begin_layout Plain Layout

			v_new(s) = max_a E[R + gamma * v(S_t+1) | S_t = s, A_t = a]
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

		v = v_new
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	return v
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the following table, we sum up the different approaches:
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Problem
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bellman Equation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Algorithm
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Prediction
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bellman Expectation Eq
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Iterative Policy Eval
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Control
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bellman Expectation Eq + (Greedy) Policy Improvement
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Policy Iteration
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Control
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bellman Optimality Eq
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Value Iteration
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
Observations
\end_layout

\begin_layout Itemize
The algorithms are based on state-value functions 
\begin_inset Formula $v_{\pi}\left(s\right)$
\end_inset

 or 
\begin_inset Formula $v^{*}\left(s\right)$
\end_inset

, with complexity 
\begin_inset Formula $O\left(\left|A\right|\left|S\right|^{2}\right)$
\end_inset

 per iteration.
\end_layout

\begin_layout Itemize
It could also be applied to action-value functions 
\begin_inset Formula $q_{\pi}\left(s,a\right)$
\end_inset

 or 
\begin_inset Formula $q^{*}\left(s,a\right)$
\end_inset

, with complexity 
\begin_inset Formula $O\left(\left|A\right|^{2}\left|S\right|^{2}\right)$
\end_inset

 per iteration.
\end_layout

\begin_layout Subsection
Extensions to Dynamic Programming
\end_layout

\begin_layout Subsubsection
Asynchronous Dynamic Programming
\end_layout

\begin_layout Standard
DP methods described so far used 
\series bold
synchronous
\series default
 updates, meaning all states are updated in parallel.
 In contrast, 
\series bold
asynchronous DP
\series default
 backs up states individually, in any order.
 This can significantly reduce computation, and it is guaranteed to converge
 if all states continue to be selected.
\end_layout

\begin_layout Standard
We are going to see three approaches for ADP:
\end_layout

\begin_layout Paragraph
In-Place DP
\end_layout

\begin_layout Standard
Before, with synchronous value iteration, we stored two copies of the value
 function:
\begin_inset Formula 
\[
v_{new}\left(s\right)=\max_{a}\mathbb{E}\left[R_{t+1}+\gamma v\left(S_{t+1}\right)|S_{t}=s,A_{t}=a\right],
\]

\end_inset


\begin_inset Formula 
\[
v=v_{new}.
\]

\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
Now, in-place value iteration stores only one copy of the value function,
 doing:
\begin_inset Formula 
\[
v\left(s\right)=\max_{a}\mathbb{E}\left[R_{t+1}+\gamma v\left(S_{t+1}\right)|S_{t}=s,A_{t}=a\right].
\]

\end_inset


\end_layout

\begin_layout Paragraph
Prioritised Sweeping
\end_layout

\begin_layout Standard
We can use the magnitude of the Bellman error to guide the state selection.
 For example:
\begin_inset Formula 
\[
E=\left|\max_{a}\mathbb{E}\left[R_{t+1}+\gamma v\left(S_{t+1}\right)|S_{t}=s,A_{t}=a\right]-v\left(s\right)\right|.
\]

\end_inset

 We then backup the state with the largest remaining Bellman error, and
 update the Bellman error of affected states after each backup.
 This reuires knowledge of reverse dynamics (which are the predecessor states).
 It can be implemented efficiently with a priority queue.
\end_layout

\begin_layout Paragraph
Real-Time DP
\end_layout

\begin_layout Standard
The idea in this case is to only update states that are relevant to the
 agent.
 For example, if the agent is in state 
\begin_inset Formula $S_{t}$
\end_inset

, we update that state value, or the states that it expects to be in soon.
\end_layout

\begin_layout Paragraph
Full-Width backups
\end_layout

\begin_layout Standard
Standard DP uses full-width backups.
 This means that, for each backup, it being synchronous or asynchronous:
\end_layout

\begin_layout Itemize
Every successor state and action is considered.
\end_layout

\begin_layout Itemize
Using the true model of transitions and reward function.
\end_layout

\begin_layout Standard
DP is effective for medium-sized problems (with millions of states).
 For large problems DP suffers from the curse of dimensionality, since the
 number of states grows exponentially with the number of state variables,
 and even one full backup can be too expensive.
\end_layout

\begin_layout Paragraph
Sample Backups
\end_layout

\begin_layout Standard
This approach consists in using sample rewards and sample transitions 
\begin_inset Formula $\left(s,a,r,s'\right)$
\end_inset

 instead of the reward function 
\begin_inset Formula $R$
\end_inset

, and the transition dynamics, 
\begin_inset Formula $P$
\end_inset

.
 
\end_layout

\begin_layout Standard
It presents some advantages:
\end_layout

\begin_layout Itemize
It's model free: knowledge about the MDP is not required.
\end_layout

\begin_layout Itemize
Breaks the curse of dimensionality through sampling.
\end_layout

\begin_layout Itemize
Cost of backup is constant, independent of 
\begin_inset Formula $n=\left|S\right|$
\end_inset

.
\end_layout

\begin_layout Section
Model-Free Prediction
\end_layout

\begin_layout Subsection
Monte Carlo Algorithms
\end_layout

\begin_layout Standard
We can use experience samples to learn without a model.
 The direct sampling of episodes is called 
\series bold
Monte Carlo
\series default
, and this is a model-free approach, because we don't need knowledge about
 the MDP, only the samples.
\end_layout

\begin_layout Subsubsection
Monte Carlo Policy Evaluation
\end_layout

\begin_layout Standard
We consider sequential decision problems, and our goal is to learn 
\begin_inset Formula $v_{\pi}$
\end_inset

 from episodes of experience under policy 
\begin_inset Formula $\pi$
\end_inset

:
\begin_inset Formula 
\[
S_{1},A_{1},R_{2},...,S_{k}\sim\pi.
\]

\end_inset

 The 
\series bold
return
\series default
 is the total discounted reward, for an episode ending at time 
\begin_inset Formula $T<t$
\end_inset

:
\begin_inset Formula 
\[
G_{t}=R_{t+1}+\gamma R_{t+1}+...+\gamma^{T-t-1}R_{T}.
\]

\end_inset

 The 
\series bold
value function
\series default
 is the expected return:
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[G_{t}|S_{t}=s,\pi\right].
\]

\end_inset

 We could also use just the sample average return, instead of the expected
 return.
\end_layout

\begin_layout Subsubsection
First-Visit Monte Carlo Policy Evaluation
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

def FV_MC_PE:
\end_layout

\begin_layout Plain Layout

	# Initialization
\end_layout

\begin_layout Plain Layout

	foreach s:
\end_layout

\begin_layout Plain Layout

		N(s) = 0
\end_layout

\begin_layout Plain Layout

		G(s) = 0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	# Computation
\end_layout

\begin_layout Plain Layout

	loop:
\end_layout

\begin_layout Plain Layout

		# Sample episode
\end_layout

\begin_layout Plain Layout

		e_i = s[i,1], a[i,1], r[i,1], s[i,2], a[i,2], r[i,2], ..., s[i,T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		# Compute return from time step t onwards in episode i
\end_layout

\begin_layout Plain Layout

		G[i,t] = r[i,t] + gamma * r[i,t+1] + ...
 + gamma ** (T_i - 1) * r[i, T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		foreach time step t till the end of episode i:
\end_layout

\begin_layout Plain Layout

			s = e_i[i, t].state
\end_layout

\begin_layout Plain Layout

			if not visited[s, i]:
\end_layout

\begin_layout Plain Layout

				N(s) = N(s) + 1		# Increment total visits counter
\end_layout

\begin_layout Plain Layout

				G(s) = G(s) + G[i,t]	# Increment total return
\end_layout

\begin_layout Plain Layout

				V_pi(s) = G(s) / N(s) 	# Update estimate					
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Properties:
\end_layout

\begin_layout Itemize
\begin_inset Formula $V^{\pi}$
\end_inset

 is an unbiased estimator of the true 
\begin_inset Formula $\mathbb{E}_{\pi}\left[G_{t}|s_{t}=s\right]$
\end_inset

.
\end_layout

\begin_layout Itemize
By the law of large numbers, as 
\begin_inset Formula $N\left(s\right)\rightarrow\infty$
\end_inset

 we have 
\begin_inset Formula $V^{\pi}\rightarrow\mathbb{E}_{\pi}\left[G_{t}|s_{t}=s\right]$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Every-Visit Monte Carlo Policy Evaluation
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

def EV_MC_PE:
\end_layout

\begin_layout Plain Layout

	# Initialization
\end_layout

\begin_layout Plain Layout

	foreach s:
\end_layout

\begin_layout Plain Layout

		N(s) = 0
\end_layout

\begin_layout Plain Layout

		G(s) = 0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	# Computation
\end_layout

\begin_layout Plain Layout

	loop:
\end_layout

\begin_layout Plain Layout

		# Sample episode
\end_layout

\begin_layout Plain Layout

		e_i = s[i,1], a[i,1], r[i,1], s[i,2], a[i,2], r[i,2], ..., s[i,T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		# Compute return from time step t onwards in episode i
\end_layout

\begin_layout Plain Layout

		G[i,t] = r[i,t] + gamma * r[i,t+1] + ...
 + gamma ** (T_i - 1) * r[i, T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		foreach time step t till the end of episode i:
\end_layout

\begin_layout Plain Layout

			s = e_i[i, t].state
\end_layout

\begin_layout Plain Layout

			N(s) = N(s) + 1		# Increment total visits counter
\end_layout

\begin_layout Plain Layout

			G(s) = G(s) + G[i,t]	# Increment total return
\end_layout

\begin_layout Plain Layout

			V_pi(s) = G(s) / N(s) 	# Update estimate					
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Properties:
\end_layout

\begin_layout Itemize
\begin_inset Formula $V^{\pi}$
\end_inset

 is a biased estimator of 
\begin_inset Formula $\mathbb{E}_{\pi}\left[G_{t}|s_{t}=s\right]$
\end_inset

.
\end_layout

\begin_layout Itemize
But it is consistent and often with better MSE.
\end_layout

\begin_layout Subsubsection
Incremental Monte Carlo Policy Evaluation
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

def EV_MC_PE:
\end_layout

\begin_layout Plain Layout

	# Initialization
\end_layout

\begin_layout Plain Layout

	foreach s:
\end_layout

\begin_layout Plain Layout

		N(s) = 0
\end_layout

\begin_layout Plain Layout

		G(s) = 0
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	# Computation
\end_layout

\begin_layout Plain Layout

	loop:
\end_layout

\begin_layout Plain Layout

		# Sample episode
\end_layout

\begin_layout Plain Layout

		e_i = s[i,1], a[i,1], r[i,1], s[i,2], a[i,2], r[i,2], ..., s[i,T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		# Compute return from time step t onwards in episode i
\end_layout

\begin_layout Plain Layout

		G[i,t] = r[i,t] + gamma * r[i,t+1] + ...
 + gamma ** (T_i - 1) * r[i, T_i]
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

		for j=1:T_i:
\end_layout

\begin_layout Plain Layout

			V_pi(s[j,t]) = V_pi(s[j,t]) + alpha * (G[j,t] - V_pi(s[j,t]))					
\end_layout

\end_inset


\end_layout

\begin_layout Standard
These algorithms can be used to learn value predictions, but when episodes
 are long, the learning process can be slow, because we have to wait until
 an episode ends before we can learn.
 In addition, the return can have high variance.
 Therefore, it would be nice to have other methods.
\end_layout

\begin_layout Subsection
Temporal Difference Learning
\end_layout

\begin_layout Standard
The core of TD learning is the temporal difference error, which measures
 the difference between the estimated value of the current state and the
 estimated value of the next state, combined with the reward received for
 transitioning between these states.
 This error guides the update of the value function.
\end_layout

\begin_layout Standard
Therefore, TD is model-free and learns directly from experience.
 It can also learn from incomplete episodes, by bootstrapping.
\end_layout

\begin_layout Standard
TD can learn during each episode, it does not need to complete it.
\end_layout

\begin_layout Subsubsection
Temporal Difference Learning by Sampling Bellman Equations
\end_layout

\begin_layout Standard
Recall the Bellman equations,
\begin_inset Formula 
\[
v_{\pi}\left(s\right)=\mathbb{E}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right)|S_{t}=s,A_{t}\sim\pi\left(S_{t}\right)\right],
\]

\end_inset

 which can be approximated by iterating
\begin_inset Formula 
\[
v_{k+1}\left(s\right)=\mathbb{E}\left[R_{t+1}+\gamma v_{k}\left(S_{t+1}\right)|S_{t}=s,A_{t}\sim\pi\left(S_{t}\right)\right].
\]

\end_inset

 But we can also sample this, as
\begin_inset Formula 
\[
v_{t+1}\left(S_{t}\right)=R_{t+1}+\gamma v_{t}\left(S_{t+1}\right).
\]

\end_inset

 However, this is likely to be very noisy, so it is better to take a small
 step,
\begin_inset Formula 
\[
v_{t+1}\left(S_{t}\right)=v_{t}\left(S_{t}\right)+\alpha_{t}\left({\color{red}R_{t+1}+\gamma v_{t}\left(S_{t+1}\right)}-v_{t}\left(S_{t}\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
The red part is the target value, and 
\begin_inset Formula $\delta_{t}=R_{t+1}+\gamma v_{t}\left(S_{t+1}\right)-v_{t}\left(S_{t}\right)$
\end_inset

 is called the 
\series bold
TD error
\series default
.
\end_layout

\begin_layout Standard
We can visualize the difference between the Dynamic Programming approach,
 the Monte Carlo approach and the Temporal Difference approach in the following
 figure:
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename pegado25.png
	scale 40

\end_inset


\begin_inset Graphics
	filename pegado26.png
	scale 40

\end_inset


\begin_inset Graphics
	filename pegado27.png
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Backups for the different methods.
 DP (left), MC (center), TD (right).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the context of reinforcement learning, 
\series bold
bootstrapping
\series default
 refers to a method where the current estimates are updated based on other
 estimated values, rather than solely on actual rewards and complete trajectorie
s.
 
\series bold
Sampling
\series default
, on the other side, refers to learning from actual experiences or interactions
 with the environment.
\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Method
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bootstrapping
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sampling
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DP
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MC
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
TD
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
Note now that the idea of TD can also be applied to action values, and we
 can update the value 
\begin_inset Formula $q_{t}\left(S_{t},A_{t}\right)$
\end_inset

 towards the estimated return 
\begin_inset Formula $R_{t+1}+\gamma q\left(S_{t+1},A_{t+1}\right)$
\end_inset

 by
\begin_inset Formula 
\[
q_{t+1}\left(S_{t},A_{t}\right)\leftarrow q_{t}\left(S_{t},A_{t}\right)+\alpha\left(R_{t+1},\gamma q_{t}\left(S_{t+1},A_{t+1}\right)-q_{t}\left(S_{t},A_{t}\right)\right).
\]

\end_inset

 This approach is known as 
\series bold
SARSA
\series default
, since it uses 
\begin_inset Formula $\left(S_{t},A_{t},R_{t+1},S_{t+1},A_{t+1}\right)$
\end_inset

.
\end_layout

\begin_layout Subsection
Comparing MC and TD
\end_layout

\begin_layout Itemize

\color lime
TD
\color inherit
 can learn before knowing the final outcome, online after every step, while
 
\color red
MC
\color inherit
 must wait until the end of the episode before the return is known.
\end_layout

\begin_layout Itemize

\color lime
TD
\color inherit
 can learn without of the final outcome.
 It can learn from incomplete sequences and it works it continuing (non-terminat
ing) environments.
 
\color red
MC
\color inherit
, on the other hand, can only learn from complete sequences, and only works
 for episodic (terminating) environments.
\end_layout

\begin_layout Itemize

\color lime
TD
\color inherit
 is independent of the temporal span of the prediction, being able to learn
 from single transitions, while 
\color red
MC
\color inherit
 must store all predictions to update at the end of an episode.
\end_layout

\begin_layout Itemize

\color red
TD
\color inherit
 needs reasonable value estimates.
\end_layout

\begin_layout Itemize

\color lime
MC
\color inherit
 returns an unbiased estimate 
\begin_inset Formula $v_{\pi}\left(S_{t}\right)$
\end_inset

, while 
\color red
TD
\color inherit
 returns a biased estimate of 
\begin_inset Formula $v_{\pi}\left(S_{t}\right)$
\end_inset

, but the 
\color lime
TD
\color inherit
 target has lower variance, because the total return depends on many random
 actions, transitions and rewards, while the TD target depends on one random
 action, transition and reward.
\end_layout

\begin_layout Itemize
In some case, 
\color red
TD
\color inherit
 can have irreducible bias.
\end_layout

\begin_layout Itemize
When the world is partially observable, 
\color lime
MC
\color inherit
 would implicitly account for all the latent variables.
\end_layout

\begin_layout Itemize
The function to approximate the values may fit poorly.
\end_layout

\begin_layout Itemize
In the tabular case, both MC and TD will converge to 
\begin_inset Formula $v_{\pi}$
\end_inset

.
\end_layout

\begin_layout Subsection
Batch Monte Carlo and Temporal Difference
\end_layout

\begin_layout Standard
Tabular MC and TD converge as experience keeps going to infinity and 
\begin_inset Formula $\alpha_{t}\rightarrow0$
\end_inset

.
 But what about finite experience?
\end_layout

\begin_layout Standard
Consider a fixed batch of experience:
\begin_inset Formula 
\begin{align*}
episode\ 1: & S_{1}^{1},A_{1}^{1},R_{2}^{1},...,S_{T_{1}}^{1}\\
\vdots\\
episode\ K: & S_{1}^{K},A_{1}^{K},R_{2}^{K},...,S_{T_{1}}^{K}
\end{align*}

\end_inset

 We can repeatedly sample each episode 
\begin_inset Formula $k\in\left[1,K\right]$
\end_inset

 and apply MC or TD(0), which is equivalent to sampling from an empirical
 model.
\end_layout

\begin_layout Standard
MC converges to the best mean-square fit for the observed returns:
\begin_inset Formula 
\[
\sum_{k=1}^{K}\sum_{t=1}^{T_{k}}\left(G_{t}^{k}-v\left(S_{t}^{k}\right)\right)^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
TD converges to solution of the maximum likelihood Markov model, given the
 data.
\end_layout

\begin_layout Example
Consider two states, 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, with no discounting, and the following 8 episodes of experience:
\begin_inset Formula 
\begin{align*}
A & :0,B:0\\
B & :1\\
B & :1\\
B & :1\\
B & :1\\
B & :1\\
B & :1\\
B & :0
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
What are 
\begin_inset Formula $v\left(A\right)$
\end_inset

 and 
\begin_inset Formula $v\left(B\right)$
\end_inset

?
\end_layout

\begin_layout Standard
MC:
\end_layout

\begin_layout Standard
All episodes regarding 
\begin_inset Formula $A$
\end_inset

 have 0 reward, therefore
\begin_inset Formula 
\[
v\left(A\right)=0.
\]

\end_inset


\end_layout

\begin_layout Standard
Episodes regarding 
\begin_inset Formula $B$
\end_inset

 have 1 reward 75% of the time, so
\begin_inset Formula 
\[
v\left(B\right)=0.75.
\]

\end_inset


\end_layout

\begin_layout Standard
TD:
\end_layout

\begin_layout Standard
In this case, we observe that
\begin_inset Formula 
\[
p\left(S_{t+1}=B|S_{t}=A\right)=1,
\]

\end_inset

 that is, whenever we go through state 
\begin_inset Formula $A$
\end_inset

, then we go to state 
\begin_inset Formula $B$
\end_inset

.
 This means that the reward of 
\begin_inset Formula $A$
\end_inset

 is the same as the reward for 
\begin_inset Formula $B$
\end_inset

,
\begin_inset Formula 
\[
v\left(A\right)=v\left(B\right)=0.75.
\]

\end_inset


\end_layout

\begin_layout Standard
TD exploits the Markov property, and so it can be helpful in fully-observable
 environments.
 On the other side, MC does not rely the Markov property, so it can be useful
 in partially-observable environments.
 
\end_layout

\begin_layout Standard
When the data is finite or we are approximating the functions, the solutions
 may differ.
\end_layout

\begin_layout Subsection
Multi-Step Temporal Difference
\end_layout

\begin_layout Standard
TD uses value estimates, which can be innacurate.
 In addition, the information can propagate quite slowly.
 On the other side, the information propagates faster, but the updates are
 noisier.
 We can go in between the two methods!
\end_layout

\begin_layout Standard
The idea is by applying TD, but instead of doing just one step, we allow
 it to target 
\begin_inset Formula $n$
\end_inset

 steps into the future.
\end_layout

\begin_layout Standard
The returns, in this case, are:
\begin_inset Formula 
\begin{align*}
n=1 &  & G_{t}^{\left(1\right)}= & R_{t+1}+\gamma v\left(S_{t+1}\right)\\
n=2 &  & G_{t}^{\left(2\right)}= & R_{t+1}+\gamma R_{t+2}+\gamma^{2}v\left(S_{t+2}\right)\\
\vdots &  & \vdots\\
n=\infty &  & G_{t}^{\left(\infty\right)}= & R_{t+1}+\gamma R_{t+2}+...+\gamma^{T-t-1}R_{T}
\end{align*}

\end_inset

As we can see, for 
\begin_inset Formula $n=1$
\end_inset

 we obtain the regular TD, and for 
\begin_inset Formula $n=\infty$
\end_inset

 we obtain MC.
\end_layout

\begin_layout Standard
The 
\series bold
learning process
\series default
 is done by
\begin_inset Formula 
\[
v\left(S_{t}\right)\leftarrow v\left(S_{t}\right)+\alpha\left(G_{t}^{\left(n\right)}-v\left(S_{t}\right)\right).
\]

\end_inset


\end_layout

\begin_layout Section
Model-Free Control
\end_layout

\begin_layout Standard
Model-Free Control refers to learning optimal policies directly from experience
 (i.e., from interaction with the environment) without needing a model of
 the environment.
 In model-based control, you know the dynamics of the environment (transition
 probabilities and rewards), but in model-free control, you do not.
\end_layout

\begin_layout Subsection
Monte-Carlo Control
\end_layout

\begin_layout Standard
In the previous chapter, we focused on how to estimate the value function,
 given a policy.
 Now, we are going to try to discover new policies using these estimations.
 Monte-Carlo control is based on estimating the value of actions through
 sampling.
 This means that the agent tries out actions and observe the outcomes, and
 learns from these.
\end_layout

\begin_layout Standard
When we have a model, we saw how we can use a greedy policy improvement
 over 
\begin_inset Formula $v\left(s\right)$
\end_inset

, as
\begin_inset Formula 
\[
\pi'\left(s\right)=\arg\max_{a}\mathbb{E}\left[R_{t+1}+\gamma v\left(S_{t+1}\right)|S_{t}=s,A_{t}=a\right].
\]

\end_inset

 However, when we don't have the model, we cannot use this approach.
 Instead, we can use a greedy policy improvement over the action-value function,
 as
\begin_inset Formula 
\[
\pi'\left(s\right)=\arg\max_{a}q_{\pi'}\left(s,a\right),
\]

\end_inset

 which makes the action-value function very convenient for this problem.
\end_layout

\begin_layout Standard
The idea, then, would be something like:
\end_layout

\begin_layout Itemize
Policy evaluation: Monte-Carlo policy evaluation, 
\begin_inset Formula $q\sim q_{\pi}$
\end_inset

.
 That is, from state 
\begin_inset Formula $s_{t}$
\end_inset

, we try some actions, 
\begin_inset Formula $a_{1},...,a_{k}$
\end_inset

.
 and estimate 
\begin_inset Formula $q\left(s_{t},a_{1}\right),...,q\left(s_{t},a_{k}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Policy improvement: Finding a better policy, given the value function estimated.
 Here, the policy is improved by making it greedy with respect to the estimated
 action-value function (
\begin_inset Formula $q$
\end_inset

).
 This is:
\begin_inset Formula 
\[
a_{t}=\arg\max_{i=1,...,k}q\left(s_{t},a_{i}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
But there is also a problem with this approach! We are learning by interacting
 with the environment, so we cannot sample all states 
\begin_inset Formula $s$
\end_inset

 and actions 
\begin_inset Formula $a$
\end_inset

: since learning is from interaction, not all state-action pairs may be
 visited, which makes it difficult to estimate their values accurately.
 This is particularly a problem in environments with a large number of states
 or actions.
\end_layout

\begin_layout Standard
We find a trade-off between 
\series bold
exploitation
\series default
 (use the information we already know) and 
\series bold
exploration
\series default
 (try new actions to discover more about the environment).
 One approach that increases the exploration is the 
\series bold

\begin_inset Formula $\epsilon$
\end_inset

-greedy approach
\series default
:
\end_layout

\begin_layout Itemize
With probability 
\begin_inset Formula $1-\epsilon$
\end_inset

, select greedy action,
\begin_inset Formula 
\[
a=\arg\max_{a\in\mathcal{A}}q\left(s_{t},a\right).
\]

\end_inset


\end_layout

\begin_layout Itemize
With probability 
\begin_inset Formula $\epsilon$
\end_inset

, select a random action.
\end_layout

\begin_layout Standard
This can be written, for each action 
\begin_inset Formula $a$
\end_inset

, as
\begin_inset Formula 
\[
\pi_{t}\left(a\right)=\begin{cases}
\left(1-\epsilon\right)+\frac{\epsilon}{\left|\mathcal{A}\right|} & if\ q\left(s_{t},a\right)=\max_{b}q\left(s_{t},b\right)\\
\frac{\epsilon}{\left|\mathcal{A}\right|} & otherwise
\end{cases}.
\]

\end_inset

 This approach keeps exploring and obtaining new information.
\end_layout

\begin_layout Standard
We can write the model-free control as the following algorithm:
\end_layout

\begin_layout Itemize
Repeat:
\end_layout

\begin_deeper
\begin_layout Itemize
Sample episode 
\begin_inset Formula $1,...,k,...$
\end_inset

 using 
\begin_inset Formula $\pi:\left\{ S_{1},A_{1},R_{2},...,S_{T}\right\} \sim\pi$
\end_inset

.
\end_layout

\begin_layout Itemize
For each state 
\begin_inset Formula $S_{t}$
\end_inset

 and action 
\begin_inset Formula $A_{t}$
\end_inset

 in the episode, do
\begin_inset Formula 
\[
q\left(S_{t},A_{t}\right)\leftarrow q\left(S_{t},A_{t}\right)+\alpha_{t}\left(G_{t}-q\left(S_{t},A_{t}\right)\right).
\]

\end_inset


\end_layout

\begin_layout Itemize
Improve policy:
\begin_inset Formula 
\[
\epsilon\leftarrow\frac{1}{k},
\]

\end_inset


\begin_inset Formula 
\[
\pi\leftarrow\epsilon-greedy\left(q\right).
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
Some possibilities for 
\begin_inset Formula $\alpha_{t}$
\end_inset

 are 
\begin_inset Formula 
\[
\alpha_{t}=\frac{1}{N\left(S_{t},A_{t}\right)},
\]

\end_inset

 the inverse of the amount of possible actions in state 
\begin_inset Formula $t$
\end_inset

; or
\begin_inset Formula 
\[
\alpha_{t}=\frac{1}{k},
\]

\end_inset

 the inverse of the amount of episodes considered.
\end_layout

\begin_layout Subsubsection
Greedy in the Limit with Infinite Exploration (GLIE)
\end_layout

\begin_layout Standard
GLIE is a strategy to ensure that the learning algorithm both explores the
 environment adequately and also converges to a near-optimal policy.
 
\end_layout

\begin_layout Standard

\emph on
Infinite Exploration
\emph default
 ensures that every state-action pair is explored infinitely often.
 In practical terms, this means that the learning algorithm never stops
 trying out new actions, even if it has already found actions that seem
 to give good results.
 This continuous exploration is crucial for making sure that the algorithm
 doesn't miss out on potentially better actions that haven't been tried
 enough.
 Infinite exploration is often implemented using strategies like 
\begin_inset Formula $\epsilon$
\end_inset

-greedy.
 In other words, all state-actions are explored infinitely many times:
\begin_inset Formula 
\[
\lim_{t\rightarrow\infty}N_{t}\left(s,a\right)=\infty,\forall s,a.
\]

\end_inset


\end_layout

\begin_layout Standard

\emph on
Greedy in the Limit
\emph default
 means that as the learning process continues (i.e., as the number of iterations
 goes to infinity), the policy becomes increasingly greedy with respect
 to the estimated value function.
 In other words, over time, the policy relies more and more on the knowledge
 it has gained about the environment, and less on random exploration.
 This is typically achieved by gradually reducing the 
\begin_inset Formula $\epsilon$
\end_inset

 parameter in an 
\begin_inset Formula $\epsilon$
\end_inset

-greedy policy.
 As 
\begin_inset Formula $\epsilon$
\end_inset

 approaches zero, the policy becomes completely greedy, always choosing
 the action that it currently believes to be the best.
 This means that
\begin_inset Formula 
\[
\lim_{t\rightarrow\infty}\pi_{t}\left(a|s\right)=\mathcal{I}\left(a=\arg\max_{a'}q_{t}\left(s,a'\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
An example is using 
\begin_inset Formula $\epsilon$
\end_inset

-greedy with 
\begin_inset Formula $\epsilon_{k}=\frac{1}{k}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
GLIE Model-Free Control converges to the optimal action-value funtion, 
\begin_inset Formula $q_{r}\rightarrow q^{*}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Temporal-Difference Learning for Control
\end_layout

\begin_layout Standard
We saw that TD learning has several advantages over Monte-Carlo, as it shows
 lower variance, it learns online, and from incomplete sequences.
 Therefore, it is natural to think about using TD instead of MC for control.
 Instead of estimating 
\begin_inset Formula $q\left(s,a\right)$
\end_inset

 with MC, we do it with TD.
\end_layout

\begin_layout Standard
We can also update the action-value functions with SARSA, as studied in
 the previous section, by
\begin_inset Formula 
\[
q_{t+1}\left(S_{t},A_{t}\right)=q_{t}\left(S_{t},A_{t}\right)+\alpha_{t}\left(R_{t+1}+\gamma q\left(S_{t+1},A_{t+1}\right)-q\left(S_{t},A_{t}\right)\right).
\]

\end_inset

 Once we evaluate 
\begin_inset Formula $q\sim q_{\pi}$
\end_inset

, we improve the policy with the 
\begin_inset Formula $\epsilon$
\end_inset

-greedy approach.
\end_layout

\begin_layout Standard
More concretely, the following algorithm represents the approach called
 
\series bold
tabular SARSA
\series default
:
\end_layout

\begin_layout Standard
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

initialize q(s,a) arbitrarily
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

for each episode:
\end_layout

\begin_layout Plain Layout

	initialize s
\end_layout

\begin_layout Plain Layout

	choose a from a using policy derived from q
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	for each step in the episode:
\end_layout

\begin_layout Plain Layout

		take action a
\end_layout

\begin_layout Plain Layout

		observe r, s'
\end_layout

\begin_layout Plain Layout

		choose a' from s' using policy derived from q
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

		q(s,a) <- q(s,a) + alpha * [ r + gamma * q(s',a') - q(s,a) ]
\end_layout

\begin_layout Plain Layout

		
\end_layout

\begin_layout Plain Layout

		s <- s'
\end_layout

\begin_layout Plain Layout

		a <- a'
\end_layout

\begin_layout Plain Layout

	until s is terminal
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
Tabular SARSA converges to the optimal aciton-value function, 
\begin_inset Formula $q\rightarrow q^{*}$
\end_inset

, if the policy is GLIE.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Observe why it is called Tabular SARSA: we store the action-value function
 as a matrix of size 
\begin_inset Formula $\left|\mathcal{S}\right|\times\left|\mathcal{A}\right|$
\end_inset

.
\end_layout

\begin_layout Subsection
Off-Policy Temporal-Difference and Q-Learning
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition

\series bold
On-Policy Learning
\series default
 consists on learning about the behavior policy 
\begin_inset Formula $\pi$
\end_inset

 from experience, sampeld from 
\begin_inset Formula $\pi$
\end_inset

.
\end_layout

\begin_layout Definition

\series bold
Off-Policy Learning
\series default
 consists about learning the target policy 
\begin_inset Formula $\pi$
\end_inset

 from experiences sampled from 
\begin_inset Formula $\mu$
\end_inset

.
 It tries to learn counterfactually about other things the agent could do,
 by asking 'what if...?'.
\end_layout

\end_inset


\end_layout

\begin_layout Example
What I turned left? 
\begin_inset Formula $\rightarrow$
\end_inset

 New observations, rewards?
\end_layout

\begin_layout Example
What if I played more defensively? 
\begin_inset Formula $\rightarrow$
\end_inset

 Do I change the win probability?
\end_layout

\begin_layout Example
What if I continued to go forward? 
\begin_inset Formula $\rightarrow$
\end_inset

 How long until I bump into a wall?
\end_layout

\begin_layout Standard
The approaches seen so far are on-policy learning, while off-policy learning
 approaches go as follows:
\end_layout

\begin_layout Itemize
Evaluate target policy 
\begin_inset Formula $\pi\left(a|s\right)$
\end_inset

 to compute 
\begin_inset Formula $v_{\pi}\left(s\right)$
\end_inset

 or 
\begin_inset Formula $q_{\pi}\left(s,a\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
Use a behavior policy 
\begin_inset Formula $\mu\left(a|s\right)$
\end_inset

 to generate actions.
\end_layout

\begin_layout Standard
Now, why is this important? It is important because it enables an agent
 to learn by observing humans or other agents, and to re-use experience
 from old policies.
 In addition, the agent can learn several policies, while only following
 one.
 Finally, it learns about the greedy policy while following an exploratory
 policy.
\end_layout

\begin_layout Standard
A common approach is 
\series bold
Q-Learning
\series default
, which estimates the value of the greedy policy as
\begin_inset Formula 
\[
q_{t+1}\left(s,a\right)=q_{t}\left(S_{t},A_{t}\right)+\alpha_{t}\left(R_{t+1}+\gamma\max_{a'}q_{t}\left(S_{t+1},a'\right)-q_{t}\left(S_{t},A_{t}\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Theorem
Q-Learning control converges to the optimal action-value function, 
\begin_inset Formula $q\rightarrow q^{*}$
\end_inset

, as long as we take each action in each state infinitely often.
\end_layout

\end_inset


\end_layout

\begin_layout Remark
Note that Q-Learning achieves convergence without the need for greedy behavior.
 It works for any policy that eventually selects all actions sufficiently
 often.
\end_layout

\begin_layout Remark
It requires appropriately decaying step sizes, having 
\begin_inset Formula $\sum_{t}\alpha_{t}=\infty$
\end_inset

 and 
\begin_inset Formula $\sum_{t}\alpha_{t}<\infty$
\end_inset

.
\end_layout

\begin_layout Remark
One possibility is using 
\begin_inset Formula $\alpha_{t}=\frac{1}{t^{\omega}}$
\end_inset

, with 
\begin_inset Formula $\omega\in\left(0.5,1\right)$
\end_inset

.
\end_layout

\begin_layout Example
In this picture we can observe how Q-Learning is more conservative than
 SARSA.
 SARSA manages to find the optimal path, but this is quite close to the
 cliff, and is therefore dangerous.
 Q-Learning finds a path that is less efficient, but is far from the cliff,
 minimizing the danger to fall off.
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado48.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Subsection
Overestimation in Q-Learning
\end_layout

\begin_layout Standard
Classical Q-Learning has potential issues, due to the fact it uses the same
 values to select, and to evaluate; but these values are approximate, so
 the maximizing nature of the approach makes it more likely to select overestima
ted values, and less likely to select understimated values, causing 
\series bold
upward bias
\series default
.
\end_layout

\begin_layout Example
Roulette example
\end_layout

\begin_layout Example
There are 171 actions: bet 1€ on one of 170 options, or stop.
 
\end_layout

\begin_layout Example
Stops ends the episode, with 0€.
 All other actions have high variance reward, with negative expected value,
 and betting actions do not end the episode, instead enables the agent to
 bet again.
\end_layout

\begin_layout Example
In the following graph, we observe how Q-Learning overestimates the expected
 profit in this problem:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename pegado49.png
	scale 60

\end_inset


\end_layout

\end_deeper
\begin_layout Standard
The 
\color green
solution
\color inherit
 to this problem is to decouple selection from evaluation: 
\series bold
double Q-Learning
\series default
.
 The idea is to store two action-value functions, 
\begin_inset Formula $q$
\end_inset

 and 
\begin_inset Formula $q'$
\end_inset

, and update the reward estimates using them both:
\begin_inset Formula 
\[
R_{t+1}+\gamma q_{t}'\left(S_{t+1},\arg\max_{a}q_{t}\left(S_{t+1},a\right)\right),
\]

\end_inset


\begin_inset Formula 
\[
R_{t+1}+\gamma q_{t}\left(S_{t+1},\arg\max_{a}q_{t}'\left(S_{t+1},a\right)\right).
\]

\end_inset


\end_layout

\begin_layout Standard
At each 
\begin_inset Formula $t$
\end_inset

, we pick 
\begin_inset Formula $q$
\end_inset

 or 
\begin_inset Formula $q'$
\end_inset

 (randomly or with some design) and update using one of the two previous
 formulas, depending on which one we chose.
\end_layout

\begin_layout Standard
We can alse use both to act, for example by using the policy 
\begin_inset Formula $\frac{q+q'}{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Double Q-Learning also converges to the optimal policy under the same conditions
 as Q-Learning, and solves the overestimation problem.
\end_layout

\begin_layout Standard
Moreover, this idea can be generalized to other update approaches, like
 
\series bold
double SARSA
\series default
.
\end_layout

\begin_layout Subsection
Importance of Sampling Corrections
\end_layout

\begin_layout Standard
Off-Policy Learning is basically trying to solve the following problem:
\end_layout

\begin_layout Standard
Given some function 
\begin_inset Formula $f$
\end_inset

, with random inputs 
\begin_inset Formula $X$
\end_inset

 and a distribution 
\begin_inset Formula $d'$
\end_inset

, estimate the expectation of 
\begin_inset Formula $f\left(X\right)$
\end_inset

 under a different distribution 
\begin_inset Formula $d$
\end_inset

 (the target distribution).
\end_layout

\begin_layout Standard
This can be solved by weighting the data using the ratio 
\begin_inset Formula $\frac{d}{d'}$
\end_inset

:
\begin_inset Formula 
\[
\mathbb{E}_{x\sim d}\left[f\left(x\right)\right]=\sum d\left(x\right)f\left(x\right)=\sum d'\left(x\right)\frac{d\left(x\right)}{d'\left(x\right)}f\left(x\right)=\mathbb{E}_{x\sim d'}\left[\frac{d\left(x\right)}{d'\left(x\right)}f\left(x\right)\right].
\]

\end_inset

 The intuition is that we scale up events that are rare under 
\begin_inset Formula $d'$
\end_inset

, but common under 
\begin_inset Formula $d$
\end_inset

, and scale down events that are common under 
\begin_inset Formula $d'$
\end_inset

, but rare under 
\begin_inset Formula $d$
\end_inset

.
\end_layout

\begin_layout Example
Estimate one-step reward, with behavior 
\begin_inset Formula $\mu\left(a|s\right)$
\end_inset

.
 Then
\begin_inset Formula 
\[
\mathbb{E}\left[R_{t+1}|S_{t}=s,A_{t}\sim\pi\right]=\sum_{a}\pi\left(a|s\right)r\left(s,a\right)=\sum\mu\left(a|s\right)\frac{\pi\left(a|s\right)}{\mu\left(a|s\right)}r\left(s,a\right)=\mathbb{E}\left[\frac{\pi\left(A_{t}|S_{t}\right)}{\mu\left(A_{t}|S_{t}\right)}R_{t+1}|S_{t}=s,A_{t}\sim\mu\right].
\]

\end_inset

 Therefore, when following policy 
\begin_inset Formula $\mu$
\end_inset

, we can use 
\begin_inset Formula $\frac{\pi\left(A_{t}|S_{t}\right)}{\mu\left(A_{t}|S_{t}\right)}R_{t+1}$
\end_inset

 as unbiased sample.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ps-cs"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
