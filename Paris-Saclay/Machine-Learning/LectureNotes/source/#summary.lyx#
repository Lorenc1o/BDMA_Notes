#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{footmisc}
\usepackage{listings}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1,0.99,0.94}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,  
    frame=single,
    tabsize=2
}

\lstset{style=mystyle}
\end_preamble
\use_default_options true
\begin_modules
tcolorbox
customHeadersFooters
theorems-ams-bytype
theorems-sec-bytype
algorithm2e
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "linkcolor=blue, urlcolor=blue, citecolor=blue, pdfstartview={FitH}, unicode=true"
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\boxbgcolor #62a0ea
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\headheight 2cm
\headsep 1cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
BDMA - Machine Learning
\end_layout

\begin_layout Date
Fall 2023
\end_layout

\begin_layout Author
Jose Antonio Lorencio Abril
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename ../../../Decision-Modeling/LectureNotes/source/CS-logo.png
	scale 70

\end_inset


\end_layout

\begin_layout Standard
\align right
Professor: Tom Dupuis
\end_layout

\begin_layout Standard
\align right
Student e-mail: jose-antonio.lorencio-abril@student-cs.fr
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Address
This is a summary of the course 
\emph on
Machine Learning
\emph default
 taught at the Université Paris Saclay - CentraleSupélec by Professor Tom
 Dupuis in the academic year 23/24.
 Most of the content of this document is adapted from the course notes by
 Dupuis, 
\begin_inset CommandInset citation
LatexCommand cite
key "Dupuis2023"
literal "false"

\end_inset

, so I won't be citing it all the time.
 Other references will be provided when used.
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
Deep Learning
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard

\series bold
Artificial Intelligence
\series default
 is a wide concept, encompassing different aspects and fields.
 We can understand the term AI as the multidisciplinary field of study that
 aims at recreating human intelligence using artificial means.
 This is a bit abstract, and, in fact, there is no single definition for
 what this means.
 Intelligence is not fully understood, and thus it is hard to assess whether
 an artificial invention has achieved intelligence, further than intuitively
 thinking so.
\end_layout

\begin_layout Standard
For instance, AI involves a whole variety of fields:
\end_layout

\begin_layout Itemize
Perception
\end_layout

\begin_layout Itemize
Knowledge
\end_layout

\begin_layout Itemize
Cognitive System
\end_layout

\begin_layout Itemize
Planning
\end_layout

\begin_layout Itemize
Robotics
\end_layout

\begin_layout Itemize
Machine Learning (Neural Networks)
\end_layout

\begin_layout Itemize
Natural Language Processing
\end_layout

\begin_layout Standard
Leveraging all of these, people try to recreate or even surpass human performanc
e in different tasks.
 For example, a computer program that can play chess better than any human
 could ever possibly play, such as Stockfish, or a system that is able to
 understand our messages and reply, based on the knowledge that it has learnt
 in the past, such as ChatGPT and similar tools.
 Other examples are self-driving cars, auto-controlled robots, etc.
\end_layout

\begin_layout Standard
Therefore, AI is a very wide term, which merges many different scientific
 fields.
 
\series bold
Machine Learning
\series default
, on the other side, is a narrower term, which deals with the study of the
 techniques that we can use to make a computer learn to perform some task.
 It takes concepts from Statistics, Optimization Theory, Computer Science,
 Algorithms, etc.
 A relevant subclass of Machine Learning, which has come to be one of the
 most prominent fields of research in the recent years, is 
\series bold
Neural Networks 
\series default
or 
\series bold
Deep Learning
\series default
, which consists on an ML technique based on the human brain.
 Many amazing use cases that we see everywhere, like Siri (Apple assistant),
 Cortana (Windows assistant), Amazon recommender system, Dall-E (OpenAI
 image generation system), etc.
 Not only this, but the trend is growing, and the interest in DL is continuously
 increasing.
\end_layout

\begin_layout Standard
This is partly also due to the increase in computing resources, and the
 continuous optimization that different techniques are constantly experiencing.
 For instance, for a model trained on one trillion data points, in 2021
 the training process required around 16500x less compute than a model trained
 in 2012.
\end_layout

\begin_layout Standard
But not everything is sweet and roses when using DL.
 Since these systems are being involved in decision making processes, there
 are some questions that arise, like whose responsibility is it when a model
 fails? Moreover, data is needed to train the models, so it is relevant
 to address how datasets should be collected, and to respect the privacy
 of the people that produce data.
 In addition, the recent technologies that are able to generate new content
 and to modify real content, make it a new issue that AI can create false
 information, mistrust, and even violence or paranoia.
\end_layout

\begin_layout Standard
Nonetheless, let's not focus on the negative, there are lots of nice application
s of DL, and it is a key component to deal with data, achieving higher performan
ce than traditional ML techniques for huge amount of data.
\end_layout

\begin_layout Subsection
AI History
\end_layout

\begin_layout Standard
In 1950, Alan turing aimed to answer the question '
\emph on
Can machines think?
\emph default
' through a test, which came to be named the 
\series bold
Turing Test
\series default
, and consists in a 3 players game.
 First, a similar game is the following: 2 talkers, a man and a female,
 and 1 interrogator.
 The interrogator asks questions to the talkers, with the aim of determining
 who is the man and who is the female.
 The man tries to trick the interrogator, while the woman tries to help
 him to identify her.
\end_layout

\begin_layout Standard
Then, the Turing Test consists in replacing the man by an artificial machine.
 Turing thought that a machine that could trick a human interrogator, should
 be considered intelligent.
\end_layout

\begin_layout Standard
Later, in 1956, in the Dartmouth Workshop organized by IBM, the term 
\series bold
Artificial Intelligence
\series default
 was first used to describe 
\emph on
every aspect of learning or any other feature of intelligence can be so
 precisely described that a machine can be made to simulate it
\emph default
.
\end_layout

\begin_layout Standard
From this year on, there was a focus on researching about 
\series bold
Symbolic AI
\series default
, specially in three areas of research:
\end_layout

\begin_layout Itemize
Reasoning as search: a different set of actions leads to a certain goal,
 so we can try to find the best choice of action to obtain the best possible
 outcome.
\end_layout

\begin_layout Itemize
Natural Language: different tools were developed, following grammar and
 language rules.
\end_layout

\begin_layout Itemize
Micro world: small block based worlds, that the system can identify and
 move.
\end_layout

\begin_layout Standard
In 1958, the 
\series bold
Perceptron
\series default
 was conceived, giving birth to what is called the connectionism, an approach
 to AI based on the human brain, and a big hype that encouraged funding
 to support AI research.
 At this era, scientists experience a bit of lack of perspective, thinking
 that the power of AI was much higher than it was.
 For instance, H.
 A.
 Simon stated in 1965 that '
\emph on
machines will be capable, within twenty years, of doing any work a man can
 do.
\emph default
' We can relate to our time, with the huge hype that AI is experiencing,
 as well as the many apocaliptic theories that some people are making.
 Maybe we are again overestimating the power of AI.
\end_layout

\begin_layout Standard
The time from 1974 to 1980 is seen as the first winter of AI, in which research
 was slowed down and funding was reduced.
 This was due to several problems found at the time:
\end_layout

\begin_layout Itemize
There were few computational resources.
\end_layout

\begin_layout Itemize
The models at the time were not scalable.
\end_layout

\begin_layout Itemize
The Moravec's paradox: it is comparatively easy to make computers exhibit
 adult level performance on intelligence test or playing checkers, and difficult
 or impossible to give them the skills of a one-year-old when it comes to
 perception and mobility.
\end_layout

\begin_layout Itemize
Marvin Minsky made some devastating critics to connectionism, compared to
 symbolic, rule-based models:
\end_layout

\begin_deeper
\begin_layout Itemize
Limited capacity: Minsky showed that single-layer perceptrons (a simple
 kind of neural network) could not solve certain classes of problems, like
 the XOR problem.
 While it was later shown that multi-layer perceptrons could solve these
 problems, Minsky's work resulted in a shift away from neural networks for
 a time.
\end_layout

\begin_layout Itemize
Lack of clear symbols: Minsky believed that human cognition operates at
 a higher level with symbols and structures (like frames and scripts), rather
 than just distributed patterns of activation.
 He often argued that connectionist models lacked a clear way to represent
 these symbolic structures.
\end_layout

\begin_layout Itemize
Generalization and Abstraction: Minsky was concerned that connectionist
 models struggled with generalizing beyond specific training examples or
 abstracting high-level concepts from raw data.
\end_layout

\begin_layout Itemize
Inefficiency: Minsky pointed out that many problems which seemed simple
 for symbolic models could be extremely computationally intensive for connection
ist models.
\end_layout

\begin_layout Itemize
Lack of explanation: Connectionist models, especially when they become complex,
 can be seen as "black boxes", making it difficult to interpret how they
 arrive at specific conclusions.
\end_layout

\begin_layout Itemize
Over-reliance on learning: Minsky believed that not all knowledge comes
 from learning from scratch, and some of it might be innate or structured
 in advance.
 He felt connectionism put too much emphasis on learning from raw data.
\end_layout

\end_deeper
\begin_layout Standard
In 1980, there was a boom in expert knowledge systems that made AI recover
 interest.
 An 
\series bold
expert system
\series default
 solves specific tasks following an ensemble of rules based on knowledge
 facilitated by experts.
 A remarkable use case was the XCON sorting system, developed for the Digital
 Equipment Corporation, which helped them save 40M$ per year.
 In addition, connectionism also came again on scene, thanks to the development
 of 
\series bold
backpropagation
\series default
 applied to neurons, by Geoffrey Hinton.
 All these achievement made funding to come back to the field.
\end_layout

\begin_layout Standard
Nonetheless, there came a second winter of AI, from 1987 to 1994, mainly
 because several companies were disappointed and AI was seen as a technology
 that couldn't solve wide varieties of tasks.
 The funding was withdrawn from the field and a lot AI companies went bankrupt.
\end_layout

\begin_layout Standard
Luckily, from 1995 there started a new return of AI in the industry.
 The Moore's Law states that speed and memory of computer doubles every
 two years, and so computing power and memory was rapidly increasing, making
 the use of AI systems more feasible each year.
 During this time, many new concepts were introduced, such as 
\series bold
intelligent agents
\series default
 as systems that perceive their environment and take actions which maximize
 their chances of success; or different 
\series bold
probabilistic reasoning tools
\series default
 such as Bayesian networks, hidden Markov models, information theory, SVM,...
 In addition, AI researchers started to reframe their work in terms of mathemati
cs, computer science, physics, etc., making the field more attractive for
 funding.
 A remarkable milestone during this time was the victory of Deep Blue against
 Garry Kasparov.
\end_layout

\begin_layout Standard
The last era of AI comes from 2011 to today, with the advent and popularization
 of 
\series bold
Deep Learning
\series default
 (DL), which are deep graph processing layers mimicking human neurons interactio
ns.
 This happened thanks to the advances of hardware technologies, that have
 enabled the enormous computing requirements needed for DL.
 The huge hype comes from the spectacular results shown by this kind of
 systems in a huge variety of tasks, such as computer vision, natural language
 processing, anomaly detection,...
\end_layout

\begin_layout Standard
In summary, we can see how the history of AI has been a succession of hype
 and dissapointment cycles, with many actors involved and the industry as
 a very important part of the process.
\end_layout

\begin_layout Section
Machine Learning Basics
\end_layout

\begin_layout Standard
In this section, we review some notation, and basic knowledge of Linear
 Algebra, Probability and Machine Learning.
\end_layout

\begin_layout Subsection
Linear Algebra Basics
\end_layout

\begin_layout Standard
A 
\series bold
scalar
\series default
 is a number, either real and usually denoted 
\begin_inset Formula $x\in\mathbb{R}$
\end_inset

, or natural and denoted 
\begin_inset Formula $n\in\mathbb{N}$
\end_inset

.
 A 
\series bold
vector
\series default
 is an array of numbers, usually real, 
\begin_inset Formula $x\in\mathbb{R}^{n},$
\end_inset

 or
\begin_inset Formula 
\[
x=\left[\begin{array}{c}
x_{1}\\
x_{2}\\
\vdots\\
x_{n}
\end{array}\right].
\]

\end_inset

 A 
\series bold
matrix
\series default
 is a 2-dimensional array of numbers, 
\begin_inset Formula $A\in\mathbb{R}^{n\times m}$
\end_inset

, or
\begin_inset Formula 
\[
A=\left[\begin{array}{ccc}
A_{11} & \dots & A_{1n}\\
\vdots & \ddots & \vdots\\
A_{m1} & \dots & A_{mn}
\end{array}\right].
\]

\end_inset

 A 
\series bold
tensor
\series default
 is an 
\begin_inset Formula $n$
\end_inset

-dimensional array of numbers, for example 
\begin_inset Formula $A\in\mathbb{R}^{m\times k\times p}$
\end_inset

 is a 3-dimensional tensor.
\end_layout

\begin_layout Standard
Usually, we will be working with matrices, which can be operated in different
 ways:
\end_layout

\begin_layout Itemize
Transposition: 
\begin_inset Formula $A^{T}$
\end_inset

 is the transposed of 
\begin_inset Formula $A$
\end_inset

, defined as 
\begin_inset Formula $\left(A^{T}\right)_{ij}=A_{j,i}$
\end_inset

.
\end_layout

\begin_layout Itemize
Multiplication: Let 
\begin_inset Formula $A\in\mathbb{R}^{m\times k},B\in\mathbb{R}^{k\times n}$
\end_inset

, their multiplication, 
\begin_inset Formula $C\in\mathbb{R}^{m\times n}$
\end_inset

 is defined as 
\begin_inset Formula 
\[
C=A\cdot B=AB=\left(C_{ij}\right)_{i\leq m,j\leq n}=\left(\sum_{k}A_{ik}B_{kj}\right)_{i\leq m,j\leq n}.
\]

\end_inset

 Note that the following holds for every matrix 
\begin_inset Formula $A,B$
\end_inset

:
\begin_inset Formula 
\[
\left(AB\right)^{T}=B^{T}A^{T}.
\]

\end_inset


\end_layout

\begin_layout Itemize
Point-wise operations: if we have two matrices of the same size, 
\begin_inset Formula $A,B\in\mathbb{R}^{m\times n}$
\end_inset

, we can use apply scalar operator point-wise to each pair of elements in
 the same position in the two matrices.
 For example, the sum or the substraction of matrices.
\end_layout

\begin_layout Standard
There are also special matrices:
\end_layout

\begin_layout Itemize
Identity matrix: the identity matrix is a square matrix that preserves any
 vector it is multiplied with.
 For vectors of size 
\begin_inset Formula $n$
\end_inset

, the identity matrix 
\begin_inset Formula $I_{n}$
\end_inset

 verifies
\begin_inset Formula 
\[
I_{n}x=x,\forall x\in\mathbb{R}^{n}.
\]

\end_inset


\end_layout

\begin_layout Itemize
Inverse matrix: the inverse of a square matrix, 
\begin_inset Formula $A\in\mathbb{R}^{n\times n}$
\end_inset

, when it exists, is defined as the only matrix 
\begin_inset Formula $A^{-1}$
\end_inset

 such that
\begin_inset Formula 
\[
A^{-1}A=AA^{-1}=I_{n}.
\]

\end_inset


\end_layout

\begin_layout Standard
Another important concept is that of the norm, which is basically measuring
 how far a point is from the origin of the space and can be used to measure
 distances:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A 
\series bold
norm
\series default
 is a function 
\begin_inset Formula $f$
\end_inset

 that measures the size of vectors, and must have the following properties:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f\left(x\right)=0\iff x=0,$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $f\left(x+y\right)\leq f\left(x\right)+f\left(y\right),$
\end_inset

 and
\end_layout

\begin_layout Itemize
\begin_inset Formula $\forall\alpha\in\mathbb{R},f\left(\alpha x\right)=\left|\alpha\right|f\left(x\right).$
\end_inset


\end_layout

\end_deeper
\end_inset


\end_layout

\begin_layout Standard
A very important family of norms is the 
\begin_inset Formula $L^{p}$
\end_inset

 norm, defined as
\begin_inset Formula 
\[
\left\Vert x\right\Vert _{p}=\left(\sum_{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}.
\]

\end_inset

 The 
\series bold
Euclidean norm
\series default
 is the 
\begin_inset Formula $L^{2}$
\end_inset

 norm, noted 
\begin_inset Formula $\left\Vert x\right\Vert $
\end_inset

 and equivalent to computing 
\begin_inset Formula $\sqrt{x^{T}x}$
\end_inset

.
 In Machine Learning, it is not uncommon to find the use of the squared
 Euclidean norm, since it maintains the ordinals and is easier to operate
 with.
 The 
\series bold
Manhattan norm
\series default
 is the 
\begin_inset Formula $L^{1}$
\end_inset

 norm, and it is used when the difference between zero and nonzero elements
 is important.
 Finally, the 
\series bold
Max norm
\series default
 is the 
\begin_inset Formula $L^{\infty}$
\end_inset

, or 
\begin_inset Formula $\left\Vert x\right\Vert _{\infty}=\max_{i}\left|x_{i}\right|$
\end_inset

.
\end_layout

\begin_layout Subsection
Probability Basics
\end_layout

\begin_layout Standard
A 
\series bold
random variable
\series default
, 
\begin_inset Formula $X$
\end_inset

, is a variable that can take different values, 
\begin_inset Formula $x$
\end_inset

, randomly.
 They can be 
\series bold
discrete
\series default
, like the number drawn from a dice, or 
\series bold
continuous
\series default
, like the humidity in the air.
\end_layout

\begin_layout Standard
A probability distribution, 
\begin_inset Formula $p$
\end_inset

, is a 
\series bold
Probability Mass Function (PMF)
\series default
 for discrete variables, and a 
\series bold
Probability Density Function (PDF)
\series default
 for continuous random variables.
 It must satisfy:
\end_layout

\begin_layout Itemize
The domain of 
\begin_inset Formula $p$
\end_inset

 describe all possible states of 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\forall x\in X,p\left(x\right)\geq0$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $\int_{x\in X}p\left(x\right)dx=1$
\end_inset

.
\end_layout

\begin_layout Standard
It is usual to have two (or more) random variables, 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, and to be interested in the probability distribution of their combination,
 
\begin_inset Formula $p\left(x,y\right)$
\end_inset

.
 In this context, we define the 
\series bold
marginal probability
\series default
 of the variable 
\begin_inset Formula $X$
\end_inset

 as
\begin_inset Formula 
\[
p\left(X=x\right)=\int_{y\in Y}p\left(x,y\right)dy,\forall x\in X.
\]

\end_inset

 The 
\series bold
conditional probability
\series default
 of the variable 
\begin_inset Formula $Y$
\end_inset

 conditioned to 
\begin_inset Formula $X=x$
\end_inset

 is
\begin_inset Formula 
\[
p\left(Y=y|X=x\right)=\frac{p\left(Y=y,X=x\right)}{P\left(X=x\right)}.
\]

\end_inset

 Finally, there is the 
\series bold
chain rule of conditional probabilities
\series default
, in which we start with 
\begin_inset Formula $n$
\end_inset

 random variables, 
\begin_inset Formula $X_{1},...,X_{n}$
\end_inset

, and it follows:
\begin_inset Formula 
\[
p\left(X_{1}=x_{1},...,X_{n}=x_{n}\right)=p\left(X_{1}=x_{1}\right)\prod_{i=2}^{n}p\left(X_{i}=x_{i}|X_{1}=x_{1},...,X_{i-1}=x_{i-1}\right).
\]

\end_inset


\end_layout

\begin_layout Example
For example, let's say 
\begin_inset Formula $X=\left\{ 1,2,3\right\} $
\end_inset

, 
\begin_inset Formula $Y=\left\{ 1,2\right\} $
\end_inset

 and 
\begin_inset Formula $Z=\left\{ 1,2\right\} $
\end_inset

 with the following probabilities:
\end_layout

\begin_deeper
\begin_layout Standard
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="13" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $X$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Y$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $Z$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $p\left(x,y,z\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{12}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{24}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{24}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{6}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{12}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\frac{1}{20}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_deeper
\begin_layout Example
Then, the marginal probabilities for the variable 
\begin_inset Formula $X$
\end_inset

 are
\begin_inset Formula 
\[
P\left(X=1\right)=\frac{1}{6}+\frac{1}{6}+\frac{1}{12}+\frac{1}{24}=\frac{11}{24},
\]

\end_inset


\begin_inset Formula 
\[
P\left(X=2\right)=\frac{1}{24}+\frac{1}{20}+\frac{1}{20}+\frac{1}{20}=\frac{23}{120},
\]

\end_inset


\begin_inset Formula 
\[
P\left(X=3\right)=\frac{1}{6}+\frac{1}{12}+\frac{1}{20}+\frac{1}{20}=\frac{21}{60}=\frac{7}{20}.
\]

\end_inset


\end_layout

\begin_layout Example
The conditional probability for the event 
\begin_inset Formula $\left\{ Y=1|X=3\right\} $
\end_inset

 is:
\begin_inset Formula 
\[
P\left(Y=1|X=3\right)=\frac{P\left(Y=1,X=3\right)}{P\left(X=3\right)}=\frac{\frac{1}{6}+\frac{1}{12}}{\frac{7}{20}}=\frac{\frac{1}{4}}{\frac{7}{20}}=\frac{5}{7}.
\]

\end_inset


\end_layout

\begin_layout Example
The conditional probability for the event 
\begin_inset Formula $\left\{ Z=1|X=3,Y=1\right\} $
\end_inset

 is:
\begin_inset Formula 
\[
P\left(Z=1|X=3,Y=1\right)=\frac{P\left(X=3,Y=1,Z=1\right)}{P\left(X=3,Y=1\right)}=\frac{\frac{1}{6}}{\frac{1}{4}}=\frac{2}{3}.
\]

\end_inset


\end_layout

\begin_layout Example
The probability of the event 
\begin_inset Formula $\left\{ X=3,Y=1,Z=1\right\} $
\end_inset

 could be computed from the conditional probabilities as follows, in case
 we only knew these:
\begin_inset Formula 
\begin{align*}
P\left(X=3,Y=1,Z=1\right)= & P\left(X=3\right)\cdot P\left(Y=1|X=3\right)\cdot P\left(Z=1|X=3,Y=1\right)\\
= & \frac{7}{20}\cdot\frac{5}{7}\cdot\frac{2}{3}=\frac{10}{60}=\frac{1}{6}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
When there are several variables, it is possible that the value of one of
 them is dependant, somehow, on the values that the other variables take;
 or that it is not:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Two random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
independant
\series default
, denoted 
\begin_inset Formula $X\perp Y$
\end_inset

, if 
\begin_inset Formula $\forall x\in X,y\in Y,p\left(X=x,Y=y\right)=p\left(X=x\right)\cdot p\left(Y=y\right).$
\end_inset

 
\end_layout

\begin_layout Definition
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are 
\series bold
conditionally independent
\series default
 given the random variable 
\begin_inset Formula $Z$
\end_inset

, written 
\begin_inset Formula $X\perp_{Z}Y$
\end_inset

 if 
\begin_inset Formula $\forall x\in X,y\in Y,z\in Z$
\end_inset

,
\begin_inset Formula 
\[
p\left(X=x,Y=y|Z=z\right)=p\left(X=x|Z=z\right)\cdot p\left(Y=y|Z=z\right).
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Statistics and Machine Learning, there are some measures that summarize
 information about random variables, and that hold great importance.
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
The 
\series bold
expectation
\series default
 of a function 
\begin_inset Formula $f\left(x\right)$
\end_inset

 where 
\begin_inset Formula $x\sim p\left(x\right)$
\end_inset

 is the average value of 
\begin_inset Formula $f$
\end_inset

 over 
\begin_inset Formula $x$
\end_inset

:
\begin_inset Formula 
\[
\mathbb{E}_{x\sim p}\left[f\left(x\right)\right]=\int_{x\in X}p\left(x\right)f\left(x\right)dx.
\]

\end_inset

 The 
\series bold
variance
\series default
 of 
\begin_inset Formula $f\left(x\right)$
\end_inset

 measures how the values of 
\begin_inset Formula $f$
\end_inset

 varies from its average:
\begin_inset Formula 
\[
Var\left[f\left(x\right)\right]=\mathbb{E}\left[\left(f\left(x\right)-\mathbb{E}\left[f\left(x\right)\right]\right)^{2}\right],
\]

\end_inset

 and the 
\series bold
standard deviation 
\series default
is the square root of the variance.
\end_layout

\begin_layout Definition
The 
\series bold
covariance
\series default
 of two random variables provides informaiton about how much two values
 are linearly related.
 More generally, if we apply two functions 
\begin_inset Formula $f\left(x\right),$
\end_inset

 where 
\begin_inset Formula $x\sim p\left(x\right)$
\end_inset

, and 
\begin_inset Formula $g\left(y\right)$
\end_inset

, where 
\begin_inset Formula $y\sim p\left(y\right)$
\end_inset

, the covariance between them is:
\begin_inset Formula 
\[
Cov\left[f\left(x\right),g\left(y\right)\right]=\mathbb{E}\left[\left(f\left(x\right)-\mathbb{E}\left[f\left(x\right)\right]\right)\left(g\left(y\right)-\mathbb{E}\left[g\left(y\right)\right]\right)\right].
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Machine Learning Basics
\end_layout

\begin_layout Standard
To finalize with this review chapter, we are going to remember some basic
 concepts of Machine Learning.
\end_layout

\begin_layout Standard
First, let's give a definition of the concept:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
A computer program is said to 
\series bold
learn
\series default
 from experience 
\begin_inset Formula $E$
\end_inset

 with respect to some class of tasks 
\begin_inset Formula $T$
\end_inset

 and performance measure 
\begin_inset Formula $P$
\end_inset

, if its performance at tasks in 
\begin_inset Formula $T$
\end_inset

, as measured by 
\begin_inset Formula $P$
\end_inset

, improves with experience 
\begin_inset Formula $E$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
The 
\series bold
task
\series default
 
\begin_inset Formula $T$
\end_inset

 can be classification, regression, translation, generation, anomaly detection,...
\end_layout

\begin_layout Itemize
The 
\series bold
performance measure 
\begin_inset Formula $P$
\end_inset

 
\series default
is specific to the tasks involved, and can be accuracy for classification,
 for example.
 It is measured on a 
\series bold
test set
\series default
.
\end_layout

\begin_layout Itemize
The 
\series bold
experience
\series default
 
\begin_inset Formula $E$
\end_inset

 is divided into two main categories:
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
Supervised learning
\series default
: a dataset of points associated with a label or a target determines the
 expected outcome of each event.
\end_layout

\begin_layout Itemize

\series bold
Unsupervised learning
\series default
: a dataset of points without labels or targets, in which the desirable
 outcome needs to be define in some different way.
\end_layout

\end_deeper
\begin_layout Standard
Mathematically, we can formalize this as having a dataset of 
\begin_inset Formula $m$
\end_inset

 points and 
\begin_inset Formula $k$
\end_inset

 features, which can be represented as a matrix 
\begin_inset Formula $X\in\mathbb{R}^{m\times k}$
\end_inset

.
 In the case of supervised learning, 
\begin_inset Formula $X$
\end_inset

 is associated with a vector of labels, 
\begin_inset Formula $y$
\end_inset

, and we aim to learn a joint distribution, 
\begin_inset Formula $p\left(X,y\right)$
\end_inset

 to infer
\begin_inset Formula 
\[
p\left(Y=y|X=x\right)=\frac{p\left(x,y\right)}{\sum_{y'}p\left(x,y'\right)}.
\]

\end_inset

 The goal is then to find a function 
\begin_inset Formula $\hat{f}$
\end_inset

 that associates each 
\begin_inset Formula $x$
\end_inset

 to the best approximation of 
\begin_inset Formula $y$
\end_inset

, and that is capable of generalizing to unseen data.
 Usually, 
\begin_inset Formula $\hat{f}$
\end_inset

 is parameterized by a set of parameters, 
\begin_inset Formula $\theta$
\end_inset

, which are learnt during training.
\end_layout

\begin_layout Standard
The main challenge of an ML model is 
\series bold
generalization
\series default
 to unseen data estimated on test data after the training on training data.
 
\series bold
Overfitting
\series default
 occurs when the gap between training error and test error is too large,
 while 
\series bold
underfitting
\series default
 occurs when the training error is too large.
 The 
\series bold
capacity
\series default
 of a model is the range of functions that it is able to leanr and control
 how likely the model can overfit or underfit.
 This is visualized in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Appropriate-capacity,-overfittin"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename pegado1.png
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Appropriate-capacity,-overfittin"

\end_inset

Appropriate capacity, overfitting and underfitting visualization.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
When we want to train a model, we will define the parameters that characterize
 it, and then we need to obtain the best possible of the parameters, according
 to the data.
 For this, we use estimators:
\end_layout

\begin_layout Standard
\begin_inset Flex Color Box
status open

\begin_layout Definition
Given an unknown parameter 
\begin_inset Formula $\theta$
\end_inset

, we estimate it through an 
\series bold
estimator
\series default
, 
\begin_inset Formula $\hat{\theta}$
\end_inset

.
 A 
\series bold
point estimator
\series default
 is a function of the data, 
\begin_inset Formula $X$
\end_inset

,
\begin_inset Formula 
\[
\hat{\theta}=g\left(X\right).
\]

\end_inset

 The 
\series bold
bias
\series default
 of an estimator is
\begin_inset Formula 
\[
bias\left(\hat{\theta}\right)=\mathbb{E}\left[\hat{\theta}\right]-\theta.
\]

\end_inset

 An estimator is 
\series bold
unbiased 
\series default
if 
\begin_inset Formula $bias\left(\hat{\theta}\right)=0$
\end_inset

.
\end_layout

\begin_layout Definition
The 
\series bold
variance
\series default
 of an estimator is 
\begin_inset Formula $Var\left(\hat{\theta}\right)$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are different ways to construct estimators, but one that is frequently
 used and that has solid mathematical foundations is the 
\series bold
maximum likelihood estimator
\series default
.
 Consider a dataset 
\begin_inset Formula $X=\left\{ x_{1},...,x_{n}\right\} $
\end_inset

 and 
\begin_inset Formula $p\left(x;\theta\right)$
\end_inset

 a parametric family of probability distribution that maps for each 
\begin_inset Formula $x$
\end_inset

 the probability 
\begin_inset Formula $p_{data}\left(x\right)$
\end_inset

.
 This is, for each 
\begin_inset Formula $\theta$
\end_inset

, 
\begin_inset Formula $p\left(x;\theta\right)$
\end_inset

 is a probability density function.
 The maximum likelihood estimator is then
\begin_inset Formula 
\begin{align*}
\theta_{ML}= & \arg\max_{\theta}p_{model}\left(X;\theta\right)\\
= & \arg\max_{\theta}\prod_{i=1}^{m}p_{model}\left(x_{i};\theta\right),
\end{align*}

\end_inset

 considering that all instances of data are independent and identically
 distributed (iid).
 It is also a common practice to use the maximum 
\series bold
log
\series default
-likelihood instead, removing the product and avoiding floating point issues,
 since when the dataset is large, the product will rapidl
\end_layout

\begin_layout Section
Deep Neural Networks
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
Reinforcement Learning
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "ps-cs"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
